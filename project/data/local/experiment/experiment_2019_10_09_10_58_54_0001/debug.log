2019-10-09 10:58:59 | [experiment_2019_10_09_10_58_54_0001] epoch #0 | Obtaining samples...
2019-10-09 10:58:59 | [experiment_2019_10_09_10_58_54_0001] epoch #0 | Obtaining samples for iteration 0...
2019-10-09 10:58:59 | [experiment_2019_10_09_10_58_54_0001] epoch #0 | Logging diagnostics...
2019-10-09 10:58:59 | [experiment_2019_10_09_10_58_54_0001] epoch #0 | Optimizing policy...
2019-10-09 10:58:59 | [experiment_2019_10_09_10_58_54_0001] epoch #0 | Computing loss before
2019-10-09 10:58:59 | [experiment_2019_10_09_10_58_54_0001] epoch #0 | Computing KL before
2019-10-09 10:58:59 | [experiment_2019_10_09_10_58_54_0001] epoch #0 | Optimizing
2019-10-09 10:58:59 | [experiment_2019_10_09_10_58_54_0001] epoch #0 | Start CG optimization: #parameters: 1282, #inputs: 256, #subsample_inputs: 256
2019-10-09 10:58:59 | [experiment_2019_10_09_10_58_54_0001] epoch #0 | computing loss before
2019-10-09 10:58:59 | [experiment_2019_10_09_10_58_54_0001] epoch #0 | performing update
2019-10-09 10:58:59 | [experiment_2019_10_09_10_58_54_0001] epoch #0 | computing gradient
2019-10-09 10:58:59 | [experiment_2019_10_09_10_58_54_0001] epoch #0 | gradient computed
2019-10-09 10:58:59 | [experiment_2019_10_09_10_58_54_0001] epoch #0 | computing descent direction
2019-10-09 10:59:00 | [experiment_2019_10_09_10_58_54_0001] epoch #0 | descent direction computed
2019-10-09 10:59:00 | [experiment_2019_10_09_10_58_54_0001] epoch #0 | backtrack iters: 6
2019-10-09 10:59:00 | [experiment_2019_10_09_10_58_54_0001] epoch #0 | computing loss after
2019-10-09 10:59:00 | [experiment_2019_10_09_10_58_54_0001] epoch #0 | optimization finished
2019-10-09 10:59:00 | [experiment_2019_10_09_10_58_54_0001] epoch #0 | Computing KL after
2019-10-09 10:59:00 | [experiment_2019_10_09_10_58_54_0001] epoch #0 | Computing loss after
2019-10-09 10:59:00 | [experiment_2019_10_09_10_58_54_0001] epoch #0 | Fitting baseline...
2019-10-09 10:59:00 | [experiment_2019_10_09_10_58_54_0001] epoch #0 | Saving snapshot...
2019-10-09 10:59:00 | [experiment_2019_10_09_10_58_54_0001] epoch #0 | Saved
2019-10-09 10:59:00 | [experiment_2019_10_09_10_58_54_0001] epoch #0 | Time 1.51 s
2019-10-09 10:59:00 | [experiment_2019_10_09_10_58_54_0001] epoch #0 | EpochTime 1.51 s
---------------------------------------  -------------
AverageDiscountedReturn                   14.4092
AverageReturn                             15.6875
Entropy                                    0.623331
EnvExecTime                                0.0526135
Extras/EpisodeRewardMean                  15.86
Iteration                                  0
LinearFeatureBaseline/ExplainedVariance    3.0508e-08
MaxReturn                                 45
MinReturn                                  8
NumTrajs                                 256
Perplexity                                 1.86513
PolicyExecTime                             0.416131
ProcessExecTime                            0.023392
StdReturn                                  6.52729
policy/Entropy                             0.663417
policy/KL                                  0.00980993
policy/KLBefore                            1.53695e-11
policy/LossAfter                          -0.014043
policy/LossBefore                         -1.3018e-06
policy/dLoss                               0.0140417
---------------------------------------  -------------
2019-10-09 10:59:00 | [experiment_2019_10_09_10_58_54_0001] epoch #1 | Obtaining samples...
2019-10-09 10:59:00 | [experiment_2019_10_09_10_58_54_0001] epoch #1 | Obtaining samples for iteration 1...
2019-10-09 10:59:01 | [experiment_2019_10_09_10_58_54_0001] epoch #1 | Logging diagnostics...
2019-10-09 10:59:01 | [experiment_2019_10_09_10_58_54_0001] epoch #1 | Optimizing policy...
2019-10-09 10:59:01 | [experiment_2019_10_09_10_58_54_0001] epoch #1 | Computing loss before
2019-10-09 10:59:01 | [experiment_2019_10_09_10_58_54_0001] epoch #1 | Computing KL before
2019-10-09 10:59:01 | [experiment_2019_10_09_10_58_54_0001] epoch #1 | Optimizing
2019-10-09 10:59:01 | [experiment_2019_10_09_10_58_54_0001] epoch #1 | Start CG optimization: #parameters: 1282, #inputs: 251, #subsample_inputs: 251
2019-10-09 10:59:01 | [experiment_2019_10_09_10_58_54_0001] epoch #1 | computing loss before
2019-10-09 10:59:01 | [experiment_2019_10_09_10_58_54_0001] epoch #1 | performing update
2019-10-09 10:59:01 | [experiment_2019_10_09_10_58_54_0001] epoch #1 | computing gradient
2019-10-09 10:59:01 | [experiment_2019_10_09_10_58_54_0001] epoch #1 | gradient computed
2019-10-09 10:59:01 | [experiment_2019_10_09_10_58_54_0001] epoch #1 | computing descent direction
2019-10-09 10:59:01 | [experiment_2019_10_09_10_58_54_0001] epoch #1 | descent direction computed
2019-10-09 10:59:01 | [experiment_2019_10_09_10_58_54_0001] epoch #1 | backtrack iters: 3
2019-10-09 10:59:01 | [experiment_2019_10_09_10_58_54_0001] epoch #1 | computing loss after
2019-10-09 10:59:01 | [experiment_2019_10_09_10_58_54_0001] epoch #1 | optimization finished
2019-10-09 10:59:01 | [experiment_2019_10_09_10_58_54_0001] epoch #1 | Computing KL after
2019-10-09 10:59:01 | [experiment_2019_10_09_10_58_54_0001] epoch #1 | Computing loss after
2019-10-09 10:59:01 | [experiment_2019_10_09_10_58_54_0001] epoch #1 | Fitting baseline...
2019-10-09 10:59:01 | [experiment_2019_10_09_10_58_54_0001] epoch #1 | Saving snapshot...
2019-10-09 10:59:01 | [experiment_2019_10_09_10_58_54_0001] epoch #1 | Saved
2019-10-09 10:59:01 | [experiment_2019_10_09_10_58_54_0001] epoch #1 | Time 2.44 s
2019-10-09 10:59:01 | [experiment_2019_10_09_10_58_54_0001] epoch #1 | EpochTime 0.93 s
---------------------------------------  -------------
AverageDiscountedReturn                   14.696
AverageReturn                             16.0598
Entropy                                    0.664088
EnvExecTime                                0.0551341
Extras/EpisodeRewardMean                  15.8
Iteration                                  1
LinearFeatureBaseline/ExplainedVariance    0.406926
MaxReturn                                 49
MinReturn                                  8
NumTrajs                                 251
Perplexity                                 1.94272
PolicyExecTime                             0.373464
ProcessExecTime                            0.0236819
StdReturn                                  7.12834
policy/Entropy                             0.68599
policy/KL                                  0.0093669
policy/KLBefore                            8.95593e-11
policy/LossAfter                          -0.0364025
policy/LossBefore                          1.18293e-10
policy/dLoss                               0.0364025
---------------------------------------  -------------
2019-10-09 10:59:01 | [experiment_2019_10_09_10_58_54_0001] epoch #2 | Obtaining samples...
2019-10-09 10:59:01 | [experiment_2019_10_09_10_58_54_0001] epoch #2 | Obtaining samples for iteration 2...
2019-10-09 10:59:02 | [experiment_2019_10_09_10_58_54_0001] epoch #2 | Logging diagnostics...
2019-10-09 10:59:02 | [experiment_2019_10_09_10_58_54_0001] epoch #2 | Optimizing policy...
2019-10-09 10:59:02 | [experiment_2019_10_09_10_58_54_0001] epoch #2 | Computing loss before
2019-10-09 10:59:02 | [experiment_2019_10_09_10_58_54_0001] epoch #2 | Computing KL before
2019-10-09 10:59:02 | [experiment_2019_10_09_10_58_54_0001] epoch #2 | Optimizing
2019-10-09 10:59:02 | [experiment_2019_10_09_10_58_54_0001] epoch #2 | Start CG optimization: #parameters: 1282, #inputs: 203, #subsample_inputs: 203
2019-10-09 10:59:02 | [experiment_2019_10_09_10_58_54_0001] epoch #2 | computing loss before
2019-10-09 10:59:02 | [experiment_2019_10_09_10_58_54_0001] epoch #2 | performing update
2019-10-09 10:59:02 | [experiment_2019_10_09_10_58_54_0001] epoch #2 | computing gradient
2019-10-09 10:59:02 | [experiment_2019_10_09_10_58_54_0001] epoch #2 | gradient computed
2019-10-09 10:59:02 | [experiment_2019_10_09_10_58_54_0001] epoch #2 | computing descent direction
2019-10-09 10:59:02 | [experiment_2019_10_09_10_58_54_0001] epoch #2 | descent direction computed
2019-10-09 10:59:02 | [experiment_2019_10_09_10_58_54_0001] epoch #2 | backtrack iters: 2
2019-10-09 10:59:02 | [experiment_2019_10_09_10_58_54_0001] epoch #2 | computing loss after
2019-10-09 10:59:02 | [experiment_2019_10_09_10_58_54_0001] epoch #2 | optimization finished
2019-10-09 10:59:02 | [experiment_2019_10_09_10_58_54_0001] epoch #2 | Computing KL after
2019-10-09 10:59:02 | [experiment_2019_10_09_10_58_54_0001] epoch #2 | Computing loss after
2019-10-09 10:59:02 | [experiment_2019_10_09_10_58_54_0001] epoch #2 | Fitting baseline...
2019-10-09 10:59:02 | [experiment_2019_10_09_10_58_54_0001] epoch #2 | Saving snapshot...
2019-10-09 10:59:02 | [experiment_2019_10_09_10_58_54_0001] epoch #2 | Saved
2019-10-09 10:59:02 | [experiment_2019_10_09_10_58_54_0001] epoch #2 | Time 3.30 s
2019-10-09 10:59:02 | [experiment_2019_10_09_10_58_54_0001] epoch #2 | EpochTime 0.85 s
---------------------------------------  -------------
AverageDiscountedReturn                   17.5689
AverageReturn                             19.7143
Entropy                                    0.687243
EnvExecTime                                0.0542359
Extras/EpisodeRewardMean                  20.05
Iteration                                  2
LinearFeatureBaseline/ExplainedVariance    0.292039
MaxReturn                                 65
MinReturn                                  8
NumTrajs                                 203
Perplexity                                 1.98823
PolicyExecTime                             0.383478
ProcessExecTime                            0.0217085
StdReturn                                 10.1471
policy/Entropy                             0.681473
policy/KL                                  0.00934138
policy/KLBefore                           -2.17719e-10
policy/LossAfter                          -0.0305393
policy/LossBefore                         -1.25107e-09
policy/dLoss                               0.0305393
---------------------------------------  -------------
2019-10-09 10:59:02 | [experiment_2019_10_09_10_58_54_0001] epoch #3 | Obtaining samples...
2019-10-09 10:59:02 | [experiment_2019_10_09_10_58_54_0001] epoch #3 | Obtaining samples for iteration 3...
2019-10-09 10:59:02 | [experiment_2019_10_09_10_58_54_0001] epoch #3 | Logging diagnostics...
2019-10-09 10:59:02 | [experiment_2019_10_09_10_58_54_0001] epoch #3 | Optimizing policy...
2019-10-09 10:59:02 | [experiment_2019_10_09_10_58_54_0001] epoch #3 | Computing loss before
2019-10-09 10:59:02 | [experiment_2019_10_09_10_58_54_0001] epoch #3 | Computing KL before
2019-10-09 10:59:02 | [experiment_2019_10_09_10_58_54_0001] epoch #3 | Optimizing
2019-10-09 10:59:02 | [experiment_2019_10_09_10_58_54_0001] epoch #3 | Start CG optimization: #parameters: 1282, #inputs: 145, #subsample_inputs: 145
2019-10-09 10:59:02 | [experiment_2019_10_09_10_58_54_0001] epoch #3 | computing loss before
2019-10-09 10:59:02 | [experiment_2019_10_09_10_58_54_0001] epoch #3 | performing update
2019-10-09 10:59:02 | [experiment_2019_10_09_10_58_54_0001] epoch #3 | computing gradient
2019-10-09 10:59:02 | [experiment_2019_10_09_10_58_54_0001] epoch #3 | gradient computed
2019-10-09 10:59:02 | [experiment_2019_10_09_10_58_54_0001] epoch #3 | computing descent direction
2019-10-09 10:59:03 | [experiment_2019_10_09_10_58_54_0001] epoch #3 | descent direction computed
2019-10-09 10:59:03 | [experiment_2019_10_09_10_58_54_0001] epoch #3 | backtrack iters: 1
2019-10-09 10:59:03 | [experiment_2019_10_09_10_58_54_0001] epoch #3 | computing loss after
2019-10-09 10:59:03 | [experiment_2019_10_09_10_58_54_0001] epoch #3 | optimization finished
2019-10-09 10:59:03 | [experiment_2019_10_09_10_58_54_0001] epoch #3 | Computing KL after
2019-10-09 10:59:03 | [experiment_2019_10_09_10_58_54_0001] epoch #3 | Computing loss after
2019-10-09 10:59:03 | [experiment_2019_10_09_10_58_54_0001] epoch #3 | Fitting baseline...
2019-10-09 10:59:03 | [experiment_2019_10_09_10_58_54_0001] epoch #3 | Saving snapshot...
2019-10-09 10:59:03 | [experiment_2019_10_09_10_58_54_0001] epoch #3 | Saved
2019-10-09 10:59:03 | [experiment_2019_10_09_10_58_54_0001] epoch #3 | Time 4.04 s
2019-10-09 10:59:03 | [experiment_2019_10_09_10_58_54_0001] epoch #3 | EpochTime 0.74 s
---------------------------------------  -------------
AverageDiscountedReturn                   23.3352
AverageReturn                             27.6345
Entropy                                    0.679456
EnvExecTime                                0.0521517
Extras/EpisodeRewardMean                  28.06
Iteration                                  3
LinearFeatureBaseline/ExplainedVariance    0.224202
MaxReturn                                 87
MinReturn                                  8
NumTrajs                                 145
Perplexity                                 1.9728
PolicyExecTime                             0.382729
ProcessExecTime                            0.0203471
StdReturn                                 15.9529
policy/Entropy                             0.668558
policy/KL                                  0.00876761
policy/KLBefore                           -1.20843e-10
policy/LossAfter                          -0.0327714
policy/LossBefore                         -2.77272e-08
policy/dLoss                               0.0327714
---------------------------------------  -------------
2019-10-09 10:59:03 | [experiment_2019_10_09_10_58_54_0001] epoch #4 | Obtaining samples...
2019-10-09 10:59:03 | [experiment_2019_10_09_10_58_54_0001] epoch #4 | Obtaining samples for iteration 4...
2019-10-09 10:59:03 | [experiment_2019_10_09_10_58_54_0001] epoch #4 | Logging diagnostics...
2019-10-09 10:59:03 | [experiment_2019_10_09_10_58_54_0001] epoch #4 | Optimizing policy...
2019-10-09 10:59:03 | [experiment_2019_10_09_10_58_54_0001] epoch #4 | Computing loss before
2019-10-09 10:59:03 | [experiment_2019_10_09_10_58_54_0001] epoch #4 | Computing KL before
2019-10-09 10:59:03 | [experiment_2019_10_09_10_58_54_0001] epoch #4 | Optimizing
2019-10-09 10:59:03 | [experiment_2019_10_09_10_58_54_0001] epoch #4 | Start CG optimization: #parameters: 1282, #inputs: 105, #subsample_inputs: 105
2019-10-09 10:59:03 | [experiment_2019_10_09_10_58_54_0001] epoch #4 | computing loss before
2019-10-09 10:59:03 | [experiment_2019_10_09_10_58_54_0001] epoch #4 | performing update
2019-10-09 10:59:03 | [experiment_2019_10_09_10_58_54_0001] epoch #4 | computing gradient
2019-10-09 10:59:03 | [experiment_2019_10_09_10_58_54_0001] epoch #4 | gradient computed
2019-10-09 10:59:03 | [experiment_2019_10_09_10_58_54_0001] epoch #4 | computing descent direction
2019-10-09 10:59:03 | [experiment_2019_10_09_10_58_54_0001] epoch #4 | descent direction computed
2019-10-09 10:59:03 | [experiment_2019_10_09_10_58_54_0001] epoch #4 | backtrack iters: 0
2019-10-09 10:59:03 | [experiment_2019_10_09_10_58_54_0001] epoch #4 | computing loss after
2019-10-09 10:59:03 | [experiment_2019_10_09_10_58_54_0001] epoch #4 | optimization finished
2019-10-09 10:59:03 | [experiment_2019_10_09_10_58_54_0001] epoch #4 | Computing KL after
2019-10-09 10:59:03 | [experiment_2019_10_09_10_58_54_0001] epoch #4 | Computing loss after
2019-10-09 10:59:03 | [experiment_2019_10_09_10_58_54_0001] epoch #4 | Fitting baseline...
2019-10-09 10:59:03 | [experiment_2019_10_09_10_58_54_0001] epoch #4 | Saving snapshot...
2019-10-09 10:59:03 | [experiment_2019_10_09_10_58_54_0001] epoch #4 | Saved
2019-10-09 10:59:03 | [experiment_2019_10_09_10_58_54_0001] epoch #4 | Time 4.71 s
2019-10-09 10:59:03 | [experiment_2019_10_09_10_58_54_0001] epoch #4 | EpochTime 0.66 s
---------------------------------------  -------------
AverageDiscountedReturn                   30.1849
AverageReturn                             38.4
Entropy                                    0.669177
EnvExecTime                                0.0533426
Extras/EpisodeRewardMean                  38.94
Iteration                                  4
LinearFeatureBaseline/ExplainedVariance    0.212699
MaxReturn                                100
MinReturn                                 10
NumTrajs                                 105
Perplexity                                 1.95263
PolicyExecTime                             0.383777
ProcessExecTime                            0.0199614
StdReturn                                 23.9649
policy/Entropy                             0.643285
policy/KL                                  0.00774214
policy/KLBefore                            3.3922e-10
policy/LossAfter                          -0.0289006
policy/LossBefore                          5.48741e-08
policy/dLoss                               0.0289007
---------------------------------------  -------------
2019-10-09 10:59:03 | [experiment_2019_10_09_10_58_54_0001] epoch #5 | Obtaining samples...
2019-10-09 10:59:03 | [experiment_2019_10_09_10_58_54_0001] epoch #5 | Obtaining samples for iteration 5...
2019-10-09 10:59:04 | [experiment_2019_10_09_10_58_54_0001] epoch #5 | Logging diagnostics...
2019-10-09 10:59:04 | [experiment_2019_10_09_10_58_54_0001] epoch #5 | Optimizing policy...
2019-10-09 10:59:04 | [experiment_2019_10_09_10_58_54_0001] epoch #5 | Computing loss before
2019-10-09 10:59:04 | [experiment_2019_10_09_10_58_54_0001] epoch #5 | Computing KL before
2019-10-09 10:59:04 | [experiment_2019_10_09_10_58_54_0001] epoch #5 | Optimizing
2019-10-09 10:59:04 | [experiment_2019_10_09_10_58_54_0001] epoch #5 | Start CG optimization: #parameters: 1282, #inputs: 70, #subsample_inputs: 70
2019-10-09 10:59:04 | [experiment_2019_10_09_10_58_54_0001] epoch #5 | computing loss before
2019-10-09 10:59:04 | [experiment_2019_10_09_10_58_54_0001] epoch #5 | performing update
2019-10-09 10:59:04 | [experiment_2019_10_09_10_58_54_0001] epoch #5 | computing gradient
2019-10-09 10:59:04 | [experiment_2019_10_09_10_58_54_0001] epoch #5 | gradient computed
2019-10-09 10:59:04 | [experiment_2019_10_09_10_58_54_0001] epoch #5 | computing descent direction
2019-10-09 10:59:04 | [experiment_2019_10_09_10_58_54_0001] epoch #5 | descent direction computed
2019-10-09 10:59:04 | [experiment_2019_10_09_10_58_54_0001] epoch #5 | backtrack iters: 1
2019-10-09 10:59:04 | [experiment_2019_10_09_10_58_54_0001] epoch #5 | computing loss after
2019-10-09 10:59:04 | [experiment_2019_10_09_10_58_54_0001] epoch #5 | optimization finished
2019-10-09 10:59:04 | [experiment_2019_10_09_10_58_54_0001] epoch #5 | Computing KL after
2019-10-09 10:59:04 | [experiment_2019_10_09_10_58_54_0001] epoch #5 | Computing loss after
2019-10-09 10:59:04 | [experiment_2019_10_09_10_58_54_0001] epoch #5 | Fitting baseline...
2019-10-09 10:59:04 | [experiment_2019_10_09_10_58_54_0001] epoch #5 | Saving snapshot...
2019-10-09 10:59:04 | [experiment_2019_10_09_10_58_54_0001] epoch #5 | Saved
2019-10-09 10:59:04 | [experiment_2019_10_09_10_58_54_0001] epoch #5 | Time 5.35 s
2019-10-09 10:59:04 | [experiment_2019_10_09_10_58_54_0001] epoch #5 | EpochTime 0.63 s
---------------------------------------  -------------
AverageDiscountedReturn                   41.8044
AverageReturn                             58.3714
Entropy                                    0.645464
EnvExecTime                                0.0549169
Extras/EpisodeRewardMean                  52.05
Iteration                                  5
LinearFeatureBaseline/ExplainedVariance    0.311015
MaxReturn                                100
MinReturn                                 11
NumTrajs                                  70
Perplexity                                 1.90687
PolicyExecTime                             0.391372
ProcessExecTime                            0.0207517
StdReturn                                 30.2745
policy/Entropy                             0.617666
policy/KL                                  0.00680219
policy/KLBefore                           -9.9028e-13
policy/LossAfter                          -0.023157
policy/LossBefore                          4.66801e-10
policy/dLoss                               0.023157
---------------------------------------  -------------
2019-10-09 10:59:04 | [experiment_2019_10_09_10_58_54_0001] epoch #6 | Obtaining samples...
2019-10-09 10:59:04 | [experiment_2019_10_09_10_58_54_0001] epoch #6 | Obtaining samples for iteration 6...
2019-10-09 10:59:04 | [experiment_2019_10_09_10_58_54_0001] epoch #6 | Logging diagnostics...
2019-10-09 10:59:04 | [experiment_2019_10_09_10_58_54_0001] epoch #6 | Optimizing policy...
2019-10-09 10:59:04 | [experiment_2019_10_09_10_58_54_0001] epoch #6 | Computing loss before
2019-10-09 10:59:04 | [experiment_2019_10_09_10_58_54_0001] epoch #6 | Computing KL before
2019-10-09 10:59:04 | [experiment_2019_10_09_10_58_54_0001] epoch #6 | Optimizing
2019-10-09 10:59:04 | [experiment_2019_10_09_10_58_54_0001] epoch #6 | Start CG optimization: #parameters: 1282, #inputs: 55, #subsample_inputs: 55
2019-10-09 10:59:04 | [experiment_2019_10_09_10_58_54_0001] epoch #6 | computing loss before
2019-10-09 10:59:04 | [experiment_2019_10_09_10_58_54_0001] epoch #6 | performing update
2019-10-09 10:59:04 | [experiment_2019_10_09_10_58_54_0001] epoch #6 | computing gradient
2019-10-09 10:59:04 | [experiment_2019_10_09_10_58_54_0001] epoch #6 | gradient computed
2019-10-09 10:59:04 | [experiment_2019_10_09_10_58_54_0001] epoch #6 | computing descent direction
2019-10-09 10:59:05 | [experiment_2019_10_09_10_58_54_0001] epoch #6 | descent direction computed
2019-10-09 10:59:05 | [experiment_2019_10_09_10_58_54_0001] epoch #6 | backtrack iters: 1
2019-10-09 10:59:05 | [experiment_2019_10_09_10_58_54_0001] epoch #6 | computing loss after
2019-10-09 10:59:05 | [experiment_2019_10_09_10_58_54_0001] epoch #6 | optimization finished
2019-10-09 10:59:05 | [experiment_2019_10_09_10_58_54_0001] epoch #6 | Computing KL after
2019-10-09 10:59:05 | [experiment_2019_10_09_10_58_54_0001] epoch #6 | Computing loss after
2019-10-09 10:59:05 | [experiment_2019_10_09_10_58_54_0001] epoch #6 | Fitting baseline...
2019-10-09 10:59:05 | [experiment_2019_10_09_10_58_54_0001] epoch #6 | Saving snapshot...
2019-10-09 10:59:05 | [experiment_2019_10_09_10_58_54_0001] epoch #6 | Saved
2019-10-09 10:59:05 | [experiment_2019_10_09_10_58_54_0001] epoch #6 | Time 5.96 s
2019-10-09 10:59:05 | [experiment_2019_10_09_10_58_54_0001] epoch #6 | EpochTime 0.61 s
---------------------------------------  -------------
AverageDiscountedReturn                   49.7524
AverageReturn                             72.8364
Entropy                                    0.627751
EnvExecTime                                0.0520949
Extras/EpisodeRewardMean                  68.22
Iteration                                  6
LinearFeatureBaseline/ExplainedVariance    0.484023
MaxReturn                                100
MinReturn                                 11
NumTrajs                                  55
Perplexity                                 1.87339
PolicyExecTime                             0.388917
ProcessExecTime                            0.0188551
StdReturn                                 28.7103
policy/Entropy                             0.59231
policy/KL                                  0.0071817
policy/KLBefore                            1.32326e-11
policy/LossAfter                          -0.0204602
policy/LossBefore                          1.46408e-08
policy/dLoss                               0.0204602
---------------------------------------  -------------
2019-10-09 10:59:05 | [experiment_2019_10_09_10_58_54_0001] epoch #7 | Obtaining samples...
2019-10-09 10:59:05 | [experiment_2019_10_09_10_58_54_0001] epoch #7 | Obtaining samples for iteration 7...
2019-10-09 10:59:05 | [experiment_2019_10_09_10_58_54_0001] epoch #7 | Logging diagnostics...
2019-10-09 10:59:05 | [experiment_2019_10_09_10_58_54_0001] epoch #7 | Optimizing policy...
2019-10-09 10:59:05 | [experiment_2019_10_09_10_58_54_0001] epoch #7 | Computing loss before
2019-10-09 10:59:05 | [experiment_2019_10_09_10_58_54_0001] epoch #7 | Computing KL before
2019-10-09 10:59:05 | [experiment_2019_10_09_10_58_54_0001] epoch #7 | Optimizing
2019-10-09 10:59:05 | [experiment_2019_10_09_10_58_54_0001] epoch #7 | Start CG optimization: #parameters: 1282, #inputs: 45, #subsample_inputs: 45
2019-10-09 10:59:05 | [experiment_2019_10_09_10_58_54_0001] epoch #7 | computing loss before
2019-10-09 10:59:05 | [experiment_2019_10_09_10_58_54_0001] epoch #7 | performing update
2019-10-09 10:59:05 | [experiment_2019_10_09_10_58_54_0001] epoch #7 | computing gradient
2019-10-09 10:59:05 | [experiment_2019_10_09_10_58_54_0001] epoch #7 | gradient computed
2019-10-09 10:59:05 | [experiment_2019_10_09_10_58_54_0001] epoch #7 | computing descent direction
2019-10-09 10:59:05 | [experiment_2019_10_09_10_58_54_0001] epoch #7 | descent direction computed
2019-10-09 10:59:05 | [experiment_2019_10_09_10_58_54_0001] epoch #7 | backtrack iters: 0
2019-10-09 10:59:05 | [experiment_2019_10_09_10_58_54_0001] epoch #7 | computing loss after
2019-10-09 10:59:05 | [experiment_2019_10_09_10_58_54_0001] epoch #7 | optimization finished
2019-10-09 10:59:05 | [experiment_2019_10_09_10_58_54_0001] epoch #7 | Computing KL after
2019-10-09 10:59:05 | [experiment_2019_10_09_10_58_54_0001] epoch #7 | Computing loss after
2019-10-09 10:59:05 | [experiment_2019_10_09_10_58_54_0001] epoch #7 | Fitting baseline...
2019-10-09 10:59:05 | [experiment_2019_10_09_10_58_54_0001] epoch #7 | Saving snapshot...
2019-10-09 10:59:05 | [experiment_2019_10_09_10_58_54_0001] epoch #7 | Saved
2019-10-09 10:59:05 | [experiment_2019_10_09_10_58_54_0001] epoch #7 | Time 6.57 s
2019-10-09 10:59:05 | [experiment_2019_10_09_10_58_54_0001] epoch #7 | EpochTime 0.60 s
---------------------------------------  -------------
AverageDiscountedReturn                   58.08
AverageReturn                             89.1778
Entropy                                    0.603684
EnvExecTime                                0.0534205
Extras/EpisodeRewardMean                  80.19
Iteration                                  7
LinearFeatureBaseline/ExplainedVariance    0.756237
MaxReturn                                100
MinReturn                                 12
NumTrajs                                  45
Perplexity                                 1.82884
PolicyExecTime                             0.388878
ProcessExecTime                            0.0188823
StdReturn                                 21.4334
policy/Entropy                             0.593314
policy/KL                                  0.00582058
policy/KLBefore                           -2.10845e-10
policy/LossAfter                          -0.0147719
policy/LossBefore                          6.3912e-08
policy/dLoss                               0.014772
---------------------------------------  -------------
2019-10-09 10:59:05 | [experiment_2019_10_09_10_58_54_0001] epoch #8 | Obtaining samples...
2019-10-09 10:59:05 | [experiment_2019_10_09_10_58_54_0001] epoch #8 | Obtaining samples for iteration 8...
2019-10-09 10:59:06 | [experiment_2019_10_09_10_58_54_0001] epoch #8 | Logging diagnostics...
2019-10-09 10:59:06 | [experiment_2019_10_09_10_58_54_0001] epoch #8 | Optimizing policy...
2019-10-09 10:59:06 | [experiment_2019_10_09_10_58_54_0001] epoch #8 | Computing loss before
2019-10-09 10:59:06 | [experiment_2019_10_09_10_58_54_0001] epoch #8 | Computing KL before
2019-10-09 10:59:06 | [experiment_2019_10_09_10_58_54_0001] epoch #8 | Optimizing
2019-10-09 10:59:06 | [experiment_2019_10_09_10_58_54_0001] epoch #8 | Start CG optimization: #parameters: 1282, #inputs: 42, #subsample_inputs: 42
2019-10-09 10:59:06 | [experiment_2019_10_09_10_58_54_0001] epoch #8 | computing loss before
2019-10-09 10:59:06 | [experiment_2019_10_09_10_58_54_0001] epoch #8 | performing update
2019-10-09 10:59:06 | [experiment_2019_10_09_10_58_54_0001] epoch #8 | computing gradient
2019-10-09 10:59:06 | [experiment_2019_10_09_10_58_54_0001] epoch #8 | gradient computed
2019-10-09 10:59:06 | [experiment_2019_10_09_10_58_54_0001] epoch #8 | computing descent direction
2019-10-09 10:59:06 | [experiment_2019_10_09_10_58_54_0001] epoch #8 | descent direction computed
2019-10-09 10:59:06 | [experiment_2019_10_09_10_58_54_0001] epoch #8 | backtrack iters: 1
2019-10-09 10:59:06 | [experiment_2019_10_09_10_58_54_0001] epoch #8 | computing loss after
2019-10-09 10:59:06 | [experiment_2019_10_09_10_58_54_0001] epoch #8 | optimization finished
2019-10-09 10:59:06 | [experiment_2019_10_09_10_58_54_0001] epoch #8 | Computing KL after
2019-10-09 10:59:06 | [experiment_2019_10_09_10_58_54_0001] epoch #8 | Computing loss after
2019-10-09 10:59:06 | [experiment_2019_10_09_10_58_54_0001] epoch #8 | Fitting baseline...
2019-10-09 10:59:06 | [experiment_2019_10_09_10_58_54_0001] epoch #8 | Saving snapshot...
2019-10-09 10:59:06 | [experiment_2019_10_09_10_58_54_0001] epoch #8 | Saved
2019-10-09 10:59:06 | [experiment_2019_10_09_10_58_54_0001] epoch #8 | Time 7.17 s
2019-10-09 10:59:06 | [experiment_2019_10_09_10_58_54_0001] epoch #8 | EpochTime 0.60 s
---------------------------------------  -------------
AverageDiscountedReturn                   62.1887
AverageReturn                             97.3571
Entropy                                    0.591052
EnvExecTime                                0.0524814
Extras/EpisodeRewardMean                  91.33
Iteration                                  8
LinearFeatureBaseline/ExplainedVariance    0.919178
MaxReturn                                100
MinReturn                                 46
NumTrajs                                  42
Perplexity                                 1.80589
PolicyExecTime                             0.390451
ProcessExecTime                            0.0183098
StdReturn                                 10.0566
policy/Entropy                             0.585336
policy/KL                                  0.00910964
policy/KLBefore                           -5.9859e-11
policy/LossAfter                          -0.00288777
policy/LossBefore                          3.03198e-08
policy/dLoss                               0.0028878
---------------------------------------  -------------
2019-10-09 10:59:06 | [experiment_2019_10_09_10_58_54_0001] epoch #9 | Obtaining samples...
2019-10-09 10:59:06 | [experiment_2019_10_09_10_58_54_0001] epoch #9 | Obtaining samples for iteration 9...
2019-10-09 10:59:06 | [experiment_2019_10_09_10_58_54_0001] epoch #9 | Logging diagnostics...
2019-10-09 10:59:06 | [experiment_2019_10_09_10_58_54_0001] epoch #9 | Optimizing policy...
2019-10-09 10:59:06 | [experiment_2019_10_09_10_58_54_0001] epoch #9 | Computing loss before
2019-10-09 10:59:06 | [experiment_2019_10_09_10_58_54_0001] epoch #9 | Computing KL before
2019-10-09 10:59:06 | [experiment_2019_10_09_10_58_54_0001] epoch #9 | Optimizing
2019-10-09 10:59:06 | [experiment_2019_10_09_10_58_54_0001] epoch #9 | Start CG optimization: #parameters: 1282, #inputs: 41, #subsample_inputs: 41
2019-10-09 10:59:06 | [experiment_2019_10_09_10_58_54_0001] epoch #9 | computing loss before
2019-10-09 10:59:06 | [experiment_2019_10_09_10_58_54_0001] epoch #9 | performing update
2019-10-09 10:59:06 | [experiment_2019_10_09_10_58_54_0001] epoch #9 | computing gradient
2019-10-09 10:59:06 | [experiment_2019_10_09_10_58_54_0001] epoch #9 | gradient computed
2019-10-09 10:59:06 | [experiment_2019_10_09_10_58_54_0001] epoch #9 | computing descent direction
2019-10-09 10:59:06 | [experiment_2019_10_09_10_58_54_0001] epoch #9 | descent direction computed
2019-10-09 10:59:06 | [experiment_2019_10_09_10_58_54_0001] epoch #9 | backtrack iters: 2
2019-10-09 10:59:06 | [experiment_2019_10_09_10_58_54_0001] epoch #9 | computing loss after
2019-10-09 10:59:06 | [experiment_2019_10_09_10_58_54_0001] epoch #9 | optimization finished
2019-10-09 10:59:06 | [experiment_2019_10_09_10_58_54_0001] epoch #9 | Computing KL after
2019-10-09 10:59:06 | [experiment_2019_10_09_10_58_54_0001] epoch #9 | Computing loss after
2019-10-09 10:59:06 | [experiment_2019_10_09_10_58_54_0001] epoch #9 | Fitting baseline...
2019-10-09 10:59:06 | [experiment_2019_10_09_10_58_54_0001] epoch #9 | Saving snapshot...
2019-10-09 10:59:06 | [experiment_2019_10_09_10_58_54_0001] epoch #9 | Saved
2019-10-09 10:59:06 | [experiment_2019_10_09_10_58_54_0001] epoch #9 | Time 7.79 s
2019-10-09 10:59:06 | [experiment_2019_10_09_10_58_54_0001] epoch #9 | EpochTime 0.61 s
---------------------------------------  -------------
AverageDiscountedReturn                   62.4746
AverageReturn                             97.7073
Entropy                                    0.596353
EnvExecTime                                0.0527949
Extras/EpisodeRewardMean                  97.5
Iteration                                  9
LinearFeatureBaseline/ExplainedVariance    0.959803
MaxReturn                                100
MinReturn                                 77
NumTrajs                                  41
Perplexity                                 1.81549
PolicyExecTime                             0.399018
ProcessExecTime                            0.0184915
StdReturn                                  5.88194
policy/Entropy                             0.58848
policy/KL                                  0.006157
policy/KLBefore                           -1.77327e-11
policy/LossAfter                          -0.0130659
policy/LossBefore                         -1.01771e-08
policy/dLoss                               0.0130658
---------------------------------------  -------------
2019-10-09 10:59:06 | [experiment_2019_10_09_10_58_54_0001] epoch #10 | Obtaining samples...
2019-10-09 10:59:06 | [experiment_2019_10_09_10_58_54_0001] epoch #10 | Obtaining samples for iteration 10...
2019-10-09 10:59:07 | [experiment_2019_10_09_10_58_54_0001] epoch #10 | Logging diagnostics...
2019-10-09 10:59:07 | [experiment_2019_10_09_10_58_54_0001] epoch #10 | Optimizing policy...
2019-10-09 10:59:07 | [experiment_2019_10_09_10_58_54_0001] epoch #10 | Computing loss before
2019-10-09 10:59:07 | [experiment_2019_10_09_10_58_54_0001] epoch #10 | Computing KL before
2019-10-09 10:59:07 | [experiment_2019_10_09_10_58_54_0001] epoch #10 | Optimizing
2019-10-09 10:59:07 | [experiment_2019_10_09_10_58_54_0001] epoch #10 | Start CG optimization: #parameters: 1282, #inputs: 44, #subsample_inputs: 44
2019-10-09 10:59:07 | [experiment_2019_10_09_10_58_54_0001] epoch #10 | computing loss before
2019-10-09 10:59:07 | [experiment_2019_10_09_10_58_54_0001] epoch #10 | performing update
2019-10-09 10:59:07 | [experiment_2019_10_09_10_58_54_0001] epoch #10 | computing gradient
2019-10-09 10:59:07 | [experiment_2019_10_09_10_58_54_0001] epoch #10 | gradient computed
2019-10-09 10:59:07 | [experiment_2019_10_09_10_58_54_0001] epoch #10 | computing descent direction
2019-10-09 10:59:07 | [experiment_2019_10_09_10_58_54_0001] epoch #10 | descent direction computed
2019-10-09 10:59:07 | [experiment_2019_10_09_10_58_54_0001] epoch #10 | backtrack iters: 0
2019-10-09 10:59:07 | [experiment_2019_10_09_10_58_54_0001] epoch #10 | computing loss after
2019-10-09 10:59:07 | [experiment_2019_10_09_10_58_54_0001] epoch #10 | optimization finished
2019-10-09 10:59:07 | [experiment_2019_10_09_10_58_54_0001] epoch #10 | Computing KL after
2019-10-09 10:59:07 | [experiment_2019_10_09_10_58_54_0001] epoch #10 | Computing loss after
2019-10-09 10:59:07 | [experiment_2019_10_09_10_58_54_0001] epoch #10 | Fitting baseline...
2019-10-09 10:59:07 | [experiment_2019_10_09_10_58_54_0001] epoch #10 | Saving snapshot...
2019-10-09 10:59:07 | [experiment_2019_10_09_10_58_54_0001] epoch #10 | Saved
2019-10-09 10:59:07 | [experiment_2019_10_09_10_58_54_0001] epoch #10 | Time 8.41 s
2019-10-09 10:59:07 | [experiment_2019_10_09_10_58_54_0001] epoch #10 | EpochTime 0.62 s
---------------------------------------  -------------
AverageDiscountedReturn                   59.6222
AverageReturn                             92.1818
Entropy                                    0.585558
EnvExecTime                                0.0544486
Extras/EpisodeRewardMean                  95.08
Iteration                                 10
LinearFeatureBaseline/ExplainedVariance    0.806615
MaxReturn                                100
MinReturn                                 24
NumTrajs                                  44
Perplexity                                 1.79599
PolicyExecTime                             0.391353
ProcessExecTime                            0.0190618
StdReturn                                 18.322
policy/Entropy                             0.574506
policy/KL                                  0.00550546
policy/KLBefore                            1.16757e-10
policy/LossAfter                          -0.0102343
policy/LossBefore                         -5.26684e-08
policy/dLoss                               0.0102343
---------------------------------------  -------------
2019-10-09 10:59:07 | [experiment_2019_10_09_10_58_54_0001] epoch #11 | Obtaining samples...
2019-10-09 10:59:07 | [experiment_2019_10_09_10_58_54_0001] epoch #11 | Obtaining samples for iteration 11...
2019-10-09 10:59:08 | [experiment_2019_10_09_10_58_54_0001] epoch #11 | Logging diagnostics...
2019-10-09 10:59:08 | [experiment_2019_10_09_10_58_54_0001] epoch #11 | Optimizing policy...
2019-10-09 10:59:08 | [experiment_2019_10_09_10_58_54_0001] epoch #11 | Computing loss before
2019-10-09 10:59:08 | [experiment_2019_10_09_10_58_54_0001] epoch #11 | Computing KL before
2019-10-09 10:59:08 | [experiment_2019_10_09_10_58_54_0001] epoch #11 | Optimizing
2019-10-09 10:59:08 | [experiment_2019_10_09_10_58_54_0001] epoch #11 | Start CG optimization: #parameters: 1282, #inputs: 41, #subsample_inputs: 41
2019-10-09 10:59:08 | [experiment_2019_10_09_10_58_54_0001] epoch #11 | computing loss before
2019-10-09 10:59:08 | [experiment_2019_10_09_10_58_54_0001] epoch #11 | performing update
2019-10-09 10:59:08 | [experiment_2019_10_09_10_58_54_0001] epoch #11 | computing gradient
2019-10-09 10:59:08 | [experiment_2019_10_09_10_58_54_0001] epoch #11 | gradient computed
2019-10-09 10:59:08 | [experiment_2019_10_09_10_58_54_0001] epoch #11 | computing descent direction
2019-10-09 10:59:08 | [experiment_2019_10_09_10_58_54_0001] epoch #11 | descent direction computed
2019-10-09 10:59:08 | [experiment_2019_10_09_10_58_54_0001] epoch #11 | backtrack iters: 1
2019-10-09 10:59:08 | [experiment_2019_10_09_10_58_54_0001] epoch #11 | computing loss after
2019-10-09 10:59:08 | [experiment_2019_10_09_10_58_54_0001] epoch #11 | optimization finished
2019-10-09 10:59:08 | [experiment_2019_10_09_10_58_54_0001] epoch #11 | Computing KL after
2019-10-09 10:59:08 | [experiment_2019_10_09_10_58_54_0001] epoch #11 | Computing loss after
2019-10-09 10:59:08 | [experiment_2019_10_09_10_58_54_0001] epoch #11 | Fitting baseline...
2019-10-09 10:59:08 | [experiment_2019_10_09_10_58_54_0001] epoch #11 | Saving snapshot...
2019-10-09 10:59:08 | [experiment_2019_10_09_10_58_54_0001] epoch #11 | Saved
2019-10-09 10:59:08 | [experiment_2019_10_09_10_58_54_0001] epoch #11 | Time 9.00 s
2019-10-09 10:59:08 | [experiment_2019_10_09_10_58_54_0001] epoch #11 | EpochTime 0.59 s
---------------------------------------  -------------
AverageDiscountedReturn                   62.2204
AverageReturn                             97.7073
Entropy                                    0.583776
EnvExecTime                                0.0500889
Extras/EpisodeRewardMean                  95.26
Iteration                                 11
LinearFeatureBaseline/ExplainedVariance    0.938634
MaxReturn                                100
MinReturn                                 27
NumTrajs                                  41
Perplexity                                 1.7928
PolicyExecTime                             0.376668
ProcessExecTime                            0.0179181
StdReturn                                 11.6394
policy/Entropy                             0.587276
policy/KL                                  0.00629653
policy/KLBefore                           -1.99712e-11
policy/LossAfter                          -0.00452725
policy/LossBefore                          4.35057e-08
policy/dLoss                               0.00452729
---------------------------------------  -------------
2019-10-09 10:59:08 | [experiment_2019_10_09_10_58_54_0001] epoch #12 | Obtaining samples...
2019-10-09 10:59:08 | [experiment_2019_10_09_10_58_54_0001] epoch #12 | Obtaining samples for iteration 12...
2019-10-09 10:59:08 | [experiment_2019_10_09_10_58_54_0001] epoch #12 | Logging diagnostics...
2019-10-09 10:59:08 | [experiment_2019_10_09_10_58_54_0001] epoch #12 | Optimizing policy...
2019-10-09 10:59:08 | [experiment_2019_10_09_10_58_54_0001] epoch #12 | Computing loss before
2019-10-09 10:59:08 | [experiment_2019_10_09_10_58_54_0001] epoch #12 | Computing KL before
2019-10-09 10:59:08 | [experiment_2019_10_09_10_58_54_0001] epoch #12 | Optimizing
2019-10-09 10:59:08 | [experiment_2019_10_09_10_58_54_0001] epoch #12 | Start CG optimization: #parameters: 1282, #inputs: 40, #subsample_inputs: 40
2019-10-09 10:59:08 | [experiment_2019_10_09_10_58_54_0001] epoch #12 | computing loss before
2019-10-09 10:59:08 | [experiment_2019_10_09_10_58_54_0001] epoch #12 | performing update
2019-10-09 10:59:08 | [experiment_2019_10_09_10_58_54_0001] epoch #12 | computing gradient
2019-10-09 10:59:08 | [experiment_2019_10_09_10_58_54_0001] epoch #12 | gradient computed
2019-10-09 10:59:08 | [experiment_2019_10_09_10_58_54_0001] epoch #12 | computing descent direction
2019-10-09 10:59:08 | [experiment_2019_10_09_10_58_54_0001] epoch #12 | descent direction computed
2019-10-09 10:59:08 | [experiment_2019_10_09_10_58_54_0001] epoch #12 | backtrack iters: 0
2019-10-09 10:59:08 | [experiment_2019_10_09_10_58_54_0001] epoch #12 | computing loss after
2019-10-09 10:59:08 | [experiment_2019_10_09_10_58_54_0001] epoch #12 | optimization finished
2019-10-09 10:59:08 | [experiment_2019_10_09_10_58_54_0001] epoch #12 | Computing KL after
2019-10-09 10:59:08 | [experiment_2019_10_09_10_58_54_0001] epoch #12 | Computing loss after
2019-10-09 10:59:08 | [experiment_2019_10_09_10_58_54_0001] epoch #12 | Fitting baseline...
2019-10-09 10:59:08 | [experiment_2019_10_09_10_58_54_0001] epoch #12 | Saving snapshot...
2019-10-09 10:59:08 | [experiment_2019_10_09_10_58_54_0001] epoch #12 | Saved
2019-10-09 10:59:08 | [experiment_2019_10_09_10_58_54_0001] epoch #12 | Time 9.58 s
2019-10-09 10:59:08 | [experiment_2019_10_09_10_58_54_0001] epoch #12 | EpochTime 0.57 s
---------------------------------------  -------------
AverageDiscountedReturn                   63.3968
AverageReturn                            100
Entropy                                    0.596174
EnvExecTime                                0.0501697
Extras/EpisodeRewardMean                  97.5
Iteration                                 12
LinearFeatureBaseline/ExplainedVariance    0.996442
MaxReturn                                100
MinReturn                                100
NumTrajs                                  40
Perplexity                                 1.81516
PolicyExecTime                             0.362443
ProcessExecTime                            0.0176535
StdReturn                                  0
policy/Entropy                             0.580162
policy/KL                                  0.00627134
policy/KLBefore                            0
policy/LossAfter                          -0.00729434
policy/LossBefore                          2.63453e-08
policy/dLoss                               0.00729437
---------------------------------------  -------------
2019-10-09 10:59:08 | [experiment_2019_10_09_10_58_54_0001] epoch #13 | Obtaining samples...
2019-10-09 10:59:08 | [experiment_2019_10_09_10_58_54_0001] epoch #13 | Obtaining samples for iteration 13...
2019-10-09 10:59:09 | [experiment_2019_10_09_10_58_54_0001] epoch #13 | Logging diagnostics...
2019-10-09 10:59:09 | [experiment_2019_10_09_10_58_54_0001] epoch #13 | Optimizing policy...
2019-10-09 10:59:09 | [experiment_2019_10_09_10_58_54_0001] epoch #13 | Computing loss before
2019-10-09 10:59:09 | [experiment_2019_10_09_10_58_54_0001] epoch #13 | Computing KL before
2019-10-09 10:59:09 | [experiment_2019_10_09_10_58_54_0001] epoch #13 | Optimizing
2019-10-09 10:59:09 | [experiment_2019_10_09_10_58_54_0001] epoch #13 | Start CG optimization: #parameters: 1282, #inputs: 40, #subsample_inputs: 40
2019-10-09 10:59:09 | [experiment_2019_10_09_10_58_54_0001] epoch #13 | computing loss before
2019-10-09 10:59:09 | [experiment_2019_10_09_10_58_54_0001] epoch #13 | performing update
2019-10-09 10:59:09 | [experiment_2019_10_09_10_58_54_0001] epoch #13 | computing gradient
2019-10-09 10:59:09 | [experiment_2019_10_09_10_58_54_0001] epoch #13 | gradient computed
2019-10-09 10:59:09 | [experiment_2019_10_09_10_58_54_0001] epoch #13 | computing descent direction
2019-10-09 10:59:09 | [experiment_2019_10_09_10_58_54_0001] epoch #13 | descent direction computed
2019-10-09 10:59:09 | [experiment_2019_10_09_10_58_54_0001] epoch #13 | backtrack iters: 0
2019-10-09 10:59:09 | [experiment_2019_10_09_10_58_54_0001] epoch #13 | computing loss after
2019-10-09 10:59:09 | [experiment_2019_10_09_10_58_54_0001] epoch #13 | optimization finished
2019-10-09 10:59:09 | [experiment_2019_10_09_10_58_54_0001] epoch #13 | Computing KL after
2019-10-09 10:59:09 | [experiment_2019_10_09_10_58_54_0001] epoch #13 | Computing loss after
2019-10-09 10:59:09 | [experiment_2019_10_09_10_58_54_0001] epoch #13 | Fitting baseline...
2019-10-09 10:59:09 | [experiment_2019_10_09_10_58_54_0001] epoch #13 | Saving snapshot...
2019-10-09 10:59:09 | [experiment_2019_10_09_10_58_54_0001] epoch #13 | Saved
2019-10-09 10:59:09 | [experiment_2019_10_09_10_58_54_0001] epoch #13 | Time 10.14 s
2019-10-09 10:59:09 | [experiment_2019_10_09_10_58_54_0001] epoch #13 | EpochTime 0.56 s
---------------------------------------  -------------
AverageDiscountedReturn                   63.3968
AverageReturn                            100
Entropy                                    0.576329
EnvExecTime                                0.0521035
Extras/EpisodeRewardMean                  99.27
Iteration                                 13
LinearFeatureBaseline/ExplainedVariance    1
MaxReturn                                100
MinReturn                                100
NumTrajs                                  40
Perplexity                                 1.77949
PolicyExecTime                             0.350856
ProcessExecTime                            0.0187557
StdReturn                                  0
policy/Entropy                             0.571778
policy/KL                                  0.00615908
policy/KLBefore                            0
policy/LossAfter                          -0.00564418
policy/LossBefore                         -1.71661e-08
policy/dLoss                               0.00564416
---------------------------------------  -------------
2019-10-09 10:59:09 | [experiment_2019_10_09_10_58_54_0001] epoch #14 | Obtaining samples...
2019-10-09 10:59:09 | [experiment_2019_10_09_10_58_54_0001] epoch #14 | Obtaining samples for iteration 14...
2019-10-09 10:59:09 | [experiment_2019_10_09_10_58_54_0001] epoch #14 | Logging diagnostics...
2019-10-09 10:59:09 | [experiment_2019_10_09_10_58_54_0001] epoch #14 | Optimizing policy...
2019-10-09 10:59:09 | [experiment_2019_10_09_10_58_54_0001] epoch #14 | Computing loss before
2019-10-09 10:59:09 | [experiment_2019_10_09_10_58_54_0001] epoch #14 | Computing KL before
2019-10-09 10:59:09 | [experiment_2019_10_09_10_58_54_0001] epoch #14 | Optimizing
2019-10-09 10:59:09 | [experiment_2019_10_09_10_58_54_0001] epoch #14 | Start CG optimization: #parameters: 1282, #inputs: 41, #subsample_inputs: 41
2019-10-09 10:59:09 | [experiment_2019_10_09_10_58_54_0001] epoch #14 | computing loss before
2019-10-09 10:59:09 | [experiment_2019_10_09_10_58_54_0001] epoch #14 | performing update
2019-10-09 10:59:09 | [experiment_2019_10_09_10_58_54_0001] epoch #14 | computing gradient
2019-10-09 10:59:09 | [experiment_2019_10_09_10_58_54_0001] epoch #14 | gradient computed
2019-10-09 10:59:09 | [experiment_2019_10_09_10_58_54_0001] epoch #14 | computing descent direction
2019-10-09 10:59:09 | [experiment_2019_10_09_10_58_54_0001] epoch #14 | descent direction computed
2019-10-09 10:59:09 | [experiment_2019_10_09_10_58_54_0001] epoch #14 | backtrack iters: 2
2019-10-09 10:59:09 | [experiment_2019_10_09_10_58_54_0001] epoch #14 | computing loss after
2019-10-09 10:59:09 | [experiment_2019_10_09_10_58_54_0001] epoch #14 | optimization finished
2019-10-09 10:59:09 | [experiment_2019_10_09_10_58_54_0001] epoch #14 | Computing KL after
2019-10-09 10:59:09 | [experiment_2019_10_09_10_58_54_0001] epoch #14 | Computing loss after
2019-10-09 10:59:09 | [experiment_2019_10_09_10_58_54_0001] epoch #14 | Fitting baseline...
2019-10-09 10:59:09 | [experiment_2019_10_09_10_58_54_0001] epoch #14 | Saving snapshot...
2019-10-09 10:59:09 | [experiment_2019_10_09_10_58_54_0001] epoch #14 | Saved
2019-10-09 10:59:09 | [experiment_2019_10_09_10_58_54_0001] epoch #14 | Time 10.77 s
2019-10-09 10:59:09 | [experiment_2019_10_09_10_58_54_0001] epoch #14 | EpochTime 0.63 s
---------------------------------------  -------------
AverageDiscountedReturn                   63.1327
AverageReturn                             99.3659
Entropy                                    0.585576
EnvExecTime                                0.0530708
Extras/EpisodeRewardMean                  99.74
Iteration                                 14
LinearFeatureBaseline/ExplainedVariance    0.985953
MaxReturn                                100
MinReturn                                 75
NumTrajs                                  41
Perplexity                                 1.79602
PolicyExecTime                             0.406214
ProcessExecTime                            0.0185492
StdReturn                                  3.85566
policy/Entropy                             0.569052
policy/KL                                  0.00947674
policy/KLBefore                           -2.67789e-10
policy/LossAfter                          -0.00922941
policy/LossBefore                         -4.11263e-08
policy/dLoss                               0.00922937
---------------------------------------  -------------
2019-10-09 10:59:09 | [experiment_2019_10_09_10_58_54_0001] epoch #15 | Obtaining samples...
2019-10-09 10:59:09 | [experiment_2019_10_09_10_58_54_0001] epoch #15 | Obtaining samples for iteration 15...
2019-10-09 10:59:10 | [experiment_2019_10_09_10_58_54_0001] epoch #15 | Logging diagnostics...
2019-10-09 10:59:10 | [experiment_2019_10_09_10_58_54_0001] epoch #15 | Optimizing policy...
2019-10-09 10:59:10 | [experiment_2019_10_09_10_58_54_0001] epoch #15 | Computing loss before
2019-10-09 10:59:10 | [experiment_2019_10_09_10_58_54_0001] epoch #15 | Computing KL before
2019-10-09 10:59:10 | [experiment_2019_10_09_10_58_54_0001] epoch #15 | Optimizing
2019-10-09 10:59:10 | [experiment_2019_10_09_10_58_54_0001] epoch #15 | Start CG optimization: #parameters: 1282, #inputs: 40, #subsample_inputs: 40
2019-10-09 10:59:10 | [experiment_2019_10_09_10_58_54_0001] epoch #15 | computing loss before
2019-10-09 10:59:10 | [experiment_2019_10_09_10_58_54_0001] epoch #15 | performing update
2019-10-09 10:59:10 | [experiment_2019_10_09_10_58_54_0001] epoch #15 | computing gradient
2019-10-09 10:59:10 | [experiment_2019_10_09_10_58_54_0001] epoch #15 | gradient computed
2019-10-09 10:59:10 | [experiment_2019_10_09_10_58_54_0001] epoch #15 | computing descent direction
2019-10-09 10:59:10 | [experiment_2019_10_09_10_58_54_0001] epoch #15 | descent direction computed
2019-10-09 10:59:10 | [experiment_2019_10_09_10_58_54_0001] epoch #15 | backtrack iters: 1
2019-10-09 10:59:10 | [experiment_2019_10_09_10_58_54_0001] epoch #15 | computing loss after
2019-10-09 10:59:10 | [experiment_2019_10_09_10_58_54_0001] epoch #15 | optimization finished
2019-10-09 10:59:10 | [experiment_2019_10_09_10_58_54_0001] epoch #15 | Computing KL after
2019-10-09 10:59:10 | [experiment_2019_10_09_10_58_54_0001] epoch #15 | Computing loss after
2019-10-09 10:59:10 | [experiment_2019_10_09_10_58_54_0001] epoch #15 | Fitting baseline...
2019-10-09 10:59:10 | [experiment_2019_10_09_10_58_54_0001] epoch #15 | Saving snapshot...
2019-10-09 10:59:10 | [experiment_2019_10_09_10_58_54_0001] epoch #15 | Saved
2019-10-09 10:59:10 | [experiment_2019_10_09_10_58_54_0001] epoch #15 | Time 11.35 s
2019-10-09 10:59:10 | [experiment_2019_10_09_10_58_54_0001] epoch #15 | EpochTime 0.58 s
---------------------------------------  -------------
AverageDiscountedReturn                   63.3968
AverageReturn                            100
Entropy                                    0.583306
EnvExecTime                                0.050041
Extras/EpisodeRewardMean                  99.74
Iteration                                 15
LinearFeatureBaseline/ExplainedVariance    0.9978
MaxReturn                                100
MinReturn                                100
NumTrajs                                  40
Perplexity                                 1.79195
PolicyExecTime                             0.36841
ProcessExecTime                            0.0179224
StdReturn                                  0
policy/Entropy                             0.559654
policy/KL                                  0.0068432
policy/KLBefore                            0
policy/LossAfter                          -0.00931657
policy/LossBefore                         -1.60933e-08
policy/dLoss                               0.00931656
---------------------------------------  -------------
2019-10-09 10:59:10 | [experiment_2019_10_09_10_58_54_0001] epoch #16 | Obtaining samples...
2019-10-09 10:59:10 | [experiment_2019_10_09_10_58_54_0001] epoch #16 | Obtaining samples for iteration 16...
2019-10-09 10:59:10 | [experiment_2019_10_09_10_58_54_0001] epoch #16 | Logging diagnostics...
2019-10-09 10:59:10 | [experiment_2019_10_09_10_58_54_0001] epoch #16 | Optimizing policy...
2019-10-09 10:59:10 | [experiment_2019_10_09_10_58_54_0001] epoch #16 | Computing loss before
2019-10-09 10:59:10 | [experiment_2019_10_09_10_58_54_0001] epoch #16 | Computing KL before
2019-10-09 10:59:10 | [experiment_2019_10_09_10_58_54_0001] epoch #16 | Optimizing
2019-10-09 10:59:10 | [experiment_2019_10_09_10_58_54_0001] epoch #16 | Start CG optimization: #parameters: 1282, #inputs: 40, #subsample_inputs: 40
2019-10-09 10:59:10 | [experiment_2019_10_09_10_58_54_0001] epoch #16 | computing loss before
2019-10-09 10:59:10 | [experiment_2019_10_09_10_58_54_0001] epoch #16 | performing update
2019-10-09 10:59:10 | [experiment_2019_10_09_10_58_54_0001] epoch #16 | computing gradient
2019-10-09 10:59:10 | [experiment_2019_10_09_10_58_54_0001] epoch #16 | gradient computed
2019-10-09 10:59:10 | [experiment_2019_10_09_10_58_54_0001] epoch #16 | computing descent direction
2019-10-09 10:59:11 | [experiment_2019_10_09_10_58_54_0001] epoch #16 | descent direction computed
2019-10-09 10:59:11 | [experiment_2019_10_09_10_58_54_0001] epoch #16 | backtrack iters: 0
2019-10-09 10:59:11 | [experiment_2019_10_09_10_58_54_0001] epoch #16 | computing loss after
2019-10-09 10:59:11 | [experiment_2019_10_09_10_58_54_0001] epoch #16 | optimization finished
2019-10-09 10:59:11 | [experiment_2019_10_09_10_58_54_0001] epoch #16 | Computing KL after
2019-10-09 10:59:11 | [experiment_2019_10_09_10_58_54_0001] epoch #16 | Computing loss after
2019-10-09 10:59:11 | [experiment_2019_10_09_10_58_54_0001] epoch #16 | Fitting baseline...
2019-10-09 10:59:11 | [experiment_2019_10_09_10_58_54_0001] epoch #16 | Saving snapshot...
2019-10-09 10:59:11 | [experiment_2019_10_09_10_58_54_0001] epoch #16 | Saved
2019-10-09 10:59:11 | [experiment_2019_10_09_10_58_54_0001] epoch #16 | Time 11.96 s
2019-10-09 10:59:11 | [experiment_2019_10_09_10_58_54_0001] epoch #16 | EpochTime 0.60 s
---------------------------------------  -------------
AverageDiscountedReturn                   63.3968
AverageReturn                            100
Entropy                                    0.575827
EnvExecTime                                0.0542631
Extras/EpisodeRewardMean                  99.99
Iteration                                 16
LinearFeatureBaseline/ExplainedVariance    1
MaxReturn                                100
MinReturn                                100
NumTrajs                                  40
Perplexity                                 1.7786
PolicyExecTime                             0.383882
ProcessExecTime                            0.0194328
StdReturn                                  0
policy/Entropy                             0.56952
policy/KL                                  0.00844435
policy/KLBefore                            0
policy/LossAfter                          -0.00797972
policy/LossBefore                         -1.07288e-09
policy/dLoss                               0.00797972
---------------------------------------  -------------
2019-10-09 10:59:11 | [experiment_2019_10_09_10_58_54_0001] epoch #17 | Obtaining samples...
2019-10-09 10:59:11 | [experiment_2019_10_09_10_58_54_0001] epoch #17 | Obtaining samples for iteration 17...
2019-10-09 10:59:11 | [experiment_2019_10_09_10_58_54_0001] epoch #17 | Logging diagnostics...
2019-10-09 10:59:11 | [experiment_2019_10_09_10_58_54_0001] epoch #17 | Optimizing policy...
2019-10-09 10:59:11 | [experiment_2019_10_09_10_58_54_0001] epoch #17 | Computing loss before
2019-10-09 10:59:11 | [experiment_2019_10_09_10_58_54_0001] epoch #17 | Computing KL before
2019-10-09 10:59:11 | [experiment_2019_10_09_10_58_54_0001] epoch #17 | Optimizing
2019-10-09 10:59:11 | [experiment_2019_10_09_10_58_54_0001] epoch #17 | Start CG optimization: #parameters: 1282, #inputs: 40, #subsample_inputs: 40
2019-10-09 10:59:11 | [experiment_2019_10_09_10_58_54_0001] epoch #17 | computing loss before
2019-10-09 10:59:11 | [experiment_2019_10_09_10_58_54_0001] epoch #17 | performing update
2019-10-09 10:59:11 | [experiment_2019_10_09_10_58_54_0001] epoch #17 | computing gradient
2019-10-09 10:59:11 | [experiment_2019_10_09_10_58_54_0001] epoch #17 | gradient computed
2019-10-09 10:59:11 | [experiment_2019_10_09_10_58_54_0001] epoch #17 | computing descent direction
2019-10-09 10:59:11 | [experiment_2019_10_09_10_58_54_0001] epoch #17 | descent direction computed
2019-10-09 10:59:11 | [experiment_2019_10_09_10_58_54_0001] epoch #17 | backtrack iters: 2
2019-10-09 10:59:11 | [experiment_2019_10_09_10_58_54_0001] epoch #17 | computing loss after
2019-10-09 10:59:11 | [experiment_2019_10_09_10_58_54_0001] epoch #17 | optimization finished
2019-10-09 10:59:11 | [experiment_2019_10_09_10_58_54_0001] epoch #17 | Computing KL after
2019-10-09 10:59:11 | [experiment_2019_10_09_10_58_54_0001] epoch #17 | Computing loss after
2019-10-09 10:59:11 | [experiment_2019_10_09_10_58_54_0001] epoch #17 | Fitting baseline...
2019-10-09 10:59:11 | [experiment_2019_10_09_10_58_54_0001] epoch #17 | Saving snapshot...
2019-10-09 10:59:11 | [experiment_2019_10_09_10_58_54_0001] epoch #17 | Saved
2019-10-09 10:59:11 | [experiment_2019_10_09_10_58_54_0001] epoch #17 | Time 12.56 s
2019-10-09 10:59:11 | [experiment_2019_10_09_10_58_54_0001] epoch #17 | EpochTime 0.59 s
---------------------------------------  -------------
AverageDiscountedReturn                   63.3968
AverageReturn                            100
Entropy                                    0.558179
EnvExecTime                                0.0495646
Extras/EpisodeRewardMean                 100
Iteration                                 17
LinearFeatureBaseline/ExplainedVariance    1
MaxReturn                                100
MinReturn                                100
NumTrajs                                  40
Perplexity                                 1.74749
PolicyExecTime                             0.372191
ProcessExecTime                            0.0175872
StdReturn                                  0
policy/Entropy                             0.565234
policy/KL                                  0.00665283
policy/KLBefore                            0
policy/LossAfter                          -0.00413031
policy/LossBefore                         -5.72205e-09
policy/dLoss                               0.00413031
---------------------------------------  -------------
2019-10-09 10:59:11 | [experiment_2019_10_09_10_58_54_0001] epoch #18 | Obtaining samples...
2019-10-09 10:59:11 | [experiment_2019_10_09_10_58_54_0001] epoch #18 | Obtaining samples for iteration 18...
2019-10-09 10:59:12 | [experiment_2019_10_09_10_58_54_0001] epoch #18 | Logging diagnostics...
2019-10-09 10:59:12 | [experiment_2019_10_09_10_58_54_0001] epoch #18 | Optimizing policy...
2019-10-09 10:59:12 | [experiment_2019_10_09_10_58_54_0001] epoch #18 | Computing loss before
2019-10-09 10:59:12 | [experiment_2019_10_09_10_58_54_0001] epoch #18 | Computing KL before
2019-10-09 10:59:12 | [experiment_2019_10_09_10_58_54_0001] epoch #18 | Optimizing
2019-10-09 10:59:12 | [experiment_2019_10_09_10_58_54_0001] epoch #18 | Start CG optimization: #parameters: 1282, #inputs: 43, #subsample_inputs: 43
2019-10-09 10:59:12 | [experiment_2019_10_09_10_58_54_0001] epoch #18 | computing loss before
2019-10-09 10:59:12 | [experiment_2019_10_09_10_58_54_0001] epoch #18 | performing update
2019-10-09 10:59:12 | [experiment_2019_10_09_10_58_54_0001] epoch #18 | computing gradient
2019-10-09 10:59:12 | [experiment_2019_10_09_10_58_54_0001] epoch #18 | gradient computed
2019-10-09 10:59:12 | [experiment_2019_10_09_10_58_54_0001] epoch #18 | computing descent direction
2019-10-09 10:59:12 | [experiment_2019_10_09_10_58_54_0001] epoch #18 | descent direction computed
2019-10-09 10:59:12 | [experiment_2019_10_09_10_58_54_0001] epoch #18 | backtrack iters: 2
2019-10-09 10:59:12 | [experiment_2019_10_09_10_58_54_0001] epoch #18 | computing loss after
2019-10-09 10:59:12 | [experiment_2019_10_09_10_58_54_0001] epoch #18 | optimization finished
2019-10-09 10:59:12 | [experiment_2019_10_09_10_58_54_0001] epoch #18 | Computing KL after
2019-10-09 10:59:12 | [experiment_2019_10_09_10_58_54_0001] epoch #18 | Computing loss after
2019-10-09 10:59:12 | [experiment_2019_10_09_10_58_54_0001] epoch #18 | Fitting baseline...
2019-10-09 10:59:12 | [experiment_2019_10_09_10_58_54_0001] epoch #18 | Saving snapshot...
2019-10-09 10:59:12 | [experiment_2019_10_09_10_58_54_0001] epoch #18 | Saved
2019-10-09 10:59:12 | [experiment_2019_10_09_10_58_54_0001] epoch #18 | Time 13.16 s
2019-10-09 10:59:12 | [experiment_2019_10_09_10_58_54_0001] epoch #18 | EpochTime 0.60 s
---------------------------------------  -------------
AverageDiscountedReturn                   60.3641
AverageReturn                             93.6977
Entropy                                    0.56745
EnvExecTime                                0.0541978
Extras/EpisodeRewardMean                  97.29
Iteration                                 18
LinearFeatureBaseline/ExplainedVariance    0.822608
MaxReturn                                100
MinReturn                                 39
NumTrajs                                  43
Perplexity                                 1.76376
PolicyExecTime                             0.374531
ProcessExecTime                            0.0193281
StdReturn                                 16.752
policy/Entropy                             0.553733
policy/KL                                  0.00608835
policy/KLBefore                            6.63185e-11
policy/LossAfter                          -0.0134019
policy/LossBefore                          4.82873e-08
policy/dLoss                               0.0134019
---------------------------------------  -------------
2019-10-09 10:59:12 | [experiment_2019_10_09_10_58_54_0001] epoch #19 | Obtaining samples...
2019-10-09 10:59:12 | [experiment_2019_10_09_10_58_54_0001] epoch #19 | Obtaining samples for iteration 19...
2019-10-09 10:59:12 | [experiment_2019_10_09_10_58_54_0001] epoch #19 | Logging diagnostics...
2019-10-09 10:59:12 | [experiment_2019_10_09_10_58_54_0001] epoch #19 | Optimizing policy...
2019-10-09 10:59:12 | [experiment_2019_10_09_10_58_54_0001] epoch #19 | Computing loss before
2019-10-09 10:59:12 | [experiment_2019_10_09_10_58_54_0001] epoch #19 | Computing KL before
2019-10-09 10:59:12 | [experiment_2019_10_09_10_58_54_0001] epoch #19 | Optimizing
2019-10-09 10:59:12 | [experiment_2019_10_09_10_58_54_0001] epoch #19 | Start CG optimization: #parameters: 1282, #inputs: 41, #subsample_inputs: 41
2019-10-09 10:59:12 | [experiment_2019_10_09_10_58_54_0001] epoch #19 | computing loss before
2019-10-09 10:59:12 | [experiment_2019_10_09_10_58_54_0001] epoch #19 | performing update
2019-10-09 10:59:12 | [experiment_2019_10_09_10_58_54_0001] epoch #19 | computing gradient
2019-10-09 10:59:12 | [experiment_2019_10_09_10_58_54_0001] epoch #19 | gradient computed
2019-10-09 10:59:12 | [experiment_2019_10_09_10_58_54_0001] epoch #19 | computing descent direction
2019-10-09 10:59:12 | [experiment_2019_10_09_10_58_54_0001] epoch #19 | descent direction computed
2019-10-09 10:59:12 | [experiment_2019_10_09_10_58_54_0001] epoch #19 | backtrack iters: 2
2019-10-09 10:59:12 | [experiment_2019_10_09_10_58_54_0001] epoch #19 | computing loss after
2019-10-09 10:59:12 | [experiment_2019_10_09_10_58_54_0001] epoch #19 | optimization finished
2019-10-09 10:59:12 | [experiment_2019_10_09_10_58_54_0001] epoch #19 | Computing KL after
2019-10-09 10:59:12 | [experiment_2019_10_09_10_58_54_0001] epoch #19 | Computing loss after
2019-10-09 10:59:12 | [experiment_2019_10_09_10_58_54_0001] epoch #19 | Fitting baseline...
2019-10-09 10:59:12 | [experiment_2019_10_09_10_58_54_0001] epoch #19 | Saving snapshot...
2019-10-09 10:59:12 | [experiment_2019_10_09_10_58_54_0001] epoch #19 | Saved
2019-10-09 10:59:12 | [experiment_2019_10_09_10_58_54_0001] epoch #19 | Time 13.82 s
2019-10-09 10:59:12 | [experiment_2019_10_09_10_58_54_0001] epoch #19 | EpochTime 0.65 s
---------------------------------------  -------------
AverageDiscountedReturn                   63.3696
AverageReturn                             99.9268
Entropy                                    0.551322
EnvExecTime                                0.0592861
Extras/EpisodeRewardMean                  97.26
Iteration                                 19
LinearFeatureBaseline/ExplainedVariance    0.971006
MaxReturn                                100
MinReturn                                 98
NumTrajs                                  41
Perplexity                                 1.73555
PolicyExecTime                             0.414815
ProcessExecTime                            0.0205808
StdReturn                                  0.341463
policy/Entropy                             0.551994
policy/KL                                  0.00659614
policy/KLBefore                            3.30065e-11
policy/LossAfter                          -0.00786744
policy/LossBefore                         -1.83455e-08
policy/dLoss                               0.00786742
---------------------------------------  -------------
2019-10-09 10:59:12 | [experiment_2019_10_09_10_58_54_0001] epoch #20 | Obtaining samples...
2019-10-09 10:59:12 | [experiment_2019_10_09_10_58_54_0001] epoch #20 | Obtaining samples for iteration 20...
2019-10-09 10:59:13 | [experiment_2019_10_09_10_58_54_0001] epoch #20 | Logging diagnostics...
2019-10-09 10:59:13 | [experiment_2019_10_09_10_58_54_0001] epoch #20 | Optimizing policy...
2019-10-09 10:59:13 | [experiment_2019_10_09_10_58_54_0001] epoch #20 | Computing loss before
2019-10-09 10:59:13 | [experiment_2019_10_09_10_58_54_0001] epoch #20 | Computing KL before
2019-10-09 10:59:13 | [experiment_2019_10_09_10_58_54_0001] epoch #20 | Optimizing
2019-10-09 10:59:13 | [experiment_2019_10_09_10_58_54_0001] epoch #20 | Start CG optimization: #parameters: 1282, #inputs: 41, #subsample_inputs: 41
2019-10-09 10:59:13 | [experiment_2019_10_09_10_58_54_0001] epoch #20 | computing loss before
2019-10-09 10:59:13 | [experiment_2019_10_09_10_58_54_0001] epoch #20 | performing update
2019-10-09 10:59:13 | [experiment_2019_10_09_10_58_54_0001] epoch #20 | computing gradient
2019-10-09 10:59:13 | [experiment_2019_10_09_10_58_54_0001] epoch #20 | gradient computed
2019-10-09 10:59:13 | [experiment_2019_10_09_10_58_54_0001] epoch #20 | computing descent direction
2019-10-09 10:59:13 | [experiment_2019_10_09_10_58_54_0001] epoch #20 | descent direction computed
2019-10-09 10:59:13 | [experiment_2019_10_09_10_58_54_0001] epoch #20 | backtrack iters: 3
2019-10-09 10:59:13 | [experiment_2019_10_09_10_58_54_0001] epoch #20 | computing loss after
2019-10-09 10:59:13 | [experiment_2019_10_09_10_58_54_0001] epoch #20 | optimization finished
2019-10-09 10:59:13 | [experiment_2019_10_09_10_58_54_0001] epoch #20 | Computing KL after
2019-10-09 10:59:13 | [experiment_2019_10_09_10_58_54_0001] epoch #20 | Computing loss after
2019-10-09 10:59:13 | [experiment_2019_10_09_10_58_54_0001] epoch #20 | Fitting baseline...
2019-10-09 10:59:13 | [experiment_2019_10_09_10_58_54_0001] epoch #20 | Saving snapshot...
2019-10-09 10:59:13 | [experiment_2019_10_09_10_58_54_0001] epoch #20 | Saved
2019-10-09 10:59:13 | [experiment_2019_10_09_10_58_54_0001] epoch #20 | Time 14.45 s
2019-10-09 10:59:13 | [experiment_2019_10_09_10_58_54_0001] epoch #20 | EpochTime 0.63 s
---------------------------------------  -------------
AverageDiscountedReturn                   63.241
AverageReturn                             99.6098
Entropy                                    0.57492
EnvExecTime                                0.0578337
Extras/EpisodeRewardMean                  98.61
Iteration                                 20
LinearFeatureBaseline/ExplainedVariance    0.993818
MaxReturn                                100
MinReturn                                 84
NumTrajs                                  41
Perplexity                                 1.77699
PolicyExecTime                             0.392082
ProcessExecTime                            0.0208557
StdReturn                                  2.46812
policy/Entropy                             0.558416
policy/KL                                  0.007971
policy/KLBefore                           -2.12009e-11
policy/LossAfter                          -0.0201928
policy/LossBefore                          1.1943e-08
policy/dLoss                               0.0201929
---------------------------------------  -------------
2019-10-09 10:59:13 | [experiment_2019_10_09_10_58_54_0001] epoch #21 | Obtaining samples...
2019-10-09 10:59:13 | [experiment_2019_10_09_10_58_54_0001] epoch #21 | Obtaining samples for iteration 21...
2019-10-09 10:59:14 | [experiment_2019_10_09_10_58_54_0001] epoch #21 | Logging diagnostics...
2019-10-09 10:59:14 | [experiment_2019_10_09_10_58_54_0001] epoch #21 | Optimizing policy...
2019-10-09 10:59:14 | [experiment_2019_10_09_10_58_54_0001] epoch #21 | Computing loss before
2019-10-09 10:59:14 | [experiment_2019_10_09_10_58_54_0001] epoch #21 | Computing KL before
2019-10-09 10:59:14 | [experiment_2019_10_09_10_58_54_0001] epoch #21 | Optimizing
2019-10-09 10:59:14 | [experiment_2019_10_09_10_58_54_0001] epoch #21 | Start CG optimization: #parameters: 1282, #inputs: 40, #subsample_inputs: 40
2019-10-09 10:59:14 | [experiment_2019_10_09_10_58_54_0001] epoch #21 | computing loss before
2019-10-09 10:59:14 | [experiment_2019_10_09_10_58_54_0001] epoch #21 | performing update
2019-10-09 10:59:14 | [experiment_2019_10_09_10_58_54_0001] epoch #21 | computing gradient
2019-10-09 10:59:14 | [experiment_2019_10_09_10_58_54_0001] epoch #21 | gradient computed
2019-10-09 10:59:14 | [experiment_2019_10_09_10_58_54_0001] epoch #21 | computing descent direction
2019-10-09 10:59:14 | [experiment_2019_10_09_10_58_54_0001] epoch #21 | descent direction computed
2019-10-09 10:59:14 | [experiment_2019_10_09_10_58_54_0001] epoch #21 | backtrack iters: 1
2019-10-09 10:59:14 | [experiment_2019_10_09_10_58_54_0001] epoch #21 | computing loss after
2019-10-09 10:59:14 | [experiment_2019_10_09_10_58_54_0001] epoch #21 | optimization finished
2019-10-09 10:59:14 | [experiment_2019_10_09_10_58_54_0001] epoch #21 | Computing KL after
2019-10-09 10:59:14 | [experiment_2019_10_09_10_58_54_0001] epoch #21 | Computing loss after
2019-10-09 10:59:14 | [experiment_2019_10_09_10_58_54_0001] epoch #21 | Fitting baseline...
2019-10-09 10:59:14 | [experiment_2019_10_09_10_58_54_0001] epoch #21 | Saving snapshot...
2019-10-09 10:59:14 | [experiment_2019_10_09_10_58_54_0001] epoch #21 | Saved
2019-10-09 10:59:14 | [experiment_2019_10_09_10_58_54_0001] epoch #21 | Time 15.04 s
2019-10-09 10:59:14 | [experiment_2019_10_09_10_58_54_0001] epoch #21 | EpochTime 0.58 s
---------------------------------------  -------------
AverageDiscountedReturn                   63.3968
AverageReturn                            100
Entropy                                    0.573931
EnvExecTime                                0.0526063
Extras/EpisodeRewardMean                  99.84
Iteration                                 21
LinearFeatureBaseline/ExplainedVariance    0.999451
MaxReturn                                100
MinReturn                                100
NumTrajs                                  40
Perplexity                                 1.77523
PolicyExecTime                             0.358093
ProcessExecTime                            0.01897
StdReturn                                  0
policy/Entropy                             0.538653
policy/KL                                  0.00811333
policy/KLBefore                            0
policy/LossAfter                          -0.00896216
policy/LossBefore                          9.77516e-09
policy/dLoss                               0.00896217
---------------------------------------  -------------
2019-10-09 10:59:14 | [experiment_2019_10_09_10_58_54_0001] epoch #22 | Obtaining samples...
2019-10-09 10:59:14 | [experiment_2019_10_09_10_58_54_0001] epoch #22 | Obtaining samples for iteration 22...
2019-10-09 10:59:14 | [experiment_2019_10_09_10_58_54_0001] epoch #22 | Logging diagnostics...
2019-10-09 10:59:14 | [experiment_2019_10_09_10_58_54_0001] epoch #22 | Optimizing policy...
2019-10-09 10:59:14 | [experiment_2019_10_09_10_58_54_0001] epoch #22 | Computing loss before
2019-10-09 10:59:14 | [experiment_2019_10_09_10_58_54_0001] epoch #22 | Computing KL before
2019-10-09 10:59:14 | [experiment_2019_10_09_10_58_54_0001] epoch #22 | Optimizing
2019-10-09 10:59:14 | [experiment_2019_10_09_10_58_54_0001] epoch #22 | Start CG optimization: #parameters: 1282, #inputs: 40, #subsample_inputs: 40
2019-10-09 10:59:14 | [experiment_2019_10_09_10_58_54_0001] epoch #22 | computing loss before
2019-10-09 10:59:14 | [experiment_2019_10_09_10_58_54_0001] epoch #22 | performing update
2019-10-09 10:59:14 | [experiment_2019_10_09_10_58_54_0001] epoch #22 | computing gradient
2019-10-09 10:59:14 | [experiment_2019_10_09_10_58_54_0001] epoch #22 | gradient computed
2019-10-09 10:59:14 | [experiment_2019_10_09_10_58_54_0001] epoch #22 | computing descent direction
2019-10-09 10:59:14 | [experiment_2019_10_09_10_58_54_0001] epoch #22 | descent direction computed
2019-10-09 10:59:14 | [experiment_2019_10_09_10_58_54_0001] epoch #22 | backtrack iters: 1
2019-10-09 10:59:14 | [experiment_2019_10_09_10_58_54_0001] epoch #22 | computing loss after
2019-10-09 10:59:14 | [experiment_2019_10_09_10_58_54_0001] epoch #22 | optimization finished
2019-10-09 10:59:14 | [experiment_2019_10_09_10_58_54_0001] epoch #22 | Computing KL after
2019-10-09 10:59:14 | [experiment_2019_10_09_10_58_54_0001] epoch #22 | Computing loss after
2019-10-09 10:59:14 | [experiment_2019_10_09_10_58_54_0001] epoch #22 | Fitting baseline...
2019-10-09 10:59:14 | [experiment_2019_10_09_10_58_54_0001] epoch #22 | Saving snapshot...
2019-10-09 10:59:14 | [experiment_2019_10_09_10_58_54_0001] epoch #22 | Saved
2019-10-09 10:59:14 | [experiment_2019_10_09_10_58_54_0001] epoch #22 | Time 15.65 s
2019-10-09 10:59:14 | [experiment_2019_10_09_10_58_54_0001] epoch #22 | EpochTime 0.60 s
---------------------------------------  -------------
AverageDiscountedReturn                   63.3968
AverageReturn                            100
Entropy                                    0.556397
EnvExecTime                                0.0526547
Extras/EpisodeRewardMean                 100
Iteration                                 22
LinearFeatureBaseline/ExplainedVariance    1
MaxReturn                                100
MinReturn                                100
NumTrajs                                  40
Perplexity                                 1.74438
PolicyExecTime                             0.377455
ProcessExecTime                            0.0187302
StdReturn                                  0
policy/Entropy                             0.553384
policy/KL                                  0.00730483
policy/KLBefore                            0
policy/LossAfter                          -0.00621397
policy/LossBefore                         -1.66893e-08
policy/dLoss                               0.00621396
---------------------------------------  -------------
2019-10-09 10:59:14 | [experiment_2019_10_09_10_58_54_0001] epoch #23 | Obtaining samples...
2019-10-09 10:59:14 | [experiment_2019_10_09_10_58_54_0001] epoch #23 | Obtaining samples for iteration 23...
2019-10-09 10:59:15 | [experiment_2019_10_09_10_58_54_0001] epoch #23 | Logging diagnostics...
2019-10-09 10:59:15 | [experiment_2019_10_09_10_58_54_0001] epoch #23 | Optimizing policy...
2019-10-09 10:59:15 | [experiment_2019_10_09_10_58_54_0001] epoch #23 | Computing loss before
2019-10-09 10:59:15 | [experiment_2019_10_09_10_58_54_0001] epoch #23 | Computing KL before
2019-10-09 10:59:15 | [experiment_2019_10_09_10_58_54_0001] epoch #23 | Optimizing
2019-10-09 10:59:15 | [experiment_2019_10_09_10_58_54_0001] epoch #23 | Start CG optimization: #parameters: 1282, #inputs: 40, #subsample_inputs: 40
2019-10-09 10:59:15 | [experiment_2019_10_09_10_58_54_0001] epoch #23 | computing loss before
2019-10-09 10:59:15 | [experiment_2019_10_09_10_58_54_0001] epoch #23 | performing update
2019-10-09 10:59:15 | [experiment_2019_10_09_10_58_54_0001] epoch #23 | computing gradient
2019-10-09 10:59:15 | [experiment_2019_10_09_10_58_54_0001] epoch #23 | gradient computed
2019-10-09 10:59:15 | [experiment_2019_10_09_10_58_54_0001] epoch #23 | computing descent direction
2019-10-09 10:59:15 | [experiment_2019_10_09_10_58_54_0001] epoch #23 | descent direction computed
2019-10-09 10:59:15 | [experiment_2019_10_09_10_58_54_0001] epoch #23 | backtrack iters: 2
2019-10-09 10:59:15 | [experiment_2019_10_09_10_58_54_0001] epoch #23 | computing loss after
2019-10-09 10:59:15 | [experiment_2019_10_09_10_58_54_0001] epoch #23 | optimization finished
2019-10-09 10:59:15 | [experiment_2019_10_09_10_58_54_0001] epoch #23 | Computing KL after
2019-10-09 10:59:15 | [experiment_2019_10_09_10_58_54_0001] epoch #23 | Computing loss after
2019-10-09 10:59:15 | [experiment_2019_10_09_10_58_54_0001] epoch #23 | Fitting baseline...
2019-10-09 10:59:15 | [experiment_2019_10_09_10_58_54_0001] epoch #23 | Saving snapshot...
2019-10-09 10:59:15 | [experiment_2019_10_09_10_58_54_0001] epoch #23 | Saved
2019-10-09 10:59:15 | [experiment_2019_10_09_10_58_54_0001] epoch #23 | Time 16.21 s
2019-10-09 10:59:15 | [experiment_2019_10_09_10_58_54_0001] epoch #23 | EpochTime 0.56 s
---------------------------------------  -------------
AverageDiscountedReturn                   63.3968
AverageReturn                            100
Entropy                                    0.561501
EnvExecTime                                0.0525639
Extras/EpisodeRewardMean                 100
Iteration                                 23
LinearFeatureBaseline/ExplainedVariance    1
MaxReturn                                100
MinReturn                                100
NumTrajs                                  40
Perplexity                                 1.7533
PolicyExecTime                             0.344611
ProcessExecTime                            0.0199831
StdReturn                                  0
policy/Entropy                             0.594515
policy/KL                                  0.00968805
policy/KLBefore                            0
policy/LossAfter                          -0.00646254
policy/LossBefore                         -1.19209e-08
policy/dLoss                               0.00646253
---------------------------------------  -------------
2019-10-09 10:59:15 | [experiment_2019_10_09_10_58_54_0001] epoch #24 | Obtaining samples...
2019-10-09 10:59:15 | [experiment_2019_10_09_10_58_54_0001] epoch #24 | Obtaining samples for iteration 24...
2019-10-09 10:59:15 | [experiment_2019_10_09_10_58_54_0001] epoch #24 | Logging diagnostics...
2019-10-09 10:59:15 | [experiment_2019_10_09_10_58_54_0001] epoch #24 | Optimizing policy...
2019-10-09 10:59:15 | [experiment_2019_10_09_10_58_54_0001] epoch #24 | Computing loss before
2019-10-09 10:59:15 | [experiment_2019_10_09_10_58_54_0001] epoch #24 | Computing KL before
2019-10-09 10:59:15 | [experiment_2019_10_09_10_58_54_0001] epoch #24 | Optimizing
2019-10-09 10:59:15 | [experiment_2019_10_09_10_58_54_0001] epoch #24 | Start CG optimization: #parameters: 1282, #inputs: 40, #subsample_inputs: 40
2019-10-09 10:59:15 | [experiment_2019_10_09_10_58_54_0001] epoch #24 | computing loss before
2019-10-09 10:59:15 | [experiment_2019_10_09_10_58_54_0001] epoch #24 | performing update
2019-10-09 10:59:15 | [experiment_2019_10_09_10_58_54_0001] epoch #24 | computing gradient
2019-10-09 10:59:15 | [experiment_2019_10_09_10_58_54_0001] epoch #24 | gradient computed
2019-10-09 10:59:15 | [experiment_2019_10_09_10_58_54_0001] epoch #24 | computing descent direction
2019-10-09 10:59:15 | [experiment_2019_10_09_10_58_54_0001] epoch #24 | descent direction computed
2019-10-09 10:59:15 | [experiment_2019_10_09_10_58_54_0001] epoch #24 | backtrack iters: 0
2019-10-09 10:59:15 | [experiment_2019_10_09_10_58_54_0001] epoch #24 | computing loss after
2019-10-09 10:59:15 | [experiment_2019_10_09_10_58_54_0001] epoch #24 | optimization finished
2019-10-09 10:59:15 | [experiment_2019_10_09_10_58_54_0001] epoch #24 | Computing KL after
2019-10-09 10:59:15 | [experiment_2019_10_09_10_58_54_0001] epoch #24 | Computing loss after
2019-10-09 10:59:15 | [experiment_2019_10_09_10_58_54_0001] epoch #24 | Fitting baseline...
2019-10-09 10:59:15 | [experiment_2019_10_09_10_58_54_0001] epoch #24 | Saving snapshot...
2019-10-09 10:59:15 | [experiment_2019_10_09_10_58_54_0001] epoch #24 | Saved
2019-10-09 10:59:15 | [experiment_2019_10_09_10_58_54_0001] epoch #24 | Time 16.79 s
2019-10-09 10:59:15 | [experiment_2019_10_09_10_58_54_0001] epoch #24 | EpochTime 0.58 s
---------------------------------------  ------------
AverageDiscountedReturn                   63.3968
AverageReturn                            100
Entropy                                    0.572655
EnvExecTime                                0.0527432
Extras/EpisodeRewardMean                 100
Iteration                                 24
LinearFeatureBaseline/ExplainedVariance    1
MaxReturn                                100
MinReturn                                100
NumTrajs                                  40
Perplexity                                 1.77297
PolicyExecTime                             0.362749
ProcessExecTime                            0.0189357
StdReturn                                  0
policy/Entropy                             0.562869
policy/KL                                  0.00937462
policy/KLBefore                            0
policy/LossAfter                          -0.0044804
policy/LossBefore                         -1.2219e-08
policy/dLoss                               0.00448039
---------------------------------------  ------------
2019-10-09 10:59:15 | [experiment_2019_10_09_10_58_54_0001] epoch #25 | Obtaining samples...
2019-10-09 10:59:15 | [experiment_2019_10_09_10_58_54_0001] epoch #25 | Obtaining samples for iteration 25...
2019-10-09 10:59:16 | [experiment_2019_10_09_10_58_54_0001] epoch #25 | Logging diagnostics...
2019-10-09 10:59:16 | [experiment_2019_10_09_10_58_54_0001] epoch #25 | Optimizing policy...
2019-10-09 10:59:16 | [experiment_2019_10_09_10_58_54_0001] epoch #25 | Computing loss before
2019-10-09 10:59:16 | [experiment_2019_10_09_10_58_54_0001] epoch #25 | Computing KL before
2019-10-09 10:59:16 | [experiment_2019_10_09_10_58_54_0001] epoch #25 | Optimizing
2019-10-09 10:59:16 | [experiment_2019_10_09_10_58_54_0001] epoch #25 | Start CG optimization: #parameters: 1282, #inputs: 40, #subsample_inputs: 40
2019-10-09 10:59:16 | [experiment_2019_10_09_10_58_54_0001] epoch #25 | computing loss before
2019-10-09 10:59:16 | [experiment_2019_10_09_10_58_54_0001] epoch #25 | performing update
2019-10-09 10:59:16 | [experiment_2019_10_09_10_58_54_0001] epoch #25 | computing gradient
2019-10-09 10:59:16 | [experiment_2019_10_09_10_58_54_0001] epoch #25 | gradient computed
2019-10-09 10:59:16 | [experiment_2019_10_09_10_58_54_0001] epoch #25 | computing descent direction
2019-10-09 10:59:16 | [experiment_2019_10_09_10_58_54_0001] epoch #25 | descent direction computed
2019-10-09 10:59:16 | [experiment_2019_10_09_10_58_54_0001] epoch #25 | backtrack iters: 1
2019-10-09 10:59:16 | [experiment_2019_10_09_10_58_54_0001] epoch #25 | computing loss after
2019-10-09 10:59:16 | [experiment_2019_10_09_10_58_54_0001] epoch #25 | optimization finished
2019-10-09 10:59:16 | [experiment_2019_10_09_10_58_54_0001] epoch #25 | Computing KL after
2019-10-09 10:59:16 | [experiment_2019_10_09_10_58_54_0001] epoch #25 | Computing loss after
2019-10-09 10:59:16 | [experiment_2019_10_09_10_58_54_0001] epoch #25 | Fitting baseline...
2019-10-09 10:59:16 | [experiment_2019_10_09_10_58_54_0001] epoch #25 | Saving snapshot...
2019-10-09 10:59:16 | [experiment_2019_10_09_10_58_54_0001] epoch #25 | Saved
2019-10-09 10:59:16 | [experiment_2019_10_09_10_58_54_0001] epoch #25 | Time 17.39 s
2019-10-09 10:59:16 | [experiment_2019_10_09_10_58_54_0001] epoch #25 | EpochTime 0.59 s
---------------------------------------  -------------
AverageDiscountedReturn                   63.3968
AverageReturn                            100
Entropy                                    0.576635
EnvExecTime                                0.0509391
Extras/EpisodeRewardMean                 100
Iteration                                 25
LinearFeatureBaseline/ExplainedVariance    1
MaxReturn                                100
MinReturn                                100
NumTrajs                                  40
Perplexity                                 1.78004
PolicyExecTime                             0.367711
ProcessExecTime                            0.0176849
StdReturn                                  0
policy/Entropy                             0.57911
policy/KL                                  0.00687754
policy/KLBefore                            0
policy/LossAfter                          -0.00679873
policy/LossBefore                          1.54972e-08
policy/dLoss                               0.00679875
---------------------------------------  -------------
2019-10-09 10:59:16 | [experiment_2019_10_09_10_58_54_0001] epoch #26 | Obtaining samples...
2019-10-09 10:59:16 | [experiment_2019_10_09_10_58_54_0001] epoch #26 | Obtaining samples for iteration 26...
2019-10-09 10:59:16 | [experiment_2019_10_09_10_58_54_0001] epoch #26 | Logging diagnostics...
2019-10-09 10:59:16 | [experiment_2019_10_09_10_58_54_0001] epoch #26 | Optimizing policy...
2019-10-09 10:59:16 | [experiment_2019_10_09_10_58_54_0001] epoch #26 | Computing loss before
2019-10-09 10:59:16 | [experiment_2019_10_09_10_58_54_0001] epoch #26 | Computing KL before
2019-10-09 10:59:16 | [experiment_2019_10_09_10_58_54_0001] epoch #26 | Optimizing
2019-10-09 10:59:16 | [experiment_2019_10_09_10_58_54_0001] epoch #26 | Start CG optimization: #parameters: 1282, #inputs: 40, #subsample_inputs: 40
2019-10-09 10:59:16 | [experiment_2019_10_09_10_58_54_0001] epoch #26 | computing loss before
2019-10-09 10:59:16 | [experiment_2019_10_09_10_58_54_0001] epoch #26 | performing update
2019-10-09 10:59:16 | [experiment_2019_10_09_10_58_54_0001] epoch #26 | computing gradient
2019-10-09 10:59:16 | [experiment_2019_10_09_10_58_54_0001] epoch #26 | gradient computed
2019-10-09 10:59:16 | [experiment_2019_10_09_10_58_54_0001] epoch #26 | computing descent direction
2019-10-09 10:59:17 | [experiment_2019_10_09_10_58_54_0001] epoch #26 | descent direction computed
2019-10-09 10:59:17 | [experiment_2019_10_09_10_58_54_0001] epoch #26 | backtrack iters: 1
2019-10-09 10:59:17 | [experiment_2019_10_09_10_58_54_0001] epoch #26 | computing loss after
2019-10-09 10:59:17 | [experiment_2019_10_09_10_58_54_0001] epoch #26 | optimization finished
2019-10-09 10:59:17 | [experiment_2019_10_09_10_58_54_0001] epoch #26 | Computing KL after
2019-10-09 10:59:17 | [experiment_2019_10_09_10_58_54_0001] epoch #26 | Computing loss after
2019-10-09 10:59:17 | [experiment_2019_10_09_10_58_54_0001] epoch #26 | Fitting baseline...
2019-10-09 10:59:17 | [experiment_2019_10_09_10_58_54_0001] epoch #26 | Saving snapshot...
2019-10-09 10:59:17 | [experiment_2019_10_09_10_58_54_0001] epoch #26 | Saved
2019-10-09 10:59:17 | [experiment_2019_10_09_10_58_54_0001] epoch #26 | Time 17.96 s
2019-10-09 10:59:17 | [experiment_2019_10_09_10_58_54_0001] epoch #26 | EpochTime 0.57 s
---------------------------------------  -------------
AverageDiscountedReturn                   63.3968
AverageReturn                            100
Entropy                                    0.568192
EnvExecTime                                0.0505307
Extras/EpisodeRewardMean                 100
Iteration                                 26
LinearFeatureBaseline/ExplainedVariance    1
MaxReturn                                100
MinReturn                                100
NumTrajs                                  40
Perplexity                                 1.76507
PolicyExecTime                             0.355041
ProcessExecTime                            0.0176888
StdReturn                                  0
policy/Entropy                             0.573462
policy/KL                                  0.00658032
policy/KLBefore                            0
policy/LossAfter                          -0.00551017
policy/LossBefore                         -8.34465e-09
policy/dLoss                               0.00551016
---------------------------------------  -------------
2019-10-09 10:59:17 | [experiment_2019_10_09_10_58_54_0001] epoch #27 | Obtaining samples...
2019-10-09 10:59:17 | [experiment_2019_10_09_10_58_54_0001] epoch #27 | Obtaining samples for iteration 27...
2019-10-09 10:59:17 | [experiment_2019_10_09_10_58_54_0001] epoch #27 | Logging diagnostics...
2019-10-09 10:59:17 | [experiment_2019_10_09_10_58_54_0001] epoch #27 | Optimizing policy...
2019-10-09 10:59:17 | [experiment_2019_10_09_10_58_54_0001] epoch #27 | Computing loss before
2019-10-09 10:59:17 | [experiment_2019_10_09_10_58_54_0001] epoch #27 | Computing KL before
2019-10-09 10:59:17 | [experiment_2019_10_09_10_58_54_0001] epoch #27 | Optimizing
2019-10-09 10:59:17 | [experiment_2019_10_09_10_58_54_0001] epoch #27 | Start CG optimization: #parameters: 1282, #inputs: 40, #subsample_inputs: 40
2019-10-09 10:59:17 | [experiment_2019_10_09_10_58_54_0001] epoch #27 | computing loss before
2019-10-09 10:59:17 | [experiment_2019_10_09_10_58_54_0001] epoch #27 | performing update
2019-10-09 10:59:17 | [experiment_2019_10_09_10_58_54_0001] epoch #27 | computing gradient
2019-10-09 10:59:17 | [experiment_2019_10_09_10_58_54_0001] epoch #27 | gradient computed
2019-10-09 10:59:17 | [experiment_2019_10_09_10_58_54_0001] epoch #27 | computing descent direction
2019-10-09 10:59:17 | [experiment_2019_10_09_10_58_54_0001] epoch #27 | descent direction computed
2019-10-09 10:59:17 | [experiment_2019_10_09_10_58_54_0001] epoch #27 | backtrack iters: 0
2019-10-09 10:59:17 | [experiment_2019_10_09_10_58_54_0001] epoch #27 | computing loss after
2019-10-09 10:59:17 | [experiment_2019_10_09_10_58_54_0001] epoch #27 | optimization finished
2019-10-09 10:59:17 | [experiment_2019_10_09_10_58_54_0001] epoch #27 | Computing KL after
2019-10-09 10:59:17 | [experiment_2019_10_09_10_58_54_0001] epoch #27 | Computing loss after
2019-10-09 10:59:17 | [experiment_2019_10_09_10_58_54_0001] epoch #27 | Fitting baseline...
2019-10-09 10:59:17 | [experiment_2019_10_09_10_58_54_0001] epoch #27 | Saving snapshot...
2019-10-09 10:59:17 | [experiment_2019_10_09_10_58_54_0001] epoch #27 | Saved
2019-10-09 10:59:17 | [experiment_2019_10_09_10_58_54_0001] epoch #27 | Time 18.55 s
2019-10-09 10:59:17 | [experiment_2019_10_09_10_58_54_0001] epoch #27 | EpochTime 0.59 s
---------------------------------------  -------------
AverageDiscountedReturn                   63.3968
AverageReturn                            100
Entropy                                    0.580587
EnvExecTime                                0.0539072
Extras/EpisodeRewardMean                 100
Iteration                                 27
LinearFeatureBaseline/ExplainedVariance    1
MaxReturn                                100
MinReturn                                100
NumTrajs                                  40
Perplexity                                 1.78709
PolicyExecTime                             0.373886
ProcessExecTime                            0.0190747
StdReturn                                  0
policy/Entropy                             0.575312
policy/KL                                  0.00571642
policy/KLBefore                            0
policy/LossAfter                          -0.00302164
policy/LossBefore                         -8.34465e-09
policy/dLoss                               0.00302163
---------------------------------------  -------------
2019-10-09 10:59:17 | [experiment_2019_10_09_10_58_54_0001] epoch #28 | Obtaining samples...
2019-10-09 10:59:17 | [experiment_2019_10_09_10_58_54_0001] epoch #28 | Obtaining samples for iteration 28...
2019-10-09 10:59:18 | [experiment_2019_10_09_10_58_54_0001] epoch #28 | Logging diagnostics...
2019-10-09 10:59:18 | [experiment_2019_10_09_10_58_54_0001] epoch #28 | Optimizing policy...
2019-10-09 10:59:18 | [experiment_2019_10_09_10_58_54_0001] epoch #28 | Computing loss before
2019-10-09 10:59:18 | [experiment_2019_10_09_10_58_54_0001] epoch #28 | Computing KL before
2019-10-09 10:59:18 | [experiment_2019_10_09_10_58_54_0001] epoch #28 | Optimizing
2019-10-09 10:59:18 | [experiment_2019_10_09_10_58_54_0001] epoch #28 | Start CG optimization: #parameters: 1282, #inputs: 40, #subsample_inputs: 40
2019-10-09 10:59:18 | [experiment_2019_10_09_10_58_54_0001] epoch #28 | computing loss before
2019-10-09 10:59:18 | [experiment_2019_10_09_10_58_54_0001] epoch #28 | performing update
2019-10-09 10:59:18 | [experiment_2019_10_09_10_58_54_0001] epoch #28 | computing gradient
2019-10-09 10:59:18 | [experiment_2019_10_09_10_58_54_0001] epoch #28 | gradient computed
2019-10-09 10:59:18 | [experiment_2019_10_09_10_58_54_0001] epoch #28 | computing descent direction
2019-10-09 10:59:18 | [experiment_2019_10_09_10_58_54_0001] epoch #28 | descent direction computed
2019-10-09 10:59:18 | [experiment_2019_10_09_10_58_54_0001] epoch #28 | backtrack iters: 1
2019-10-09 10:59:18 | [experiment_2019_10_09_10_58_54_0001] epoch #28 | computing loss after
2019-10-09 10:59:18 | [experiment_2019_10_09_10_58_54_0001] epoch #28 | optimization finished
2019-10-09 10:59:18 | [experiment_2019_10_09_10_58_54_0001] epoch #28 | Computing KL after
2019-10-09 10:59:18 | [experiment_2019_10_09_10_58_54_0001] epoch #28 | Computing loss after
2019-10-09 10:59:18 | [experiment_2019_10_09_10_58_54_0001] epoch #28 | Fitting baseline...
2019-10-09 10:59:18 | [experiment_2019_10_09_10_58_54_0001] epoch #28 | Saving snapshot...
2019-10-09 10:59:18 | [experiment_2019_10_09_10_58_54_0001] epoch #28 | Saved
2019-10-09 10:59:18 | [experiment_2019_10_09_10_58_54_0001] epoch #28 | Time 19.17 s
2019-10-09 10:59:18 | [experiment_2019_10_09_10_58_54_0001] epoch #28 | EpochTime 0.61 s
---------------------------------------  -------------
AverageDiscountedReturn                   63.3968
AverageReturn                            100
Entropy                                    0.581268
EnvExecTime                                0.0564277
Extras/EpisodeRewardMean                 100
Iteration                                 28
LinearFeatureBaseline/ExplainedVariance    1
MaxReturn                                100
MinReturn                                100
NumTrajs                                  40
Perplexity                                 1.7883
PolicyExecTime                             0.38305
ProcessExecTime                            0.0204971
StdReturn                                  0
policy/Entropy                             0.56396
policy/KL                                  0.00913795
policy/KLBefore                            0
policy/LossAfter                          -0.00400035
policy/LossBefore                          6.67572e-09
policy/dLoss                               0.00400036
---------------------------------------  -------------
2019-10-09 10:59:18 | [experiment_2019_10_09_10_58_54_0001] epoch #29 | Obtaining samples...
2019-10-09 10:59:18 | [experiment_2019_10_09_10_58_54_0001] epoch #29 | Obtaining samples for iteration 29...
2019-10-09 10:59:18 | [experiment_2019_10_09_10_58_54_0001] epoch #29 | Logging diagnostics...
2019-10-09 10:59:18 | [experiment_2019_10_09_10_58_54_0001] epoch #29 | Optimizing policy...
2019-10-09 10:59:18 | [experiment_2019_10_09_10_58_54_0001] epoch #29 | Computing loss before
2019-10-09 10:59:18 | [experiment_2019_10_09_10_58_54_0001] epoch #29 | Computing KL before
2019-10-09 10:59:18 | [experiment_2019_10_09_10_58_54_0001] epoch #29 | Optimizing
2019-10-09 10:59:18 | [experiment_2019_10_09_10_58_54_0001] epoch #29 | Start CG optimization: #parameters: 1282, #inputs: 41, #subsample_inputs: 41
2019-10-09 10:59:18 | [experiment_2019_10_09_10_58_54_0001] epoch #29 | computing loss before
2019-10-09 10:59:18 | [experiment_2019_10_09_10_58_54_0001] epoch #29 | performing update
2019-10-09 10:59:18 | [experiment_2019_10_09_10_58_54_0001] epoch #29 | computing gradient
2019-10-09 10:59:18 | [experiment_2019_10_09_10_58_54_0001] epoch #29 | gradient computed
2019-10-09 10:59:18 | [experiment_2019_10_09_10_58_54_0001] epoch #29 | computing descent direction
2019-10-09 10:59:18 | [experiment_2019_10_09_10_58_54_0001] epoch #29 | descent direction computed
2019-10-09 10:59:18 | [experiment_2019_10_09_10_58_54_0001] epoch #29 | backtrack iters: 5
2019-10-09 10:59:18 | [experiment_2019_10_09_10_58_54_0001] epoch #29 | computing loss after
2019-10-09 10:59:18 | [experiment_2019_10_09_10_58_54_0001] epoch #29 | optimization finished
2019-10-09 10:59:18 | [experiment_2019_10_09_10_58_54_0001] epoch #29 | Computing KL after
2019-10-09 10:59:18 | [experiment_2019_10_09_10_58_54_0001] epoch #29 | Computing loss after
2019-10-09 10:59:18 | [experiment_2019_10_09_10_58_54_0001] epoch #29 | Fitting baseline...
2019-10-09 10:59:18 | [experiment_2019_10_09_10_58_54_0001] epoch #29 | Saving snapshot...
2019-10-09 10:59:18 | [experiment_2019_10_09_10_58_54_0001] epoch #29 | Saved
2019-10-09 10:59:18 | [experiment_2019_10_09_10_58_54_0001] epoch #29 | Time 19.78 s
2019-10-09 10:59:18 | [experiment_2019_10_09_10_58_54_0001] epoch #29 | EpochTime 0.61 s
---------------------------------------  -------------
AverageDiscountedReturn                   62.6579
AverageReturn                             98.5366
Entropy                                    0.572517
EnvExecTime                                0.0519834
Extras/EpisodeRewardMean                  99.4
Iteration                                 29
LinearFeatureBaseline/ExplainedVariance    0.958231
MaxReturn                                100
MinReturn                                 40
NumTrajs                                  41
Perplexity                                 1.77272
PolicyExecTime                             0.370289
ProcessExecTime                            0.0183556
StdReturn                                  9.25545
policy/Entropy                             0.569299
policy/KL                                  0.00709318
policy/KLBefore                            3.46834e-10
policy/LossAfter                          -0.00912199
policy/LossBefore                          1.11537e-08
policy/dLoss                               0.00912201
---------------------------------------  -------------
2019-10-09 10:59:18 | [experiment_2019_10_09_10_58_54_0001] epoch #30 | Obtaining samples...
2019-10-09 10:59:18 | [experiment_2019_10_09_10_58_54_0001] epoch #30 | Obtaining samples for iteration 30...
2019-10-09 10:59:19 | [experiment_2019_10_09_10_58_54_0001] epoch #30 | Logging diagnostics...
2019-10-09 10:59:19 | [experiment_2019_10_09_10_58_54_0001] epoch #30 | Optimizing policy...
2019-10-09 10:59:19 | [experiment_2019_10_09_10_58_54_0001] epoch #30 | Computing loss before
2019-10-09 10:59:19 | [experiment_2019_10_09_10_58_54_0001] epoch #30 | Computing KL before
2019-10-09 10:59:19 | [experiment_2019_10_09_10_58_54_0001] epoch #30 | Optimizing
2019-10-09 10:59:19 | [experiment_2019_10_09_10_58_54_0001] epoch #30 | Start CG optimization: #parameters: 1282, #inputs: 41, #subsample_inputs: 41
2019-10-09 10:59:19 | [experiment_2019_10_09_10_58_54_0001] epoch #30 | computing loss before
2019-10-09 10:59:19 | [experiment_2019_10_09_10_58_54_0001] epoch #30 | performing update
2019-10-09 10:59:19 | [experiment_2019_10_09_10_58_54_0001] epoch #30 | computing gradient
2019-10-09 10:59:19 | [experiment_2019_10_09_10_58_54_0001] epoch #30 | gradient computed
2019-10-09 10:59:19 | [experiment_2019_10_09_10_58_54_0001] epoch #30 | computing descent direction
2019-10-09 10:59:19 | [experiment_2019_10_09_10_58_54_0001] epoch #30 | descent direction computed
2019-10-09 10:59:19 | [experiment_2019_10_09_10_58_54_0001] epoch #30 | backtrack iters: 3
2019-10-09 10:59:19 | [experiment_2019_10_09_10_58_54_0001] epoch #30 | computing loss after
2019-10-09 10:59:19 | [experiment_2019_10_09_10_58_54_0001] epoch #30 | optimization finished
2019-10-09 10:59:19 | [experiment_2019_10_09_10_58_54_0001] epoch #30 | Computing KL after
2019-10-09 10:59:19 | [experiment_2019_10_09_10_58_54_0001] epoch #30 | Computing loss after
2019-10-09 10:59:19 | [experiment_2019_10_09_10_58_54_0001] epoch #30 | Fitting baseline...
2019-10-09 10:59:19 | [experiment_2019_10_09_10_58_54_0001] epoch #30 | Saving snapshot...
2019-10-09 10:59:19 | [experiment_2019_10_09_10_58_54_0001] epoch #30 | Saved
2019-10-09 10:59:19 | [experiment_2019_10_09_10_58_54_0001] epoch #30 | Time 20.51 s
2019-10-09 10:59:19 | [experiment_2019_10_09_10_58_54_0001] epoch #30 | EpochTime 0.72 s
---------------------------------------  -------------
AverageDiscountedReturn                   63.1066
AverageReturn                             99.3171
Entropy                                    0.571451
EnvExecTime                                0.0595298
Extras/EpisodeRewardMean                  99.12
Iteration                                 30
LinearFeatureBaseline/ExplainedVariance    0.981452
MaxReturn                                100
MinReturn                                 72
NumTrajs                                  41
Perplexity                                 1.77083
PolicyExecTime                             0.46942
ProcessExecTime                            0.0214703
StdReturn                                  4.31921
policy/Entropy                             0.555901
policy/KL                                  0.00563961
policy/KLBefore                            9.9303e-11
policy/LossAfter                          -0.00664722
policy/LossBefore                          6.30884e-09
policy/dLoss                               0.00664723
---------------------------------------  -------------
2019-10-09 10:59:19 | [experiment_2019_10_09_10_58_54_0001] epoch #31 | Obtaining samples...
2019-10-09 10:59:19 | [experiment_2019_10_09_10_58_54_0001] epoch #31 | Obtaining samples for iteration 31...
2019-10-09 10:59:20 | [experiment_2019_10_09_10_58_54_0001] epoch #31 | Logging diagnostics...
2019-10-09 10:59:20 | [experiment_2019_10_09_10_58_54_0001] epoch #31 | Optimizing policy...
2019-10-09 10:59:20 | [experiment_2019_10_09_10_58_54_0001] epoch #31 | Computing loss before
2019-10-09 10:59:20 | [experiment_2019_10_09_10_58_54_0001] epoch #31 | Computing KL before
2019-10-09 10:59:20 | [experiment_2019_10_09_10_58_54_0001] epoch #31 | Optimizing
2019-10-09 10:59:20 | [experiment_2019_10_09_10_58_54_0001] epoch #31 | Start CG optimization: #parameters: 1282, #inputs: 40, #subsample_inputs: 40
2019-10-09 10:59:20 | [experiment_2019_10_09_10_58_54_0001] epoch #31 | computing loss before
2019-10-09 10:59:20 | [experiment_2019_10_09_10_58_54_0001] epoch #31 | performing update
2019-10-09 10:59:20 | [experiment_2019_10_09_10_58_54_0001] epoch #31 | computing gradient
2019-10-09 10:59:20 | [experiment_2019_10_09_10_58_54_0001] epoch #31 | gradient computed
2019-10-09 10:59:20 | [experiment_2019_10_09_10_58_54_0001] epoch #31 | computing descent direction
2019-10-09 10:59:20 | [experiment_2019_10_09_10_58_54_0001] epoch #31 | descent direction computed
2019-10-09 10:59:20 | [experiment_2019_10_09_10_58_54_0001] epoch #31 | backtrack iters: 2
2019-10-09 10:59:20 | [experiment_2019_10_09_10_58_54_0001] epoch #31 | computing loss after
2019-10-09 10:59:20 | [experiment_2019_10_09_10_58_54_0001] epoch #31 | optimization finished
2019-10-09 10:59:20 | [experiment_2019_10_09_10_58_54_0001] epoch #31 | Computing KL after
2019-10-09 10:59:20 | [experiment_2019_10_09_10_58_54_0001] epoch #31 | Computing loss after
2019-10-09 10:59:20 | [experiment_2019_10_09_10_58_54_0001] epoch #31 | Fitting baseline...
2019-10-09 10:59:20 | [experiment_2019_10_09_10_58_54_0001] epoch #31 | Saving snapshot...
2019-10-09 10:59:20 | [experiment_2019_10_09_10_58_54_0001] epoch #31 | Saved
2019-10-09 10:59:20 | [experiment_2019_10_09_10_58_54_0001] epoch #31 | Time 21.11 s
2019-10-09 10:59:20 | [experiment_2019_10_09_10_58_54_0001] epoch #31 | EpochTime 0.59 s
---------------------------------------  -------------
AverageDiscountedReturn                   63.3968
AverageReturn                            100
Entropy                                    0.56886
EnvExecTime                                0.0529621
Extras/EpisodeRewardMean                  99.12
Iteration                                 31
LinearFeatureBaseline/ExplainedVariance    0.999122
MaxReturn                                100
MinReturn                                100
NumTrajs                                  40
Perplexity                                 1.76625
PolicyExecTime                             0.369356
ProcessExecTime                            0.0192516
StdReturn                                  0
policy/Entropy                             0.530098
policy/KL                                  0.0095866
policy/KLBefore                            0
policy/LossAfter                          -0.00456832
policy/LossBefore                          1.19209e-08
policy/dLoss                               0.00456833
---------------------------------------  -------------
2019-10-09 10:59:20 | [experiment_2019_10_09_10_58_54_0001] epoch #32 | Obtaining samples...
2019-10-09 10:59:20 | [experiment_2019_10_09_10_58_54_0001] epoch #32 | Obtaining samples for iteration 32...
2019-10-09 10:59:20 | [experiment_2019_10_09_10_58_54_0001] epoch #32 | Logging diagnostics...
2019-10-09 10:59:20 | [experiment_2019_10_09_10_58_54_0001] epoch #32 | Optimizing policy...
2019-10-09 10:59:20 | [experiment_2019_10_09_10_58_54_0001] epoch #32 | Computing loss before
2019-10-09 10:59:20 | [experiment_2019_10_09_10_58_54_0001] epoch #32 | Computing KL before
2019-10-09 10:59:20 | [experiment_2019_10_09_10_58_54_0001] epoch #32 | Optimizing
2019-10-09 10:59:20 | [experiment_2019_10_09_10_58_54_0001] epoch #32 | Start CG optimization: #parameters: 1282, #inputs: 40, #subsample_inputs: 40
2019-10-09 10:59:20 | [experiment_2019_10_09_10_58_54_0001] epoch #32 | computing loss before
2019-10-09 10:59:20 | [experiment_2019_10_09_10_58_54_0001] epoch #32 | performing update
2019-10-09 10:59:20 | [experiment_2019_10_09_10_58_54_0001] epoch #32 | computing gradient
2019-10-09 10:59:20 | [experiment_2019_10_09_10_58_54_0001] epoch #32 | gradient computed
2019-10-09 10:59:20 | [experiment_2019_10_09_10_58_54_0001] epoch #32 | computing descent direction
2019-10-09 10:59:20 | [experiment_2019_10_09_10_58_54_0001] epoch #32 | descent direction computed
2019-10-09 10:59:20 | [experiment_2019_10_09_10_58_54_0001] epoch #32 | backtrack iters: 2
2019-10-09 10:59:20 | [experiment_2019_10_09_10_58_54_0001] epoch #32 | computing loss after
2019-10-09 10:59:20 | [experiment_2019_10_09_10_58_54_0001] epoch #32 | optimization finished
2019-10-09 10:59:20 | [experiment_2019_10_09_10_58_54_0001] epoch #32 | Computing KL after
2019-10-09 10:59:20 | [experiment_2019_10_09_10_58_54_0001] epoch #32 | Computing loss after
2019-10-09 10:59:20 | [experiment_2019_10_09_10_58_54_0001] epoch #32 | Fitting baseline...
2019-10-09 10:59:20 | [experiment_2019_10_09_10_58_54_0001] epoch #32 | Saving snapshot...
2019-10-09 10:59:20 | [experiment_2019_10_09_10_58_54_0001] epoch #32 | Saved
2019-10-09 10:59:20 | [experiment_2019_10_09_10_58_54_0001] epoch #32 | Time 21.69 s
2019-10-09 10:59:20 | [experiment_2019_10_09_10_58_54_0001] epoch #32 | EpochTime 0.58 s
---------------------------------------  -------------
AverageDiscountedReturn                   63.3968
AverageReturn                            100
Entropy                                    0.555174
EnvExecTime                                0.0502341
Extras/EpisodeRewardMean                  99.72
Iteration                                 32
LinearFeatureBaseline/ExplainedVariance    1
MaxReturn                                100
MinReturn                                100
NumTrajs                                  40
Perplexity                                 1.74224
PolicyExecTime                             0.354294
ProcessExecTime                            0.0178254
StdReturn                                  0
policy/Entropy                             0.536588
policy/KL                                  0.00744367
policy/KLBefore                            0
policy/LossAfter                          -0.00647189
policy/LossBefore                          1.19209e-09
policy/dLoss                               0.00647189
---------------------------------------  -------------
2019-10-09 10:59:20 | [experiment_2019_10_09_10_58_54_0001] epoch #33 | Obtaining samples...
2019-10-09 10:59:20 | [experiment_2019_10_09_10_58_54_0001] epoch #33 | Obtaining samples for iteration 33...
2019-10-09 10:59:21 | [experiment_2019_10_09_10_58_54_0001] epoch #33 | Logging diagnostics...
2019-10-09 10:59:21 | [experiment_2019_10_09_10_58_54_0001] epoch #33 | Optimizing policy...
2019-10-09 10:59:21 | [experiment_2019_10_09_10_58_54_0001] epoch #33 | Computing loss before
2019-10-09 10:59:21 | [experiment_2019_10_09_10_58_54_0001] epoch #33 | Computing KL before
2019-10-09 10:59:21 | [experiment_2019_10_09_10_58_54_0001] epoch #33 | Optimizing
2019-10-09 10:59:21 | [experiment_2019_10_09_10_58_54_0001] epoch #33 | Start CG optimization: #parameters: 1282, #inputs: 41, #subsample_inputs: 41
2019-10-09 10:59:21 | [experiment_2019_10_09_10_58_54_0001] epoch #33 | computing loss before
2019-10-09 10:59:21 | [experiment_2019_10_09_10_58_54_0001] epoch #33 | performing update
2019-10-09 10:59:21 | [experiment_2019_10_09_10_58_54_0001] epoch #33 | computing gradient
2019-10-09 10:59:21 | [experiment_2019_10_09_10_58_54_0001] epoch #33 | gradient computed
2019-10-09 10:59:21 | [experiment_2019_10_09_10_58_54_0001] epoch #33 | computing descent direction
2019-10-09 10:59:21 | [experiment_2019_10_09_10_58_54_0001] epoch #33 | descent direction computed
2019-10-09 10:59:21 | [experiment_2019_10_09_10_58_54_0001] epoch #33 | backtrack iters: 4
2019-10-09 10:59:21 | [experiment_2019_10_09_10_58_54_0001] epoch #33 | computing loss after
2019-10-09 10:59:21 | [experiment_2019_10_09_10_58_54_0001] epoch #33 | optimization finished
2019-10-09 10:59:21 | [experiment_2019_10_09_10_58_54_0001] epoch #33 | Computing KL after
2019-10-09 10:59:21 | [experiment_2019_10_09_10_58_54_0001] epoch #33 | Computing loss after
2019-10-09 10:59:21 | [experiment_2019_10_09_10_58_54_0001] epoch #33 | Fitting baseline...
2019-10-09 10:59:21 | [experiment_2019_10_09_10_58_54_0001] epoch #33 | Saving snapshot...
2019-10-09 10:59:21 | [experiment_2019_10_09_10_58_54_0001] epoch #33 | Saved
2019-10-09 10:59:21 | [experiment_2019_10_09_10_58_54_0001] epoch #33 | Time 22.32 s
2019-10-09 10:59:21 | [experiment_2019_10_09_10_58_54_0001] epoch #33 | EpochTime 0.62 s
---------------------------------------  -------------
AverageDiscountedReturn                   62.9704
AverageReturn                             98.9268
Entropy                                    0.54163
EnvExecTime                                0.053992
Extras/EpisodeRewardMean                  99.56
Iteration                                 33
LinearFeatureBaseline/ExplainedVariance    0.983402
MaxReturn                                100
MinReturn                                 82
NumTrajs                                  41
Perplexity                                 1.71881
PolicyExecTime                             0.382811
ProcessExecTime                            0.0190861
StdReturn                                  3.87859
policy/Entropy                             0.555087
policy/KL                                  0.00943711
policy/KLBefore                            4.66236e-11
policy/LossAfter                          -0.00474856
policy/LossBefore                         -1.96331e-08
policy/dLoss                               0.00474854
---------------------------------------  -------------
2019-10-09 10:59:21 | [experiment_2019_10_09_10_58_54_0001] epoch #34 | Obtaining samples...
2019-10-09 10:59:21 | [experiment_2019_10_09_10_58_54_0001] epoch #34 | Obtaining samples for iteration 34...
2019-10-09 10:59:21 | [experiment_2019_10_09_10_58_54_0001] epoch #34 | Logging diagnostics...
2019-10-09 10:59:21 | [experiment_2019_10_09_10_58_54_0001] epoch #34 | Optimizing policy...
2019-10-09 10:59:21 | [experiment_2019_10_09_10_58_54_0001] epoch #34 | Computing loss before
2019-10-09 10:59:21 | [experiment_2019_10_09_10_58_54_0001] epoch #34 | Computing KL before
2019-10-09 10:59:21 | [experiment_2019_10_09_10_58_54_0001] epoch #34 | Optimizing
2019-10-09 10:59:21 | [experiment_2019_10_09_10_58_54_0001] epoch #34 | Start CG optimization: #parameters: 1282, #inputs: 41, #subsample_inputs: 41
2019-10-09 10:59:21 | [experiment_2019_10_09_10_58_54_0001] epoch #34 | computing loss before
2019-10-09 10:59:21 | [experiment_2019_10_09_10_58_54_0001] epoch #34 | performing update
2019-10-09 10:59:21 | [experiment_2019_10_09_10_58_54_0001] epoch #34 | computing gradient
2019-10-09 10:59:21 | [experiment_2019_10_09_10_58_54_0001] epoch #34 | gradient computed
2019-10-09 10:59:21 | [experiment_2019_10_09_10_58_54_0001] epoch #34 | computing descent direction
2019-10-09 10:59:22 | [experiment_2019_10_09_10_58_54_0001] epoch #34 | descent direction computed
2019-10-09 10:59:22 | [experiment_2019_10_09_10_58_54_0001] epoch #34 | backtrack iters: 1
2019-10-09 10:59:22 | [experiment_2019_10_09_10_58_54_0001] epoch #34 | computing loss after
2019-10-09 10:59:22 | [experiment_2019_10_09_10_58_54_0001] epoch #34 | optimization finished
2019-10-09 10:59:22 | [experiment_2019_10_09_10_58_54_0001] epoch #34 | Computing KL after
2019-10-09 10:59:22 | [experiment_2019_10_09_10_58_54_0001] epoch #34 | Computing loss after
2019-10-09 10:59:22 | [experiment_2019_10_09_10_58_54_0001] epoch #34 | Fitting baseline...
2019-10-09 10:59:22 | [experiment_2019_10_09_10_58_54_0001] epoch #34 | Saving snapshot...
2019-10-09 10:59:22 | [experiment_2019_10_09_10_58_54_0001] epoch #34 | Saved
2019-10-09 10:59:22 | [experiment_2019_10_09_10_58_54_0001] epoch #34 | Time 22.96 s
2019-10-09 10:59:22 | [experiment_2019_10_09_10_58_54_0001] epoch #34 | EpochTime 0.64 s
---------------------------------------  -------------
AverageDiscountedReturn                   63.1166
AverageReturn                             99.2927
Entropy                                    0.552271
EnvExecTime                                0.054302
Extras/EpisodeRewardMean                  99.27
Iteration                                 34
LinearFeatureBaseline/ExplainedVariance    0.988699
MaxReturn                                100
MinReturn                                 85
NumTrajs                                  41
Perplexity                                 1.73719
PolicyExecTime                             0.407161
ProcessExecTime                            0.0187876
StdReturn                                  3.12538
policy/Entropy                             0.548725
policy/KL                                  0.00627872
policy/KLBefore                           -1.15517e-10
policy/LossAfter                          -0.0172291
policy/LossBefore                          3.23279e-08
policy/dLoss                               0.0172292
---------------------------------------  -------------
2019-10-09 10:59:22 | [experiment_2019_10_09_10_58_54_0001] epoch #35 | Obtaining samples...
2019-10-09 10:59:22 | [experiment_2019_10_09_10_58_54_0001] epoch #35 | Obtaining samples for iteration 35...
2019-10-09 10:59:22 | [experiment_2019_10_09_10_58_54_0001] epoch #35 | Logging diagnostics...
2019-10-09 10:59:22 | [experiment_2019_10_09_10_58_54_0001] epoch #35 | Optimizing policy...
2019-10-09 10:59:22 | [experiment_2019_10_09_10_58_54_0001] epoch #35 | Computing loss before
2019-10-09 10:59:22 | [experiment_2019_10_09_10_58_54_0001] epoch #35 | Computing KL before
2019-10-09 10:59:22 | [experiment_2019_10_09_10_58_54_0001] epoch #35 | Optimizing
2019-10-09 10:59:22 | [experiment_2019_10_09_10_58_54_0001] epoch #35 | Start CG optimization: #parameters: 1282, #inputs: 40, #subsample_inputs: 40
2019-10-09 10:59:22 | [experiment_2019_10_09_10_58_54_0001] epoch #35 | computing loss before
2019-10-09 10:59:22 | [experiment_2019_10_09_10_58_54_0001] epoch #35 | performing update
2019-10-09 10:59:22 | [experiment_2019_10_09_10_58_54_0001] epoch #35 | computing gradient
2019-10-09 10:59:22 | [experiment_2019_10_09_10_58_54_0001] epoch #35 | gradient computed
2019-10-09 10:59:22 | [experiment_2019_10_09_10_58_54_0001] epoch #35 | computing descent direction
2019-10-09 10:59:22 | [experiment_2019_10_09_10_58_54_0001] epoch #35 | descent direction computed
2019-10-09 10:59:22 | [experiment_2019_10_09_10_58_54_0001] epoch #35 | backtrack iters: 1
2019-10-09 10:59:22 | [experiment_2019_10_09_10_58_54_0001] epoch #35 | computing loss after
2019-10-09 10:59:22 | [experiment_2019_10_09_10_58_54_0001] epoch #35 | optimization finished
2019-10-09 10:59:22 | [experiment_2019_10_09_10_58_54_0001] epoch #35 | Computing KL after
2019-10-09 10:59:22 | [experiment_2019_10_09_10_58_54_0001] epoch #35 | Computing loss after
2019-10-09 10:59:22 | [experiment_2019_10_09_10_58_54_0001] epoch #35 | Fitting baseline...
2019-10-09 10:59:22 | [experiment_2019_10_09_10_58_54_0001] epoch #35 | Saving snapshot...
2019-10-09 10:59:22 | [experiment_2019_10_09_10_58_54_0001] epoch #35 | Saved
2019-10-09 10:59:22 | [experiment_2019_10_09_10_58_54_0001] epoch #35 | Time 23.54 s
2019-10-09 10:59:22 | [experiment_2019_10_09_10_58_54_0001] epoch #35 | EpochTime 0.57 s
---------------------------------------  ------------
AverageDiscountedReturn                   63.3968
AverageReturn                            100
Entropy                                    0.55111
EnvExecTime                                0.0504272
Extras/EpisodeRewardMean                  99.39
Iteration                                 35
LinearFeatureBaseline/ExplainedVariance    0.998133
MaxReturn                                100
MinReturn                                100
NumTrajs                                  40
Perplexity                                 1.73518
PolicyExecTime                             0.357026
ProcessExecTime                            0.0183604
StdReturn                                  0
policy/Entropy                             0.510424
policy/KL                                  0.00777294
policy/KLBefore                            0
policy/LossAfter                          -0.00883015
policy/LossBefore                         -4.673e-08
policy/dLoss                               0.0088301
---------------------------------------  ------------
2019-10-09 10:59:22 | [experiment_2019_10_09_10_58_54_0001] epoch #36 | Obtaining samples...
2019-10-09 10:59:22 | [experiment_2019_10_09_10_58_54_0001] epoch #36 | Obtaining samples for iteration 36...
2019-10-09 10:59:23 | [experiment_2019_10_09_10_58_54_0001] epoch #36 | Logging diagnostics...
2019-10-09 10:59:23 | [experiment_2019_10_09_10_58_54_0001] epoch #36 | Optimizing policy...
2019-10-09 10:59:23 | [experiment_2019_10_09_10_58_54_0001] epoch #36 | Computing loss before
2019-10-09 10:59:23 | [experiment_2019_10_09_10_58_54_0001] epoch #36 | Computing KL before
2019-10-09 10:59:23 | [experiment_2019_10_09_10_58_54_0001] epoch #36 | Optimizing
2019-10-09 10:59:23 | [experiment_2019_10_09_10_58_54_0001] epoch #36 | Start CG optimization: #parameters: 1282, #inputs: 40, #subsample_inputs: 40
2019-10-09 10:59:23 | [experiment_2019_10_09_10_58_54_0001] epoch #36 | computing loss before
2019-10-09 10:59:23 | [experiment_2019_10_09_10_58_54_0001] epoch #36 | performing update
2019-10-09 10:59:23 | [experiment_2019_10_09_10_58_54_0001] epoch #36 | computing gradient
2019-10-09 10:59:23 | [experiment_2019_10_09_10_58_54_0001] epoch #36 | gradient computed
2019-10-09 10:59:23 | [experiment_2019_10_09_10_58_54_0001] epoch #36 | computing descent direction
2019-10-09 10:59:23 | [experiment_2019_10_09_10_58_54_0001] epoch #36 | descent direction computed
2019-10-09 10:59:23 | [experiment_2019_10_09_10_58_54_0001] epoch #36 | backtrack iters: 1
2019-10-09 10:59:23 | [experiment_2019_10_09_10_58_54_0001] epoch #36 | computing loss after
2019-10-09 10:59:23 | [experiment_2019_10_09_10_58_54_0001] epoch #36 | optimization finished
2019-10-09 10:59:23 | [experiment_2019_10_09_10_58_54_0001] epoch #36 | Computing KL after
2019-10-09 10:59:23 | [experiment_2019_10_09_10_58_54_0001] epoch #36 | Computing loss after
2019-10-09 10:59:23 | [experiment_2019_10_09_10_58_54_0001] epoch #36 | Fitting baseline...
2019-10-09 10:59:23 | [experiment_2019_10_09_10_58_54_0001] epoch #36 | Saving snapshot...
2019-10-09 10:59:23 | [experiment_2019_10_09_10_58_54_0001] epoch #36 | Saved
2019-10-09 10:59:23 | [experiment_2019_10_09_10_58_54_0001] epoch #36 | Time 24.11 s
2019-10-09 10:59:23 | [experiment_2019_10_09_10_58_54_0001] epoch #36 | EpochTime 0.57 s
---------------------------------------  -------------
AverageDiscountedReturn                   63.3968
AverageReturn                            100
Entropy                                    0.523702
EnvExecTime                                0.0502787
Extras/EpisodeRewardMean                  99.85
Iteration                                 36
LinearFeatureBaseline/ExplainedVariance    1
MaxReturn                                100
MinReturn                                100
NumTrajs                                  40
Perplexity                                 1.68827
PolicyExecTime                             0.347236
ProcessExecTime                            0.0174789
StdReturn                                  0
policy/Entropy                             0.531355
policy/KL                                  0.00877093
policy/KLBefore                            0
policy/LossAfter                          -0.00682408
policy/LossBefore                          5.72205e-09
policy/dLoss                               0.00682408
---------------------------------------  -------------
2019-10-09 10:59:23 | [experiment_2019_10_09_10_58_54_0001] epoch #37 | Obtaining samples...
2019-10-09 10:59:23 | [experiment_2019_10_09_10_58_54_0001] epoch #37 | Obtaining samples for iteration 37...
2019-10-09 10:59:23 | [experiment_2019_10_09_10_58_54_0001] epoch #37 | Logging diagnostics...
2019-10-09 10:59:23 | [experiment_2019_10_09_10_58_54_0001] epoch #37 | Optimizing policy...
2019-10-09 10:59:23 | [experiment_2019_10_09_10_58_54_0001] epoch #37 | Computing loss before
2019-10-09 10:59:23 | [experiment_2019_10_09_10_58_54_0001] epoch #37 | Computing KL before
2019-10-09 10:59:23 | [experiment_2019_10_09_10_58_54_0001] epoch #37 | Optimizing
2019-10-09 10:59:23 | [experiment_2019_10_09_10_58_54_0001] epoch #37 | Start CG optimization: #parameters: 1282, #inputs: 41, #subsample_inputs: 41
2019-10-09 10:59:23 | [experiment_2019_10_09_10_58_54_0001] epoch #37 | computing loss before
2019-10-09 10:59:23 | [experiment_2019_10_09_10_58_54_0001] epoch #37 | performing update
2019-10-09 10:59:23 | [experiment_2019_10_09_10_58_54_0001] epoch #37 | computing gradient
2019-10-09 10:59:23 | [experiment_2019_10_09_10_58_54_0001] epoch #37 | gradient computed
2019-10-09 10:59:23 | [experiment_2019_10_09_10_58_54_0001] epoch #37 | computing descent direction
2019-10-09 10:59:23 | [experiment_2019_10_09_10_58_54_0001] epoch #37 | descent direction computed
2019-10-09 10:59:23 | [experiment_2019_10_09_10_58_54_0001] epoch #37 | backtrack iters: 4
2019-10-09 10:59:23 | [experiment_2019_10_09_10_58_54_0001] epoch #37 | computing loss after
2019-10-09 10:59:23 | [experiment_2019_10_09_10_58_54_0001] epoch #37 | optimization finished
2019-10-09 10:59:23 | [experiment_2019_10_09_10_58_54_0001] epoch #37 | Computing KL after
2019-10-09 10:59:23 | [experiment_2019_10_09_10_58_54_0001] epoch #37 | Computing loss after
2019-10-09 10:59:23 | [experiment_2019_10_09_10_58_54_0001] epoch #37 | Fitting baseline...
2019-10-09 10:59:23 | [experiment_2019_10_09_10_58_54_0001] epoch #37 | Saving snapshot...
2019-10-09 10:59:23 | [experiment_2019_10_09_10_58_54_0001] epoch #37 | Saved
2019-10-09 10:59:23 | [experiment_2019_10_09_10_58_54_0001] epoch #37 | Time 24.76 s
2019-10-09 10:59:23 | [experiment_2019_10_09_10_58_54_0001] epoch #37 | EpochTime 0.64 s
---------------------------------------  -------------
AverageDiscountedReturn                   63.3786
AverageReturn                             99.9512
Entropy                                    0.528308
EnvExecTime                                0.0549722
Extras/EpisodeRewardMean                  99.98
Iteration                                 37
LinearFeatureBaseline/ExplainedVariance    0.999876
MaxReturn                                100
MinReturn                                 98
NumTrajs                                  41
Perplexity                                 1.69606
PolicyExecTime                             0.393185
ProcessExecTime                            0.0194297
StdReturn                                  0.308515
policy/Entropy                             0.534619
policy/KL                                  0.00871342
policy/KLBefore                           -2.90223e-11
policy/LossAfter                          -0.00621569
policy/LossBefore                          1.22176e-08
policy/dLoss                               0.0062157
---------------------------------------  -------------
2019-10-09 10:59:23 | [experiment_2019_10_09_10_58_54_0001] epoch #38 | Obtaining samples...
2019-10-09 10:59:23 | [experiment_2019_10_09_10_58_54_0001] epoch #38 | Obtaining samples for iteration 38...
2019-10-09 10:59:24 | [experiment_2019_10_09_10_58_54_0001] epoch #38 | Logging diagnostics...
2019-10-09 10:59:24 | [experiment_2019_10_09_10_58_54_0001] epoch #38 | Optimizing policy...
2019-10-09 10:59:24 | [experiment_2019_10_09_10_58_54_0001] epoch #38 | Computing loss before
2019-10-09 10:59:24 | [experiment_2019_10_09_10_58_54_0001] epoch #38 | Computing KL before
2019-10-09 10:59:24 | [experiment_2019_10_09_10_58_54_0001] epoch #38 | Optimizing
2019-10-09 10:59:24 | [experiment_2019_10_09_10_58_54_0001] epoch #38 | Start CG optimization: #parameters: 1282, #inputs: 40, #subsample_inputs: 40
2019-10-09 10:59:24 | [experiment_2019_10_09_10_58_54_0001] epoch #38 | computing loss before
2019-10-09 10:59:24 | [experiment_2019_10_09_10_58_54_0001] epoch #38 | performing update
2019-10-09 10:59:24 | [experiment_2019_10_09_10_58_54_0001] epoch #38 | computing gradient
2019-10-09 10:59:24 | [experiment_2019_10_09_10_58_54_0001] epoch #38 | gradient computed
2019-10-09 10:59:24 | [experiment_2019_10_09_10_58_54_0001] epoch #38 | computing descent direction
2019-10-09 10:59:24 | [experiment_2019_10_09_10_58_54_0001] epoch #38 | descent direction computed
2019-10-09 10:59:24 | [experiment_2019_10_09_10_58_54_0001] epoch #38 | backtrack iters: 0
2019-10-09 10:59:24 | [experiment_2019_10_09_10_58_54_0001] epoch #38 | computing loss after
2019-10-09 10:59:24 | [experiment_2019_10_09_10_58_54_0001] epoch #38 | optimization finished
2019-10-09 10:59:24 | [experiment_2019_10_09_10_58_54_0001] epoch #38 | Computing KL after
2019-10-09 10:59:24 | [experiment_2019_10_09_10_58_54_0001] epoch #38 | Computing loss after
2019-10-09 10:59:24 | [experiment_2019_10_09_10_58_54_0001] epoch #38 | Fitting baseline...
2019-10-09 10:59:24 | [experiment_2019_10_09_10_58_54_0001] epoch #38 | Saving snapshot...
2019-10-09 10:59:24 | [experiment_2019_10_09_10_58_54_0001] epoch #38 | Saved
2019-10-09 10:59:24 | [experiment_2019_10_09_10_58_54_0001] epoch #38 | Time 25.33 s
2019-10-09 10:59:24 | [experiment_2019_10_09_10_58_54_0001] epoch #38 | EpochTime 0.57 s
---------------------------------------  -------------
AverageDiscountedReturn                   63.3968
AverageReturn                            100
Entropy                                    0.524838
EnvExecTime                                0.0505905
Extras/EpisodeRewardMean                  99.98
Iteration                                 38
LinearFeatureBaseline/ExplainedVariance    0.999985
MaxReturn                                100
MinReturn                                100
NumTrajs                                  40
Perplexity                                 1.69019
PolicyExecTime                             0.35462
ProcessExecTime                            0.0180883
StdReturn                                  0
policy/Entropy                             0.515282
policy/KL                                  0.00712379
policy/KLBefore                            0
policy/LossAfter                          -0.012369
policy/LossBefore                          2.17557e-08
policy/dLoss                               0.012369
---------------------------------------  -------------
2019-10-09 10:59:24 | [experiment_2019_10_09_10_58_54_0001] epoch #39 | Obtaining samples...
2019-10-09 10:59:24 | [experiment_2019_10_09_10_58_54_0001] epoch #39 | Obtaining samples for iteration 39...
2019-10-09 10:59:24 | [experiment_2019_10_09_10_58_54_0001] epoch #39 | Logging diagnostics...
2019-10-09 10:59:24 | [experiment_2019_10_09_10_58_54_0001] epoch #39 | Optimizing policy...
2019-10-09 10:59:24 | [experiment_2019_10_09_10_58_54_0001] epoch #39 | Computing loss before
2019-10-09 10:59:24 | [experiment_2019_10_09_10_58_54_0001] epoch #39 | Computing KL before
2019-10-09 10:59:24 | [experiment_2019_10_09_10_58_54_0001] epoch #39 | Optimizing
2019-10-09 10:59:24 | [experiment_2019_10_09_10_58_54_0001] epoch #39 | Start CG optimization: #parameters: 1282, #inputs: 41, #subsample_inputs: 41
2019-10-09 10:59:24 | [experiment_2019_10_09_10_58_54_0001] epoch #39 | computing loss before
2019-10-09 10:59:24 | [experiment_2019_10_09_10_58_54_0001] epoch #39 | performing update
2019-10-09 10:59:24 | [experiment_2019_10_09_10_58_54_0001] epoch #39 | computing gradient
2019-10-09 10:59:24 | [experiment_2019_10_09_10_58_54_0001] epoch #39 | gradient computed
2019-10-09 10:59:24 | [experiment_2019_10_09_10_58_54_0001] epoch #39 | computing descent direction
2019-10-09 10:59:25 | [experiment_2019_10_09_10_58_54_0001] epoch #39 | descent direction computed
2019-10-09 10:59:25 | [experiment_2019_10_09_10_58_54_0001] epoch #39 | backtrack iters: 3
2019-10-09 10:59:25 | [experiment_2019_10_09_10_58_54_0001] epoch #39 | computing loss after
2019-10-09 10:59:25 | [experiment_2019_10_09_10_58_54_0001] epoch #39 | optimization finished
2019-10-09 10:59:25 | [experiment_2019_10_09_10_58_54_0001] epoch #39 | Computing KL after
2019-10-09 10:59:25 | [experiment_2019_10_09_10_58_54_0001] epoch #39 | Computing loss after
2019-10-09 10:59:25 | [experiment_2019_10_09_10_58_54_0001] epoch #39 | Fitting baseline...
2019-10-09 10:59:25 | [experiment_2019_10_09_10_58_54_0001] epoch #39 | Saving snapshot...
2019-10-09 10:59:25 | [experiment_2019_10_09_10_58_54_0001] epoch #39 | Saved
2019-10-09 10:59:25 | [experiment_2019_10_09_10_58_54_0001] epoch #39 | Time 25.98 s
2019-10-09 10:59:25 | [experiment_2019_10_09_10_58_54_0001] epoch #39 | EpochTime 0.64 s
---------------------------------------  -------------
AverageDiscountedReturn                   63.1997
AverageReturn                             99.4878
Entropy                                    0.524847
EnvExecTime                                0.0552132
Extras/EpisodeRewardMean                  99.77
Iteration                                 39
LinearFeatureBaseline/ExplainedVariance    0.99497
MaxReturn                                100
MinReturn                                 90
NumTrajs                                  41
Perplexity                                 1.6902
PolicyExecTime                             0.388021
ProcessExecTime                            0.019372
StdReturn                                  2.06152
policy/Entropy                             0.515159
policy/KL                                  0.00799442
policy/KLBefore                            1.0852e-10
policy/LossAfter                          -0.00925071
policy/LossBefore                          3.97462e-08
policy/dLoss                               0.00925075
---------------------------------------  -------------
2019-10-09 10:59:25 | [experiment_2019_10_09_10_58_54_0001] epoch #40 | Obtaining samples...
2019-10-09 10:59:25 | [experiment_2019_10_09_10_58_54_0001] epoch #40 | Obtaining samples for iteration 40...
2019-10-09 10:59:25 | [experiment_2019_10_09_10_58_54_0001] epoch #40 | Logging diagnostics...
2019-10-09 10:59:25 | [experiment_2019_10_09_10_58_54_0001] epoch #40 | Optimizing policy...
2019-10-09 10:59:25 | [experiment_2019_10_09_10_58_54_0001] epoch #40 | Computing loss before
2019-10-09 10:59:25 | [experiment_2019_10_09_10_58_54_0001] epoch #40 | Computing KL before
2019-10-09 10:59:25 | [experiment_2019_10_09_10_58_54_0001] epoch #40 | Optimizing
2019-10-09 10:59:25 | [experiment_2019_10_09_10_58_54_0001] epoch #40 | Start CG optimization: #parameters: 1282, #inputs: 41, #subsample_inputs: 41
2019-10-09 10:59:25 | [experiment_2019_10_09_10_58_54_0001] epoch #40 | computing loss before
2019-10-09 10:59:25 | [experiment_2019_10_09_10_58_54_0001] epoch #40 | performing update
2019-10-09 10:59:25 | [experiment_2019_10_09_10_58_54_0001] epoch #40 | computing gradient
2019-10-09 10:59:25 | [experiment_2019_10_09_10_58_54_0001] epoch #40 | gradient computed
2019-10-09 10:59:25 | [experiment_2019_10_09_10_58_54_0001] epoch #40 | computing descent direction
2019-10-09 10:59:25 | [experiment_2019_10_09_10_58_54_0001] epoch #40 | descent direction computed
2019-10-09 10:59:25 | [experiment_2019_10_09_10_58_54_0001] epoch #40 | backtrack iters: 2
2019-10-09 10:59:25 | [experiment_2019_10_09_10_58_54_0001] epoch #40 | computing loss after
2019-10-09 10:59:25 | [experiment_2019_10_09_10_58_54_0001] epoch #40 | optimization finished
2019-10-09 10:59:25 | [experiment_2019_10_09_10_58_54_0001] epoch #40 | Computing KL after
2019-10-09 10:59:25 | [experiment_2019_10_09_10_58_54_0001] epoch #40 | Computing loss after
2019-10-09 10:59:25 | [experiment_2019_10_09_10_58_54_0001] epoch #40 | Fitting baseline...
2019-10-09 10:59:25 | [experiment_2019_10_09_10_58_54_0001] epoch #40 | Saving snapshot...
2019-10-09 10:59:25 | [experiment_2019_10_09_10_58_54_0001] epoch #40 | Saved
2019-10-09 10:59:25 | [experiment_2019_10_09_10_58_54_0001] epoch #40 | Time 26.61 s
2019-10-09 10:59:25 | [experiment_2019_10_09_10_58_54_0001] epoch #40 | EpochTime 0.62 s
---------------------------------------  -------------
AverageDiscountedReturn                   63.3877
AverageReturn                             99.9756
Entropy                                    0.518876
EnvExecTime                                0.0548654
Extras/EpisodeRewardMean                  99.78
Iteration                                 40
LinearFeatureBaseline/ExplainedVariance    0.998495
MaxReturn                                100
MinReturn                                 99
NumTrajs                                  41
Perplexity                                 1.68014
PolicyExecTime                             0.383015
ProcessExecTime                            0.0189614
StdReturn                                  0.154257
policy/Entropy                             0.509196
policy/KL                                  0.00498601
policy/KLBefore                            3.29197e-10
policy/LossAfter                          -9.94971e-05
policy/LossBefore                         -5.58385e-09
policy/dLoss                               9.94916e-05
---------------------------------------  -------------
2019-10-09 10:59:25 | [experiment_2019_10_09_10_58_54_0001] epoch #41 | Obtaining samples...
2019-10-09 10:59:25 | [experiment_2019_10_09_10_58_54_0001] epoch #41 | Obtaining samples for iteration 41...
2019-10-09 10:59:26 | [experiment_2019_10_09_10_58_54_0001] epoch #41 | Logging diagnostics...
2019-10-09 10:59:26 | [experiment_2019_10_09_10_58_54_0001] epoch #41 | Optimizing policy...
2019-10-09 10:59:26 | [experiment_2019_10_09_10_58_54_0001] epoch #41 | Computing loss before
2019-10-09 10:59:26 | [experiment_2019_10_09_10_58_54_0001] epoch #41 | Computing KL before
2019-10-09 10:59:26 | [experiment_2019_10_09_10_58_54_0001] epoch #41 | Optimizing
2019-10-09 10:59:26 | [experiment_2019_10_09_10_58_54_0001] epoch #41 | Start CG optimization: #parameters: 1282, #inputs: 40, #subsample_inputs: 40
2019-10-09 10:59:26 | [experiment_2019_10_09_10_58_54_0001] epoch #41 | computing loss before
2019-10-09 10:59:26 | [experiment_2019_10_09_10_58_54_0001] epoch #41 | performing update
2019-10-09 10:59:26 | [experiment_2019_10_09_10_58_54_0001] epoch #41 | computing gradient
2019-10-09 10:59:26 | [experiment_2019_10_09_10_58_54_0001] epoch #41 | gradient computed
2019-10-09 10:59:26 | [experiment_2019_10_09_10_58_54_0001] epoch #41 | computing descent direction
2019-10-09 10:59:26 | [experiment_2019_10_09_10_58_54_0001] epoch #41 | descent direction computed
2019-10-09 10:59:26 | [experiment_2019_10_09_10_58_54_0001] epoch #41 | backtrack iters: 3
2019-10-09 10:59:26 | [experiment_2019_10_09_10_58_54_0001] epoch #41 | computing loss after
2019-10-09 10:59:26 | [experiment_2019_10_09_10_58_54_0001] epoch #41 | optimization finished
2019-10-09 10:59:26 | [experiment_2019_10_09_10_58_54_0001] epoch #41 | Computing KL after
2019-10-09 10:59:26 | [experiment_2019_10_09_10_58_54_0001] epoch #41 | Computing loss after
2019-10-09 10:59:26 | [experiment_2019_10_09_10_58_54_0001] epoch #41 | Fitting baseline...
2019-10-09 10:59:26 | [experiment_2019_10_09_10_58_54_0001] epoch #41 | Saving snapshot...
2019-10-09 10:59:26 | [experiment_2019_10_09_10_58_54_0001] epoch #41 | Saved
2019-10-09 10:59:26 | [experiment_2019_10_09_10_58_54_0001] epoch #41 | Time 27.25 s
2019-10-09 10:59:26 | [experiment_2019_10_09_10_58_54_0001] epoch #41 | EpochTime 0.64 s
---------------------------------------  -------------
AverageDiscountedReturn                   63.3968
AverageReturn                            100
Entropy                                    0.506991
EnvExecTime                                0.0563881
Extras/EpisodeRewardMean                  99.8
Iteration                                 41
LinearFeatureBaseline/ExplainedVariance    0.999985
MaxReturn                                100
MinReturn                                100
NumTrajs                                  40
Perplexity                                 1.66029
PolicyExecTime                             0.388211
ProcessExecTime                            0.020623
StdReturn                                  0
policy/Entropy                             0.520941
policy/KL                                  0.0063656
policy/KLBefore                            0
policy/LossAfter                          -0.0166191
policy/LossBefore                         -1.90735e-09
policy/dLoss                               0.0166191
---------------------------------------  -------------
2019-10-09 10:59:26 | [experiment_2019_10_09_10_58_54_0001] epoch #42 | Obtaining samples...
2019-10-09 10:59:26 | [experiment_2019_10_09_10_58_54_0001] epoch #42 | Obtaining samples for iteration 42...
2019-10-09 10:59:26 | [experiment_2019_10_09_10_58_54_0001] epoch #42 | Logging diagnostics...
2019-10-09 10:59:26 | [experiment_2019_10_09_10_58_54_0001] epoch #42 | Optimizing policy...
2019-10-09 10:59:26 | [experiment_2019_10_09_10_58_54_0001] epoch #42 | Computing loss before
2019-10-09 10:59:26 | [experiment_2019_10_09_10_58_54_0001] epoch #42 | Computing KL before
2019-10-09 10:59:26 | [experiment_2019_10_09_10_58_54_0001] epoch #42 | Optimizing
2019-10-09 10:59:26 | [experiment_2019_10_09_10_58_54_0001] epoch #42 | Start CG optimization: #parameters: 1282, #inputs: 41, #subsample_inputs: 41
2019-10-09 10:59:26 | [experiment_2019_10_09_10_58_54_0001] epoch #42 | computing loss before
2019-10-09 10:59:26 | [experiment_2019_10_09_10_58_54_0001] epoch #42 | performing update
2019-10-09 10:59:26 | [experiment_2019_10_09_10_58_54_0001] epoch #42 | computing gradient
2019-10-09 10:59:26 | [experiment_2019_10_09_10_58_54_0001] epoch #42 | gradient computed
2019-10-09 10:59:26 | [experiment_2019_10_09_10_58_54_0001] epoch #42 | computing descent direction
2019-10-09 10:59:26 | [experiment_2019_10_09_10_58_54_0001] epoch #42 | descent direction computed
2019-10-09 10:59:26 | [experiment_2019_10_09_10_58_54_0001] epoch #42 | backtrack iters: 3
2019-10-09 10:59:26 | [experiment_2019_10_09_10_58_54_0001] epoch #42 | computing loss after
2019-10-09 10:59:26 | [experiment_2019_10_09_10_58_54_0001] epoch #42 | optimization finished
2019-10-09 10:59:26 | [experiment_2019_10_09_10_58_54_0001] epoch #42 | Computing KL after
2019-10-09 10:59:26 | [experiment_2019_10_09_10_58_54_0001] epoch #42 | Computing loss after
2019-10-09 10:59:27 | [experiment_2019_10_09_10_58_54_0001] epoch #42 | Fitting baseline...
2019-10-09 10:59:27 | [experiment_2019_10_09_10_58_54_0001] epoch #42 | Saving snapshot...
2019-10-09 10:59:27 | [experiment_2019_10_09_10_58_54_0001] epoch #42 | Saved
2019-10-09 10:59:27 | [experiment_2019_10_09_10_58_54_0001] epoch #42 | Time 27.89 s
2019-10-09 10:59:27 | [experiment_2019_10_09_10_58_54_0001] epoch #42 | EpochTime 0.63 s
---------------------------------------  -------------
AverageDiscountedReturn                   63.1418
AverageReturn                             99.3902
Entropy                                    0.51592
EnvExecTime                                0.0559447
Extras/EpisodeRewardMean                  99.75
Iteration                                 42
LinearFeatureBaseline/ExplainedVariance    0.985963
MaxReturn                                100
MinReturn                                 75
NumTrajs                                  41
Perplexity                                 1.67518
PolicyExecTime                             0.383881
ProcessExecTime                            0.019908
StdReturn                                  3.85644
policy/Entropy                             0.524046
policy/KL                                  0.00847845
policy/KLBefore                            6.7097e-11
policy/LossAfter                          -0.00860113
policy/LossBefore                         -4.23449e-09
policy/dLoss                               0.00860112
---------------------------------------  -------------
2019-10-09 10:59:27 | [experiment_2019_10_09_10_58_54_0001] epoch #43 | Obtaining samples...
2019-10-09 10:59:27 | [experiment_2019_10_09_10_58_54_0001] epoch #43 | Obtaining samples for iteration 43...
2019-10-09 10:59:27 | [experiment_2019_10_09_10_58_54_0001] epoch #43 | Logging diagnostics...
2019-10-09 10:59:27 | [experiment_2019_10_09_10_58_54_0001] epoch #43 | Optimizing policy...
2019-10-09 10:59:27 | [experiment_2019_10_09_10_58_54_0001] epoch #43 | Computing loss before
2019-10-09 10:59:27 | [experiment_2019_10_09_10_58_54_0001] epoch #43 | Computing KL before
2019-10-09 10:59:27 | [experiment_2019_10_09_10_58_54_0001] epoch #43 | Optimizing
2019-10-09 10:59:27 | [experiment_2019_10_09_10_58_54_0001] epoch #43 | Start CG optimization: #parameters: 1282, #inputs: 41, #subsample_inputs: 41
2019-10-09 10:59:27 | [experiment_2019_10_09_10_58_54_0001] epoch #43 | computing loss before
2019-10-09 10:59:27 | [experiment_2019_10_09_10_58_54_0001] epoch #43 | performing update
2019-10-09 10:59:27 | [experiment_2019_10_09_10_58_54_0001] epoch #43 | computing gradient
2019-10-09 10:59:27 | [experiment_2019_10_09_10_58_54_0001] epoch #43 | gradient computed
2019-10-09 10:59:27 | [experiment_2019_10_09_10_58_54_0001] epoch #43 | computing descent direction
2019-10-09 10:59:27 | [experiment_2019_10_09_10_58_54_0001] epoch #43 | descent direction computed
2019-10-09 10:59:27 | [experiment_2019_10_09_10_58_54_0001] epoch #43 | backtrack iters: 2
2019-10-09 10:59:27 | [experiment_2019_10_09_10_58_54_0001] epoch #43 | computing loss after
2019-10-09 10:59:27 | [experiment_2019_10_09_10_58_54_0001] epoch #43 | optimization finished
2019-10-09 10:59:27 | [experiment_2019_10_09_10_58_54_0001] epoch #43 | Computing KL after
2019-10-09 10:59:27 | [experiment_2019_10_09_10_58_54_0001] epoch #43 | Computing loss after
2019-10-09 10:59:27 | [experiment_2019_10_09_10_58_54_0001] epoch #43 | Fitting baseline...
2019-10-09 10:59:27 | [experiment_2019_10_09_10_58_54_0001] epoch #43 | Saving snapshot...
2019-10-09 10:59:27 | [experiment_2019_10_09_10_58_54_0001] epoch #43 | Saved
2019-10-09 10:59:27 | [experiment_2019_10_09_10_58_54_0001] epoch #43 | Time 28.51 s
2019-10-09 10:59:27 | [experiment_2019_10_09_10_58_54_0001] epoch #43 | EpochTime 0.61 s
---------------------------------------  -------------
AverageDiscountedReturn                   63.198
AverageReturn                             99.5122
Entropy                                    0.528069
EnvExecTime                                0.0543523
Extras/EpisodeRewardMean                  99.55
Iteration                                 43
LinearFeatureBaseline/ExplainedVariance    0.990053
MaxReturn                                100
MinReturn                                 80
NumTrajs                                  41
Perplexity                                 1.69565
PolicyExecTime                             0.374017
ProcessExecTime                            0.0187774
StdReturn                                  3.08515
policy/Entropy                             0.525089
policy/KL                                  0.00814799
policy/KLBefore                           -3.91711e-11
policy/LossAfter                          -0.0100423
policy/LossBefore                          3.97364e-09
policy/dLoss                               0.0100423
---------------------------------------  -------------
2019-10-09 10:59:27 | [experiment_2019_10_09_10_58_54_0001] epoch #44 | Obtaining samples...
2019-10-09 10:59:27 | [experiment_2019_10_09_10_58_54_0001] epoch #44 | Obtaining samples for iteration 44...
2019-10-09 10:59:28 | [experiment_2019_10_09_10_58_54_0001] epoch #44 | Logging diagnostics...
2019-10-09 10:59:28 | [experiment_2019_10_09_10_58_54_0001] epoch #44 | Optimizing policy...
2019-10-09 10:59:28 | [experiment_2019_10_09_10_58_54_0001] epoch #44 | Computing loss before
2019-10-09 10:59:28 | [experiment_2019_10_09_10_58_54_0001] epoch #44 | Computing KL before
2019-10-09 10:59:28 | [experiment_2019_10_09_10_58_54_0001] epoch #44 | Optimizing
2019-10-09 10:59:28 | [experiment_2019_10_09_10_58_54_0001] epoch #44 | Start CG optimization: #parameters: 1282, #inputs: 40, #subsample_inputs: 40
2019-10-09 10:59:28 | [experiment_2019_10_09_10_58_54_0001] epoch #44 | computing loss before
2019-10-09 10:59:28 | [experiment_2019_10_09_10_58_54_0001] epoch #44 | performing update
2019-10-09 10:59:28 | [experiment_2019_10_09_10_58_54_0001] epoch #44 | computing gradient
2019-10-09 10:59:28 | [experiment_2019_10_09_10_58_54_0001] epoch #44 | gradient computed
2019-10-09 10:59:28 | [experiment_2019_10_09_10_58_54_0001] epoch #44 | computing descent direction
2019-10-09 10:59:28 | [experiment_2019_10_09_10_58_54_0001] epoch #44 | descent direction computed
2019-10-09 10:59:28 | [experiment_2019_10_09_10_58_54_0001] epoch #44 | backtrack iters: 3
2019-10-09 10:59:28 | [experiment_2019_10_09_10_58_54_0001] epoch #44 | computing loss after
2019-10-09 10:59:28 | [experiment_2019_10_09_10_58_54_0001] epoch #44 | optimization finished
2019-10-09 10:59:28 | [experiment_2019_10_09_10_58_54_0001] epoch #44 | Computing KL after
2019-10-09 10:59:28 | [experiment_2019_10_09_10_58_54_0001] epoch #44 | Computing loss after
2019-10-09 10:59:28 | [experiment_2019_10_09_10_58_54_0001] epoch #44 | Fitting baseline...
2019-10-09 10:59:28 | [experiment_2019_10_09_10_58_54_0001] epoch #44 | Saving snapshot...
2019-10-09 10:59:28 | [experiment_2019_10_09_10_58_54_0001] epoch #44 | Saved
2019-10-09 10:59:28 | [experiment_2019_10_09_10_58_54_0001] epoch #44 | Time 29.11 s
2019-10-09 10:59:28 | [experiment_2019_10_09_10_58_54_0001] epoch #44 | EpochTime 0.59 s
---------------------------------------  -------------
AverageDiscountedReturn                   63.3968
AverageReturn                            100
Entropy                                    0.52882
EnvExecTime                                0.050549
Extras/EpisodeRewardMean                  99.8
Iteration                                 44
LinearFeatureBaseline/ExplainedVariance    0.999576
MaxReturn                                100
MinReturn                                100
NumTrajs                                  40
Perplexity                                 1.69693
PolicyExecTime                             0.357221
ProcessExecTime                            0.0180395
StdReturn                                  0
policy/Entropy                             0.512437
policy/KL                                  0.00810186
policy/KLBefore                            0
policy/LossAfter                          -0.00575261
policy/LossBefore                          1.19209e-09
policy/dLoss                               0.00575261
---------------------------------------  -------------
2019-10-09 10:59:28 | [experiment_2019_10_09_10_58_54_0001] epoch #45 | Obtaining samples...
2019-10-09 10:59:28 | [experiment_2019_10_09_10_58_54_0001] epoch #45 | Obtaining samples for iteration 45...
2019-10-09 10:59:28 | [experiment_2019_10_09_10_58_54_0001] epoch #45 | Logging diagnostics...
2019-10-09 10:59:28 | [experiment_2019_10_09_10_58_54_0001] epoch #45 | Optimizing policy...
2019-10-09 10:59:28 | [experiment_2019_10_09_10_58_54_0001] epoch #45 | Computing loss before
2019-10-09 10:59:28 | [experiment_2019_10_09_10_58_54_0001] epoch #45 | Computing KL before
2019-10-09 10:59:28 | [experiment_2019_10_09_10_58_54_0001] epoch #45 | Optimizing
2019-10-09 10:59:28 | [experiment_2019_10_09_10_58_54_0001] epoch #45 | Start CG optimization: #parameters: 1282, #inputs: 40, #subsample_inputs: 40
2019-10-09 10:59:28 | [experiment_2019_10_09_10_58_54_0001] epoch #45 | computing loss before
2019-10-09 10:59:28 | [experiment_2019_10_09_10_58_54_0001] epoch #45 | performing update
2019-10-09 10:59:28 | [experiment_2019_10_09_10_58_54_0001] epoch #45 | computing gradient
2019-10-09 10:59:28 | [experiment_2019_10_09_10_58_54_0001] epoch #45 | gradient computed
2019-10-09 10:59:28 | [experiment_2019_10_09_10_58_54_0001] epoch #45 | computing descent direction
2019-10-09 10:59:28 | [experiment_2019_10_09_10_58_54_0001] epoch #45 | descent direction computed
2019-10-09 10:59:28 | [experiment_2019_10_09_10_58_54_0001] epoch #45 | backtrack iters: 2
2019-10-09 10:59:28 | [experiment_2019_10_09_10_58_54_0001] epoch #45 | computing loss after
2019-10-09 10:59:28 | [experiment_2019_10_09_10_58_54_0001] epoch #45 | optimization finished
2019-10-09 10:59:28 | [experiment_2019_10_09_10_58_54_0001] epoch #45 | Computing KL after
2019-10-09 10:59:28 | [experiment_2019_10_09_10_58_54_0001] epoch #45 | Computing loss after
2019-10-09 10:59:28 | [experiment_2019_10_09_10_58_54_0001] epoch #45 | Fitting baseline...
2019-10-09 10:59:28 | [experiment_2019_10_09_10_58_54_0001] epoch #45 | Saving snapshot...
2019-10-09 10:59:28 | [experiment_2019_10_09_10_58_54_0001] epoch #45 | Saved
2019-10-09 10:59:28 | [experiment_2019_10_09_10_58_54_0001] epoch #45 | Time 29.70 s
2019-10-09 10:59:28 | [experiment_2019_10_09_10_58_54_0001] epoch #45 | EpochTime 0.59 s
---------------------------------------  ------------
AverageDiscountedReturn                   63.3968
AverageReturn                            100
Entropy                                    0.527132
EnvExecTime                                0.0524397
Extras/EpisodeRewardMean                 100
Iteration                                 45
LinearFeatureBaseline/ExplainedVariance    1
MaxReturn                                100
MinReturn                                100
NumTrajs                                  40
Perplexity                                 1.69407
PolicyExecTime                             0.358346
ProcessExecTime                            0.0188546
StdReturn                                  0
policy/Entropy                             0.500999
policy/KL                                  0.00717851
policy/KLBefore                            0
policy/LossAfter                          -0.0025558
policy/LossBefore                         -1.7643e-08
policy/dLoss                               0.00255579
---------------------------------------  ------------
2019-10-09 10:59:28 | [experiment_2019_10_09_10_58_54_0001] epoch #46 | Obtaining samples...
2019-10-09 10:59:28 | [experiment_2019_10_09_10_58_54_0001] epoch #46 | Obtaining samples for iteration 46...
2019-10-09 10:59:29 | [experiment_2019_10_09_10_58_54_0001] epoch #46 | Logging diagnostics...
2019-10-09 10:59:29 | [experiment_2019_10_09_10_58_54_0001] epoch #46 | Optimizing policy...
2019-10-09 10:59:29 | [experiment_2019_10_09_10_58_54_0001] epoch #46 | Computing loss before
2019-10-09 10:59:29 | [experiment_2019_10_09_10_58_54_0001] epoch #46 | Computing KL before
2019-10-09 10:59:29 | [experiment_2019_10_09_10_58_54_0001] epoch #46 | Optimizing
2019-10-09 10:59:29 | [experiment_2019_10_09_10_58_54_0001] epoch #46 | Start CG optimization: #parameters: 1282, #inputs: 40, #subsample_inputs: 40
2019-10-09 10:59:29 | [experiment_2019_10_09_10_58_54_0001] epoch #46 | computing loss before
2019-10-09 10:59:29 | [experiment_2019_10_09_10_58_54_0001] epoch #46 | performing update
2019-10-09 10:59:29 | [experiment_2019_10_09_10_58_54_0001] epoch #46 | computing gradient
2019-10-09 10:59:29 | [experiment_2019_10_09_10_58_54_0001] epoch #46 | gradient computed
2019-10-09 10:59:29 | [experiment_2019_10_09_10_58_54_0001] epoch #46 | computing descent direction
2019-10-09 10:59:29 | [experiment_2019_10_09_10_58_54_0001] epoch #46 | descent direction computed
2019-10-09 10:59:29 | [experiment_2019_10_09_10_58_54_0001] epoch #46 | backtrack iters: 2
2019-10-09 10:59:29 | [experiment_2019_10_09_10_58_54_0001] epoch #46 | computing loss after
2019-10-09 10:59:29 | [experiment_2019_10_09_10_58_54_0001] epoch #46 | optimization finished
2019-10-09 10:59:29 | [experiment_2019_10_09_10_58_54_0001] epoch #46 | Computing KL after
2019-10-09 10:59:29 | [experiment_2019_10_09_10_58_54_0001] epoch #46 | Computing loss after
2019-10-09 10:59:29 | [experiment_2019_10_09_10_58_54_0001] epoch #46 | Fitting baseline...
2019-10-09 10:59:29 | [experiment_2019_10_09_10_58_54_0001] epoch #46 | Saving snapshot...
2019-10-09 10:59:29 | [experiment_2019_10_09_10_58_54_0001] epoch #46 | Saved
2019-10-09 10:59:29 | [experiment_2019_10_09_10_58_54_0001] epoch #46 | Time 30.29 s
2019-10-09 10:59:29 | [experiment_2019_10_09_10_58_54_0001] epoch #46 | EpochTime 0.59 s
---------------------------------------  -------------
AverageDiscountedReturn                   63.3968
AverageReturn                            100
Entropy                                    0.507406
EnvExecTime                                0.0502784
Extras/EpisodeRewardMean                 100
Iteration                                 46
LinearFeatureBaseline/ExplainedVariance    1
MaxReturn                                100
MinReturn                                100
NumTrajs                                  40
Perplexity                                 1.66098
PolicyExecTime                             0.355329
ProcessExecTime                            0.017602
StdReturn                                  0
policy/Entropy                             0.52067
policy/KL                                  0.00743342
policy/KLBefore                            0
policy/LossAfter                          -0.00505613
policy/LossBefore                         -1.60933e-09
policy/dLoss                               0.00505612
---------------------------------------  -------------
2019-10-09 10:59:29 | [experiment_2019_10_09_10_58_54_0001] epoch #47 | Obtaining samples...
2019-10-09 10:59:29 | [experiment_2019_10_09_10_58_54_0001] epoch #47 | Obtaining samples for iteration 47...
2019-10-09 10:59:29 | [experiment_2019_10_09_10_58_54_0001] epoch #47 | Logging diagnostics...
2019-10-09 10:59:29 | [experiment_2019_10_09_10_58_54_0001] epoch #47 | Optimizing policy...
2019-10-09 10:59:29 | [experiment_2019_10_09_10_58_54_0001] epoch #47 | Computing loss before
2019-10-09 10:59:29 | [experiment_2019_10_09_10_58_54_0001] epoch #47 | Computing KL before
2019-10-09 10:59:29 | [experiment_2019_10_09_10_58_54_0001] epoch #47 | Optimizing
2019-10-09 10:59:29 | [experiment_2019_10_09_10_58_54_0001] epoch #47 | Start CG optimization: #parameters: 1282, #inputs: 40, #subsample_inputs: 40
2019-10-09 10:59:29 | [experiment_2019_10_09_10_58_54_0001] epoch #47 | computing loss before
2019-10-09 10:59:29 | [experiment_2019_10_09_10_58_54_0001] epoch #47 | performing update
2019-10-09 10:59:29 | [experiment_2019_10_09_10_58_54_0001] epoch #47 | computing gradient
2019-10-09 10:59:29 | [experiment_2019_10_09_10_58_54_0001] epoch #47 | gradient computed
2019-10-09 10:59:29 | [experiment_2019_10_09_10_58_54_0001] epoch #47 | computing descent direction
2019-10-09 10:59:29 | [experiment_2019_10_09_10_58_54_0001] epoch #47 | descent direction computed
2019-10-09 10:59:29 | [experiment_2019_10_09_10_58_54_0001] epoch #47 | backtrack iters: 4
2019-10-09 10:59:29 | [experiment_2019_10_09_10_58_54_0001] epoch #47 | computing loss after
2019-10-09 10:59:29 | [experiment_2019_10_09_10_58_54_0001] epoch #47 | optimization finished
2019-10-09 10:59:29 | [experiment_2019_10_09_10_58_54_0001] epoch #47 | Computing KL after
2019-10-09 10:59:29 | [experiment_2019_10_09_10_58_54_0001] epoch #47 | Computing loss after
2019-10-09 10:59:30 | [experiment_2019_10_09_10_58_54_0001] epoch #47 | Fitting baseline...
2019-10-09 10:59:30 | [experiment_2019_10_09_10_58_54_0001] epoch #47 | Saving snapshot...
2019-10-09 10:59:30 | [experiment_2019_10_09_10_58_54_0001] epoch #47 | Saved
2019-10-09 10:59:30 | [experiment_2019_10_09_10_58_54_0001] epoch #47 | Time 30.89 s
2019-10-09 10:59:30 | [experiment_2019_10_09_10_58_54_0001] epoch #47 | EpochTime 0.59 s
---------------------------------------  ------------
AverageDiscountedReturn                   63.3968
AverageReturn                            100
Entropy                                    0.517064
EnvExecTime                                0.0506277
Extras/EpisodeRewardMean                 100
Iteration                                 47
LinearFeatureBaseline/ExplainedVariance    1
MaxReturn                                100
MinReturn                                100
NumTrajs                                  40
Perplexity                                 1.6771
PolicyExecTime                             0.351318
ProcessExecTime                            0.0181155
StdReturn                                  0
policy/Entropy                             0.501463
policy/KL                                  0.00635311
policy/KLBefore                            0
policy/LossAfter                          -0.00253872
policy/LossBefore                          1.2815e-08
policy/dLoss                               0.00253873
---------------------------------------  ------------
2019-10-09 10:59:30 | [experiment_2019_10_09_10_58_54_0001] epoch #48 | Obtaining samples...
2019-10-09 10:59:30 | [experiment_2019_10_09_10_58_54_0001] epoch #48 | Obtaining samples for iteration 48...
2019-10-09 10:59:30 | [experiment_2019_10_09_10_58_54_0001] epoch #48 | Logging diagnostics...
2019-10-09 10:59:30 | [experiment_2019_10_09_10_58_54_0001] epoch #48 | Optimizing policy...
2019-10-09 10:59:30 | [experiment_2019_10_09_10_58_54_0001] epoch #48 | Computing loss before
2019-10-09 10:59:30 | [experiment_2019_10_09_10_58_54_0001] epoch #48 | Computing KL before
2019-10-09 10:59:30 | [experiment_2019_10_09_10_58_54_0001] epoch #48 | Optimizing
2019-10-09 10:59:30 | [experiment_2019_10_09_10_58_54_0001] epoch #48 | Start CG optimization: #parameters: 1282, #inputs: 40, #subsample_inputs: 40
2019-10-09 10:59:30 | [experiment_2019_10_09_10_58_54_0001] epoch #48 | computing loss before
2019-10-09 10:59:30 | [experiment_2019_10_09_10_58_54_0001] epoch #48 | performing update
2019-10-09 10:59:30 | [experiment_2019_10_09_10_58_54_0001] epoch #48 | computing gradient
2019-10-09 10:59:30 | [experiment_2019_10_09_10_58_54_0001] epoch #48 | gradient computed
2019-10-09 10:59:30 | [experiment_2019_10_09_10_58_54_0001] epoch #48 | computing descent direction
2019-10-09 10:59:30 | [experiment_2019_10_09_10_58_54_0001] epoch #48 | descent direction computed
2019-10-09 10:59:30 | [experiment_2019_10_09_10_58_54_0001] epoch #48 | backtrack iters: 0
2019-10-09 10:59:30 | [experiment_2019_10_09_10_58_54_0001] epoch #48 | computing loss after
2019-10-09 10:59:30 | [experiment_2019_10_09_10_58_54_0001] epoch #48 | optimization finished
2019-10-09 10:59:30 | [experiment_2019_10_09_10_58_54_0001] epoch #48 | Computing KL after
2019-10-09 10:59:30 | [experiment_2019_10_09_10_58_54_0001] epoch #48 | Computing loss after
2019-10-09 10:59:30 | [experiment_2019_10_09_10_58_54_0001] epoch #48 | Fitting baseline...
2019-10-09 10:59:30 | [experiment_2019_10_09_10_58_54_0001] epoch #48 | Saving snapshot...
2019-10-09 10:59:30 | [experiment_2019_10_09_10_58_54_0001] epoch #48 | Saved
2019-10-09 10:59:30 | [experiment_2019_10_09_10_58_54_0001] epoch #48 | Time 31.48 s
2019-10-09 10:59:30 | [experiment_2019_10_09_10_58_54_0001] epoch #48 | EpochTime 0.59 s
---------------------------------------  -------------
AverageDiscountedReturn                   63.3968
AverageReturn                            100
Entropy                                    0.516594
EnvExecTime                                0.050606
Extras/EpisodeRewardMean                 100
Iteration                                 48
LinearFeatureBaseline/ExplainedVariance    1
MaxReturn                                100
MinReturn                                100
NumTrajs                                  40
Perplexity                                 1.67631
PolicyExecTime                             0.360101
ProcessExecTime                            0.0180557
StdReturn                                  0
policy/Entropy                             0.51068
policy/KL                                  0.00509845
policy/KLBefore                            0
policy/LossAfter                          -0.00478403
policy/LossBefore                          9.53674e-09
policy/dLoss                               0.00478404
---------------------------------------  -------------
2019-10-09 10:59:30 | [experiment_2019_10_09_10_58_54_0001] epoch #49 | Obtaining samples...
2019-10-09 10:59:30 | [experiment_2019_10_09_10_58_54_0001] epoch #49 | Obtaining samples for iteration 49...
2019-10-09 10:59:31 | [experiment_2019_10_09_10_58_54_0001] epoch #49 | Logging diagnostics...
2019-10-09 10:59:31 | [experiment_2019_10_09_10_58_54_0001] epoch #49 | Optimizing policy...
2019-10-09 10:59:31 | [experiment_2019_10_09_10_58_54_0001] epoch #49 | Computing loss before
2019-10-09 10:59:31 | [experiment_2019_10_09_10_58_54_0001] epoch #49 | Computing KL before
2019-10-09 10:59:31 | [experiment_2019_10_09_10_58_54_0001] epoch #49 | Optimizing
2019-10-09 10:59:31 | [experiment_2019_10_09_10_58_54_0001] epoch #49 | Start CG optimization: #parameters: 1282, #inputs: 40, #subsample_inputs: 40
2019-10-09 10:59:31 | [experiment_2019_10_09_10_58_54_0001] epoch #49 | computing loss before
2019-10-09 10:59:31 | [experiment_2019_10_09_10_58_54_0001] epoch #49 | performing update
2019-10-09 10:59:31 | [experiment_2019_10_09_10_58_54_0001] epoch #49 | computing gradient
2019-10-09 10:59:31 | [experiment_2019_10_09_10_58_54_0001] epoch #49 | gradient computed
2019-10-09 10:59:31 | [experiment_2019_10_09_10_58_54_0001] epoch #49 | computing descent direction
2019-10-09 10:59:31 | [experiment_2019_10_09_10_58_54_0001] epoch #49 | descent direction computed
2019-10-09 10:59:31 | [experiment_2019_10_09_10_58_54_0001] epoch #49 | backtrack iters: 1
2019-10-09 10:59:31 | [experiment_2019_10_09_10_58_54_0001] epoch #49 | computing loss after
2019-10-09 10:59:31 | [experiment_2019_10_09_10_58_54_0001] epoch #49 | optimization finished
2019-10-09 10:59:31 | [experiment_2019_10_09_10_58_54_0001] epoch #49 | Computing KL after
2019-10-09 10:59:31 | [experiment_2019_10_09_10_58_54_0001] epoch #49 | Computing loss after
2019-10-09 10:59:31 | [experiment_2019_10_09_10_58_54_0001] epoch #49 | Fitting baseline...
2019-10-09 10:59:31 | [experiment_2019_10_09_10_58_54_0001] epoch #49 | Saving snapshot...
2019-10-09 10:59:31 | [experiment_2019_10_09_10_58_54_0001] epoch #49 | Saved
2019-10-09 10:59:31 | [experiment_2019_10_09_10_58_54_0001] epoch #49 | Time 32.07 s
2019-10-09 10:59:31 | [experiment_2019_10_09_10_58_54_0001] epoch #49 | EpochTime 0.58 s
---------------------------------------  -------------
AverageDiscountedReturn                   63.3968
AverageReturn                            100
Entropy                                    0.509871
EnvExecTime                                0.0496359
Extras/EpisodeRewardMean                 100
Iteration                                 49
LinearFeatureBaseline/ExplainedVariance    1
MaxReturn                                100
MinReturn                                100
NumTrajs                                  40
Perplexity                                 1.66508
PolicyExecTime                             0.344752
ProcessExecTime                            0.0173755
StdReturn                                  0
policy/Entropy                             0.509877
policy/KL                                  0.00834849
policy/KLBefore                            0
policy/LossAfter                          -0.00387614
policy/LossBefore                         -7.45058e-09
policy/dLoss                               0.00387613
---------------------------------------  -------------
2019-10-09 10:59:31 | [experiment_2019_10_09_10_58_54_0001] epoch #50 | Obtaining samples...
2019-10-09 10:59:31 | [experiment_2019_10_09_10_58_54_0001] epoch #50 | Obtaining samples for iteration 50...
2019-10-09 10:59:31 | [experiment_2019_10_09_10_58_54_0001] epoch #50 | Logging diagnostics...
2019-10-09 10:59:31 | [experiment_2019_10_09_10_58_54_0001] epoch #50 | Optimizing policy...
2019-10-09 10:59:31 | [experiment_2019_10_09_10_58_54_0001] epoch #50 | Computing loss before
2019-10-09 10:59:31 | [experiment_2019_10_09_10_58_54_0001] epoch #50 | Computing KL before
2019-10-09 10:59:31 | [experiment_2019_10_09_10_58_54_0001] epoch #50 | Optimizing
2019-10-09 10:59:31 | [experiment_2019_10_09_10_58_54_0001] epoch #50 | Start CG optimization: #parameters: 1282, #inputs: 40, #subsample_inputs: 40
2019-10-09 10:59:31 | [experiment_2019_10_09_10_58_54_0001] epoch #50 | computing loss before
2019-10-09 10:59:31 | [experiment_2019_10_09_10_58_54_0001] epoch #50 | performing update
2019-10-09 10:59:31 | [experiment_2019_10_09_10_58_54_0001] epoch #50 | computing gradient
2019-10-09 10:59:31 | [experiment_2019_10_09_10_58_54_0001] epoch #50 | gradient computed
2019-10-09 10:59:31 | [experiment_2019_10_09_10_58_54_0001] epoch #50 | computing descent direction
2019-10-09 10:59:31 | [experiment_2019_10_09_10_58_54_0001] epoch #50 | descent direction computed
2019-10-09 10:59:31 | [experiment_2019_10_09_10_58_54_0001] epoch #50 | backtrack iters: 4
2019-10-09 10:59:31 | [experiment_2019_10_09_10_58_54_0001] epoch #50 | computing loss after
2019-10-09 10:59:31 | [experiment_2019_10_09_10_58_54_0001] epoch #50 | optimization finished
2019-10-09 10:59:31 | [experiment_2019_10_09_10_58_54_0001] epoch #50 | Computing KL after
2019-10-09 10:59:31 | [experiment_2019_10_09_10_58_54_0001] epoch #50 | Computing loss after
2019-10-09 10:59:31 | [experiment_2019_10_09_10_58_54_0001] epoch #50 | Fitting baseline...
2019-10-09 10:59:31 | [experiment_2019_10_09_10_58_54_0001] epoch #50 | Saving snapshot...
2019-10-09 10:59:31 | [experiment_2019_10_09_10_58_54_0001] epoch #50 | Saved
2019-10-09 10:59:31 | [experiment_2019_10_09_10_58_54_0001] epoch #50 | Time 32.67 s
2019-10-09 10:59:31 | [experiment_2019_10_09_10_58_54_0001] epoch #50 | EpochTime 0.59 s
---------------------------------------  -------------
AverageDiscountedReturn                   63.3968
AverageReturn                            100
Entropy                                    0.515757
EnvExecTime                                0.0499742
Extras/EpisodeRewardMean                 100
Iteration                                 50
LinearFeatureBaseline/ExplainedVariance    1
MaxReturn                                100
MinReturn                                100
NumTrajs                                  40
Perplexity                                 1.67491
PolicyExecTime                             0.353841
ProcessExecTime                            0.0176826
StdReturn                                  0
policy/Entropy                             0.51295
policy/KL                                  0.00809521
policy/KLBefore                            0
policy/LossAfter                          -0.00351195
policy/LossBefore                          9.83477e-09
policy/dLoss                               0.00351196
---------------------------------------  -------------
2019-10-09 10:59:31 | [experiment_2019_10_09_10_58_54_0001] epoch #51 | Obtaining samples...
2019-10-09 10:59:31 | [experiment_2019_10_09_10_58_54_0001] epoch #51 | Obtaining samples for iteration 51...
2019-10-09 10:59:32 | [experiment_2019_10_09_10_58_54_0001] epoch #51 | Logging diagnostics...
2019-10-09 10:59:32 | [experiment_2019_10_09_10_58_54_0001] epoch #51 | Optimizing policy...
2019-10-09 10:59:32 | [experiment_2019_10_09_10_58_54_0001] epoch #51 | Computing loss before
2019-10-09 10:59:32 | [experiment_2019_10_09_10_58_54_0001] epoch #51 | Computing KL before
2019-10-09 10:59:32 | [experiment_2019_10_09_10_58_54_0001] epoch #51 | Optimizing
2019-10-09 10:59:32 | [experiment_2019_10_09_10_58_54_0001] epoch #51 | Start CG optimization: #parameters: 1282, #inputs: 40, #subsample_inputs: 40
2019-10-09 10:59:32 | [experiment_2019_10_09_10_58_54_0001] epoch #51 | computing loss before
2019-10-09 10:59:32 | [experiment_2019_10_09_10_58_54_0001] epoch #51 | performing update
2019-10-09 10:59:32 | [experiment_2019_10_09_10_58_54_0001] epoch #51 | computing gradient
2019-10-09 10:59:32 | [experiment_2019_10_09_10_58_54_0001] epoch #51 | gradient computed
2019-10-09 10:59:32 | [experiment_2019_10_09_10_58_54_0001] epoch #51 | computing descent direction
2019-10-09 10:59:32 | [experiment_2019_10_09_10_58_54_0001] epoch #51 | descent direction computed
2019-10-09 10:59:32 | [experiment_2019_10_09_10_58_54_0001] epoch #51 | backtrack iters: 2
2019-10-09 10:59:32 | [experiment_2019_10_09_10_58_54_0001] epoch #51 | computing loss after
2019-10-09 10:59:32 | [experiment_2019_10_09_10_58_54_0001] epoch #51 | optimization finished
2019-10-09 10:59:32 | [experiment_2019_10_09_10_58_54_0001] epoch #51 | Computing KL after
2019-10-09 10:59:32 | [experiment_2019_10_09_10_58_54_0001] epoch #51 | Computing loss after
2019-10-09 10:59:32 | [experiment_2019_10_09_10_58_54_0001] epoch #51 | Fitting baseline...
2019-10-09 10:59:32 | [experiment_2019_10_09_10_58_54_0001] epoch #51 | Saving snapshot...
2019-10-09 10:59:32 | [experiment_2019_10_09_10_58_54_0001] epoch #51 | Saved
2019-10-09 10:59:32 | [experiment_2019_10_09_10_58_54_0001] epoch #51 | Time 33.27 s
2019-10-09 10:59:32 | [experiment_2019_10_09_10_58_54_0001] epoch #51 | EpochTime 0.59 s
---------------------------------------  -------------
AverageDiscountedReturn                   63.3968
AverageReturn                            100
Entropy                                    0.516497
EnvExecTime                                0.0497019
Extras/EpisodeRewardMean                 100
Iteration                                 51
LinearFeatureBaseline/ExplainedVariance    1
MaxReturn                                100
MinReturn                                100
NumTrajs                                  40
Perplexity                                 1.67615
PolicyExecTime                             0.355065
ProcessExecTime                            0.0177507
StdReturn                                  0
policy/Entropy                             0.508592
policy/KL                                  0.00604702
policy/KLBefore                            0
policy/LossAfter                          -0.00252595
policy/LossBefore                          2.08616e-08
policy/dLoss                               0.00252597
---------------------------------------  -------------
2019-10-09 10:59:32 | [experiment_2019_10_09_10_58_54_0001] epoch #52 | Obtaining samples...
2019-10-09 10:59:32 | [experiment_2019_10_09_10_58_54_0001] epoch #52 | Obtaining samples for iteration 52...
2019-10-09 10:59:32 | [experiment_2019_10_09_10_58_54_0001] epoch #52 | Logging diagnostics...
2019-10-09 10:59:32 | [experiment_2019_10_09_10_58_54_0001] epoch #52 | Optimizing policy...
2019-10-09 10:59:32 | [experiment_2019_10_09_10_58_54_0001] epoch #52 | Computing loss before
2019-10-09 10:59:32 | [experiment_2019_10_09_10_58_54_0001] epoch #52 | Computing KL before
2019-10-09 10:59:32 | [experiment_2019_10_09_10_58_54_0001] epoch #52 | Optimizing
2019-10-09 10:59:32 | [experiment_2019_10_09_10_58_54_0001] epoch #52 | Start CG optimization: #parameters: 1282, #inputs: 40, #subsample_inputs: 40
2019-10-09 10:59:32 | [experiment_2019_10_09_10_58_54_0001] epoch #52 | computing loss before
2019-10-09 10:59:32 | [experiment_2019_10_09_10_58_54_0001] epoch #52 | performing update
2019-10-09 10:59:32 | [experiment_2019_10_09_10_58_54_0001] epoch #52 | computing gradient
2019-10-09 10:59:32 | [experiment_2019_10_09_10_58_54_0001] epoch #52 | gradient computed
2019-10-09 10:59:32 | [experiment_2019_10_09_10_58_54_0001] epoch #52 | computing descent direction
2019-10-09 10:59:32 | [experiment_2019_10_09_10_58_54_0001] epoch #52 | descent direction computed
2019-10-09 10:59:32 | [experiment_2019_10_09_10_58_54_0001] epoch #52 | backtrack iters: 0
2019-10-09 10:59:32 | [experiment_2019_10_09_10_58_54_0001] epoch #52 | computing loss after
2019-10-09 10:59:32 | [experiment_2019_10_09_10_58_54_0001] epoch #52 | optimization finished
2019-10-09 10:59:32 | [experiment_2019_10_09_10_58_54_0001] epoch #52 | Computing KL after
2019-10-09 10:59:32 | [experiment_2019_10_09_10_58_54_0001] epoch #52 | Computing loss after
2019-10-09 10:59:32 | [experiment_2019_10_09_10_58_54_0001] epoch #52 | Fitting baseline...
2019-10-09 10:59:32 | [experiment_2019_10_09_10_58_54_0001] epoch #52 | Saving snapshot...
2019-10-09 10:59:32 | [experiment_2019_10_09_10_58_54_0001] epoch #52 | Saved
2019-10-09 10:59:32 | [experiment_2019_10_09_10_58_54_0001] epoch #52 | Time 33.87 s
2019-10-09 10:59:32 | [experiment_2019_10_09_10_58_54_0001] epoch #52 | EpochTime 0.60 s
---------------------------------------  -------------
AverageDiscountedReturn                   63.3968
AverageReturn                            100
Entropy                                    0.529421
EnvExecTime                                0.0498805
Extras/EpisodeRewardMean                 100
Iteration                                 52
LinearFeatureBaseline/ExplainedVariance    1
MaxReturn                                100
MinReturn                                100
NumTrajs                                  40
Perplexity                                 1.69795
PolicyExecTime                             0.36385
ProcessExecTime                            0.017365
StdReturn                                  0
policy/Entropy                             0.532917
policy/KL                                  0.00766921
policy/KLBefore                            0
policy/LossAfter                          -0.00417211
policy/LossBefore                         -1.88351e-08
policy/dLoss                               0.00417209
---------------------------------------  -------------
2019-10-09 10:59:32 | [experiment_2019_10_09_10_58_54_0001] epoch #53 | Obtaining samples...
2019-10-09 10:59:32 | [experiment_2019_10_09_10_58_54_0001] epoch #53 | Obtaining samples for iteration 53...
2019-10-09 10:59:33 | [experiment_2019_10_09_10_58_54_0001] epoch #53 | Logging diagnostics...
2019-10-09 10:59:33 | [experiment_2019_10_09_10_58_54_0001] epoch #53 | Optimizing policy...
2019-10-09 10:59:33 | [experiment_2019_10_09_10_58_54_0001] epoch #53 | Computing loss before
2019-10-09 10:59:33 | [experiment_2019_10_09_10_58_54_0001] epoch #53 | Computing KL before
2019-10-09 10:59:33 | [experiment_2019_10_09_10_58_54_0001] epoch #53 | Optimizing
2019-10-09 10:59:33 | [experiment_2019_10_09_10_58_54_0001] epoch #53 | Start CG optimization: #parameters: 1282, #inputs: 41, #subsample_inputs: 41
2019-10-09 10:59:33 | [experiment_2019_10_09_10_58_54_0001] epoch #53 | computing loss before
2019-10-09 10:59:33 | [experiment_2019_10_09_10_58_54_0001] epoch #53 | performing update
2019-10-09 10:59:33 | [experiment_2019_10_09_10_58_54_0001] epoch #53 | computing gradient
2019-10-09 10:59:33 | [experiment_2019_10_09_10_58_54_0001] epoch #53 | gradient computed
2019-10-09 10:59:33 | [experiment_2019_10_09_10_58_54_0001] epoch #53 | computing descent direction
2019-10-09 10:59:33 | [experiment_2019_10_09_10_58_54_0001] epoch #53 | descent direction computed
2019-10-09 10:59:33 | [experiment_2019_10_09_10_58_54_0001] epoch #53 | backtrack iters: 2
2019-10-09 10:59:33 | [experiment_2019_10_09_10_58_54_0001] epoch #53 | computing loss after
2019-10-09 10:59:33 | [experiment_2019_10_09_10_58_54_0001] epoch #53 | optimization finished
2019-10-09 10:59:33 | [experiment_2019_10_09_10_58_54_0001] epoch #53 | Computing KL after
2019-10-09 10:59:33 | [experiment_2019_10_09_10_58_54_0001] epoch #53 | Computing loss after
2019-10-09 10:59:33 | [experiment_2019_10_09_10_58_54_0001] epoch #53 | Fitting baseline...
2019-10-09 10:59:33 | [experiment_2019_10_09_10_58_54_0001] epoch #53 | Saving snapshot...
2019-10-09 10:59:33 | [experiment_2019_10_09_10_58_54_0001] epoch #53 | Saved
2019-10-09 10:59:33 | [experiment_2019_10_09_10_58_54_0001] epoch #53 | Time 34.48 s
2019-10-09 10:59:33 | [experiment_2019_10_09_10_58_54_0001] epoch #53 | EpochTime 0.61 s
---------------------------------------  -------------
AverageDiscountedReturn                   62.4791
AverageReturn                             98.1463
Entropy                                    0.523268
EnvExecTime                                0.050782
Extras/EpisodeRewardMean                  99.24
Iteration                                 53
LinearFeatureBaseline/ExplainedVariance    0.954815
MaxReturn                                100
MinReturn                                 36
NumTrajs                                  41
Perplexity                                 1.68753
PolicyExecTime                             0.360964
ProcessExecTime                            0.0177488
StdReturn                                  9.93285
policy/Entropy                             0.497453
policy/KL                                  0.00677312
policy/KLBefore                           -7.87644e-11
policy/LossAfter                          -0.0110118
policy/LossBefore                          1.10203e-08
policy/dLoss                               0.0110118
---------------------------------------  -------------
2019-10-09 10:59:33 | [experiment_2019_10_09_10_58_54_0001] epoch #54 | Obtaining samples...
2019-10-09 10:59:33 | [experiment_2019_10_09_10_58_54_0001] epoch #54 | Obtaining samples for iteration 54...
2019-10-09 10:59:34 | [experiment_2019_10_09_10_58_54_0001] epoch #54 | Logging diagnostics...
2019-10-09 10:59:34 | [experiment_2019_10_09_10_58_54_0001] epoch #54 | Optimizing policy...
2019-10-09 10:59:34 | [experiment_2019_10_09_10_58_54_0001] epoch #54 | Computing loss before
2019-10-09 10:59:34 | [experiment_2019_10_09_10_58_54_0001] epoch #54 | Computing KL before
2019-10-09 10:59:34 | [experiment_2019_10_09_10_58_54_0001] epoch #54 | Optimizing
2019-10-09 10:59:34 | [experiment_2019_10_09_10_58_54_0001] epoch #54 | Start CG optimization: #parameters: 1282, #inputs: 40, #subsample_inputs: 40
2019-10-09 10:59:34 | [experiment_2019_10_09_10_58_54_0001] epoch #54 | computing loss before
2019-10-09 10:59:34 | [experiment_2019_10_09_10_58_54_0001] epoch #54 | performing update
2019-10-09 10:59:34 | [experiment_2019_10_09_10_58_54_0001] epoch #54 | computing gradient
2019-10-09 10:59:34 | [experiment_2019_10_09_10_58_54_0001] epoch #54 | gradient computed
2019-10-09 10:59:34 | [experiment_2019_10_09_10_58_54_0001] epoch #54 | computing descent direction
2019-10-09 10:59:34 | [experiment_2019_10_09_10_58_54_0001] epoch #54 | descent direction computed
2019-10-09 10:59:34 | [experiment_2019_10_09_10_58_54_0001] epoch #54 | backtrack iters: 0
2019-10-09 10:59:34 | [experiment_2019_10_09_10_58_54_0001] epoch #54 | computing loss after
2019-10-09 10:59:34 | [experiment_2019_10_09_10_58_54_0001] epoch #54 | optimization finished
2019-10-09 10:59:34 | [experiment_2019_10_09_10_58_54_0001] epoch #54 | Computing KL after
2019-10-09 10:59:34 | [experiment_2019_10_09_10_58_54_0001] epoch #54 | Computing loss after
2019-10-09 10:59:34 | [experiment_2019_10_09_10_58_54_0001] epoch #54 | Fitting baseline...
2019-10-09 10:59:34 | [experiment_2019_10_09_10_58_54_0001] epoch #54 | Saving snapshot...
2019-10-09 10:59:34 | [experiment_2019_10_09_10_58_54_0001] epoch #54 | Saved
2019-10-09 10:59:34 | [experiment_2019_10_09_10_58_54_0001] epoch #54 | Time 35.10 s
2019-10-09 10:59:34 | [experiment_2019_10_09_10_58_54_0001] epoch #54 | EpochTime 0.61 s
---------------------------------------  -------------
AverageDiscountedReturn                   63.3968
AverageReturn                            100
Entropy                                    0.510717
EnvExecTime                                0.0494871
Extras/EpisodeRewardMean                  99.24
Iteration                                 54
LinearFeatureBaseline/ExplainedVariance    0.997757
MaxReturn                                100
MinReturn                                100
NumTrajs                                  40
Perplexity                                 1.66649
PolicyExecTime                             0.376329
ProcessExecTime                            0.01757
StdReturn                                  0
policy/Entropy                             0.518513
policy/KL                                  0.00383657
policy/KLBefore                            0
policy/LossAfter                          -0.00242457
policy/LossBefore                         -1.06096e-08
policy/dLoss                               0.00242456
---------------------------------------  -------------
2019-10-09 10:59:34 | [experiment_2019_10_09_10_58_54_0001] epoch #55 | Obtaining samples...
2019-10-09 10:59:34 | [experiment_2019_10_09_10_58_54_0001] epoch #55 | Obtaining samples for iteration 55...
2019-10-09 10:59:34 | [experiment_2019_10_09_10_58_54_0001] epoch #55 | Logging diagnostics...
2019-10-09 10:59:34 | [experiment_2019_10_09_10_58_54_0001] epoch #55 | Optimizing policy...
2019-10-09 10:59:34 | [experiment_2019_10_09_10_58_54_0001] epoch #55 | Computing loss before
2019-10-09 10:59:34 | [experiment_2019_10_09_10_58_54_0001] epoch #55 | Computing KL before
2019-10-09 10:59:34 | [experiment_2019_10_09_10_58_54_0001] epoch #55 | Optimizing
2019-10-09 10:59:34 | [experiment_2019_10_09_10_58_54_0001] epoch #55 | Start CG optimization: #parameters: 1282, #inputs: 40, #subsample_inputs: 40
2019-10-09 10:59:34 | [experiment_2019_10_09_10_58_54_0001] epoch #55 | computing loss before
2019-10-09 10:59:34 | [experiment_2019_10_09_10_58_54_0001] epoch #55 | performing update
2019-10-09 10:59:34 | [experiment_2019_10_09_10_58_54_0001] epoch #55 | computing gradient
2019-10-09 10:59:34 | [experiment_2019_10_09_10_58_54_0001] epoch #55 | gradient computed
2019-10-09 10:59:34 | [experiment_2019_10_09_10_58_54_0001] epoch #55 | computing descent direction
2019-10-09 10:59:34 | [experiment_2019_10_09_10_58_54_0001] epoch #55 | descent direction computed
2019-10-09 10:59:34 | [experiment_2019_10_09_10_58_54_0001] epoch #55 | backtrack iters: 1
2019-10-09 10:59:34 | [experiment_2019_10_09_10_58_54_0001] epoch #55 | computing loss after
2019-10-09 10:59:34 | [experiment_2019_10_09_10_58_54_0001] epoch #55 | optimization finished
2019-10-09 10:59:34 | [experiment_2019_10_09_10_58_54_0001] epoch #55 | Computing KL after
2019-10-09 10:59:34 | [experiment_2019_10_09_10_58_54_0001] epoch #55 | Computing loss after
2019-10-09 10:59:34 | [experiment_2019_10_09_10_58_54_0001] epoch #55 | Fitting baseline...
2019-10-09 10:59:34 | [experiment_2019_10_09_10_58_54_0001] epoch #55 | Saving snapshot...
2019-10-09 10:59:34 | [experiment_2019_10_09_10_58_54_0001] epoch #55 | Saved
2019-10-09 10:59:34 | [experiment_2019_10_09_10_58_54_0001] epoch #55 | Time 35.68 s
2019-10-09 10:59:34 | [experiment_2019_10_09_10_58_54_0001] epoch #55 | EpochTime 0.58 s
---------------------------------------  -------------
AverageDiscountedReturn                   63.3968
AverageReturn                            100
Entropy                                    0.514075
EnvExecTime                                0.0493407
Extras/EpisodeRewardMean                  99.24
Iteration                                 55
LinearFeatureBaseline/ExplainedVariance    1
MaxReturn                                100
MinReturn                                100
NumTrajs                                  40
Perplexity                                 1.67209
PolicyExecTime                             0.343001
ProcessExecTime                            0.017328
StdReturn                                  0
policy/Entropy                             0.497777
policy/KL                                  0.00658226
policy/KLBefore                            0
policy/LossAfter                          -0.00611608
policy/LossBefore                          4.29153e-09
policy/dLoss                               0.00611608
---------------------------------------  -------------
2019-10-09 10:59:34 | [experiment_2019_10_09_10_58_54_0001] epoch #56 | Obtaining samples...
2019-10-09 10:59:34 | [experiment_2019_10_09_10_58_54_0001] epoch #56 | Obtaining samples for iteration 56...
2019-10-09 10:59:35 | [experiment_2019_10_09_10_58_54_0001] epoch #56 | Logging diagnostics...
2019-10-09 10:59:35 | [experiment_2019_10_09_10_58_54_0001] epoch #56 | Optimizing policy...
2019-10-09 10:59:35 | [experiment_2019_10_09_10_58_54_0001] epoch #56 | Computing loss before
2019-10-09 10:59:35 | [experiment_2019_10_09_10_58_54_0001] epoch #56 | Computing KL before
2019-10-09 10:59:35 | [experiment_2019_10_09_10_58_54_0001] epoch #56 | Optimizing
2019-10-09 10:59:35 | [experiment_2019_10_09_10_58_54_0001] epoch #56 | Start CG optimization: #parameters: 1282, #inputs: 40, #subsample_inputs: 40
2019-10-09 10:59:35 | [experiment_2019_10_09_10_58_54_0001] epoch #56 | computing loss before
2019-10-09 10:59:35 | [experiment_2019_10_09_10_58_54_0001] epoch #56 | performing update
2019-10-09 10:59:35 | [experiment_2019_10_09_10_58_54_0001] epoch #56 | computing gradient
2019-10-09 10:59:35 | [experiment_2019_10_09_10_58_54_0001] epoch #56 | gradient computed
2019-10-09 10:59:35 | [experiment_2019_10_09_10_58_54_0001] epoch #56 | computing descent direction
2019-10-09 10:59:35 | [experiment_2019_10_09_10_58_54_0001] epoch #56 | descent direction computed
2019-10-09 10:59:35 | [experiment_2019_10_09_10_58_54_0001] epoch #56 | backtrack iters: 5
2019-10-09 10:59:35 | [experiment_2019_10_09_10_58_54_0001] epoch #56 | computing loss after
2019-10-09 10:59:35 | [experiment_2019_10_09_10_58_54_0001] epoch #56 | optimization finished
2019-10-09 10:59:35 | [experiment_2019_10_09_10_58_54_0001] epoch #56 | Computing KL after
2019-10-09 10:59:35 | [experiment_2019_10_09_10_58_54_0001] epoch #56 | Computing loss after
2019-10-09 10:59:35 | [experiment_2019_10_09_10_58_54_0001] epoch #56 | Fitting baseline...
2019-10-09 10:59:35 | [experiment_2019_10_09_10_58_54_0001] epoch #56 | Saving snapshot...
2019-10-09 10:59:35 | [experiment_2019_10_09_10_58_54_0001] epoch #56 | Saved
2019-10-09 10:59:35 | [experiment_2019_10_09_10_58_54_0001] epoch #56 | Time 36.31 s
2019-10-09 10:59:35 | [experiment_2019_10_09_10_58_54_0001] epoch #56 | EpochTime 0.62 s
---------------------------------------  -------------
AverageDiscountedReturn                   63.3968
AverageReturn                            100
Entropy                                    0.50784
EnvExecTime                                0.0503595
Extras/EpisodeRewardMean                 100
Iteration                                 56
LinearFeatureBaseline/ExplainedVariance    1
MaxReturn                                100
MinReturn                                100
NumTrajs                                  40
Perplexity                                 1.6617
PolicyExecTime                             0.369388
ProcessExecTime                            0.0172343
StdReturn                                  0
policy/Entropy                             0.501107
policy/KL                                  0.00482787
policy/KLBefore                            0
policy/LossAfter                          -0.00343076
policy/LossBefore                         -8.46386e-09
policy/dLoss                               0.00343075
---------------------------------------  -------------
2019-10-09 10:59:35 | [experiment_2019_10_09_10_58_54_0001] epoch #57 | Obtaining samples...
2019-10-09 10:59:35 | [experiment_2019_10_09_10_58_54_0001] epoch #57 | Obtaining samples for iteration 57...
2019-10-09 10:59:35 | [experiment_2019_10_09_10_58_54_0001] epoch #57 | Logging diagnostics...
2019-10-09 10:59:35 | [experiment_2019_10_09_10_58_54_0001] epoch #57 | Optimizing policy...
2019-10-09 10:59:35 | [experiment_2019_10_09_10_58_54_0001] epoch #57 | Computing loss before
2019-10-09 10:59:35 | [experiment_2019_10_09_10_58_54_0001] epoch #57 | Computing KL before
2019-10-09 10:59:35 | [experiment_2019_10_09_10_58_54_0001] epoch #57 | Optimizing
2019-10-09 10:59:35 | [experiment_2019_10_09_10_58_54_0001] epoch #57 | Start CG optimization: #parameters: 1282, #inputs: 41, #subsample_inputs: 41
2019-10-09 10:59:35 | [experiment_2019_10_09_10_58_54_0001] epoch #57 | computing loss before
2019-10-09 10:59:35 | [experiment_2019_10_09_10_58_54_0001] epoch #57 | performing update
2019-10-09 10:59:35 | [experiment_2019_10_09_10_58_54_0001] epoch #57 | computing gradient
2019-10-09 10:59:35 | [experiment_2019_10_09_10_58_54_0001] epoch #57 | gradient computed
2019-10-09 10:59:35 | [experiment_2019_10_09_10_58_54_0001] epoch #57 | computing descent direction
2019-10-09 10:59:36 | [experiment_2019_10_09_10_58_54_0001] epoch #57 | descent direction computed
2019-10-09 10:59:36 | [experiment_2019_10_09_10_58_54_0001] epoch #57 | backtrack iters: 2
2019-10-09 10:59:36 | [experiment_2019_10_09_10_58_54_0001] epoch #57 | computing loss after
2019-10-09 10:59:36 | [experiment_2019_10_09_10_58_54_0001] epoch #57 | optimization finished
2019-10-09 10:59:36 | [experiment_2019_10_09_10_58_54_0001] epoch #57 | Computing KL after
2019-10-09 10:59:36 | [experiment_2019_10_09_10_58_54_0001] epoch #57 | Computing loss after
2019-10-09 10:59:36 | [experiment_2019_10_09_10_58_54_0001] epoch #57 | Fitting baseline...
2019-10-09 10:59:36 | [experiment_2019_10_09_10_58_54_0001] epoch #57 | Saving snapshot...
2019-10-09 10:59:36 | [experiment_2019_10_09_10_58_54_0001] epoch #57 | Saved
2019-10-09 10:59:36 | [experiment_2019_10_09_10_58_54_0001] epoch #57 | Time 36.95 s
2019-10-09 10:59:36 | [experiment_2019_10_09_10_58_54_0001] epoch #57 | EpochTime 0.64 s
---------------------------------------  -------------
AverageDiscountedReturn                   63.3122
AverageReturn                             99.7805
Entropy                                    0.515396
EnvExecTime                                0.053957
Extras/EpisodeRewardMean                  99.91
Iteration                                 57
LinearFeatureBaseline/ExplainedVariance    0.997729
MaxReturn                                100
MinReturn                                 91
NumTrajs                                  41
Perplexity                                 1.6743
PolicyExecTime                             0.389682
ProcessExecTime                            0.0189483
StdReturn                                  1.38832
policy/Entropy                             0.48995
policy/KL                                  0.00973843
policy/KLBefore                           -1.82569e-10
policy/LossAfter                          -0.0162792
policy/LossBefore                          1.90535e-08
policy/dLoss                               0.0162792
---------------------------------------  -------------
2019-10-09 10:59:36 | [experiment_2019_10_09_10_58_54_0001] epoch #58 | Obtaining samples...
2019-10-09 10:59:36 | [experiment_2019_10_09_10_58_54_0001] epoch #58 | Obtaining samples for iteration 58...
2019-10-09 10:59:36 | [experiment_2019_10_09_10_58_54_0001] epoch #58 | Logging diagnostics...
2019-10-09 10:59:36 | [experiment_2019_10_09_10_58_54_0001] epoch #58 | Optimizing policy...
2019-10-09 10:59:36 | [experiment_2019_10_09_10_58_54_0001] epoch #58 | Computing loss before
2019-10-09 10:59:36 | [experiment_2019_10_09_10_58_54_0001] epoch #58 | Computing KL before
2019-10-09 10:59:36 | [experiment_2019_10_09_10_58_54_0001] epoch #58 | Optimizing
2019-10-09 10:59:36 | [experiment_2019_10_09_10_58_54_0001] epoch #58 | Start CG optimization: #parameters: 1282, #inputs: 40, #subsample_inputs: 40
2019-10-09 10:59:36 | [experiment_2019_10_09_10_58_54_0001] epoch #58 | computing loss before
2019-10-09 10:59:36 | [experiment_2019_10_09_10_58_54_0001] epoch #58 | performing update
2019-10-09 10:59:36 | [experiment_2019_10_09_10_58_54_0001] epoch #58 | computing gradient
2019-10-09 10:59:36 | [experiment_2019_10_09_10_58_54_0001] epoch #58 | gradient computed
2019-10-09 10:59:36 | [experiment_2019_10_09_10_58_54_0001] epoch #58 | computing descent direction
2019-10-09 10:59:36 | [experiment_2019_10_09_10_58_54_0001] epoch #58 | descent direction computed
2019-10-09 10:59:36 | [experiment_2019_10_09_10_58_54_0001] epoch #58 | backtrack iters: 4
2019-10-09 10:59:36 | [experiment_2019_10_09_10_58_54_0001] epoch #58 | computing loss after
2019-10-09 10:59:36 | [experiment_2019_10_09_10_58_54_0001] epoch #58 | optimization finished
2019-10-09 10:59:36 | [experiment_2019_10_09_10_58_54_0001] epoch #58 | Computing KL after
2019-10-09 10:59:36 | [experiment_2019_10_09_10_58_54_0001] epoch #58 | Computing loss after
2019-10-09 10:59:36 | [experiment_2019_10_09_10_58_54_0001] epoch #58 | Fitting baseline...
2019-10-09 10:59:36 | [experiment_2019_10_09_10_58_54_0001] epoch #58 | Saving snapshot...
2019-10-09 10:59:36 | [experiment_2019_10_09_10_58_54_0001] epoch #58 | Saved
2019-10-09 10:59:36 | [experiment_2019_10_09_10_58_54_0001] epoch #58 | Time 37.55 s
2019-10-09 10:59:36 | [experiment_2019_10_09_10_58_54_0001] epoch #58 | EpochTime 0.60 s
---------------------------------------  -------------
AverageDiscountedReturn                   63.3968
AverageReturn                            100
Entropy                                    0.500185
EnvExecTime                                0.049901
Extras/EpisodeRewardMean                  99.91
Iteration                                 58
LinearFeatureBaseline/ExplainedVariance    0.999859
MaxReturn                                100
MinReturn                                100
NumTrajs                                  40
Perplexity                                 1.64903
PolicyExecTime                             0.352575
ProcessExecTime                            0.0173025
StdReturn                                  0
policy/Entropy                             0.479545
policy/KL                                  0.00569001
policy/KLBefore                            0
policy/LossAfter                          -0.0021803
policy/LossBefore                          1.00136e-08
policy/dLoss                               0.00218031
---------------------------------------  -------------
2019-10-09 10:59:36 | [experiment_2019_10_09_10_58_54_0001] epoch #59 | Obtaining samples...
2019-10-09 10:59:36 | [experiment_2019_10_09_10_58_54_0001] epoch #59 | Obtaining samples for iteration 59...
2019-10-09 10:59:37 | [experiment_2019_10_09_10_58_54_0001] epoch #59 | Logging diagnostics...
2019-10-09 10:59:37 | [experiment_2019_10_09_10_58_54_0001] epoch #59 | Optimizing policy...
2019-10-09 10:59:37 | [experiment_2019_10_09_10_58_54_0001] epoch #59 | Computing loss before
2019-10-09 10:59:37 | [experiment_2019_10_09_10_58_54_0001] epoch #59 | Computing KL before
2019-10-09 10:59:37 | [experiment_2019_10_09_10_58_54_0001] epoch #59 | Optimizing
2019-10-09 10:59:37 | [experiment_2019_10_09_10_58_54_0001] epoch #59 | Start CG optimization: #parameters: 1282, #inputs: 40, #subsample_inputs: 40
2019-10-09 10:59:37 | [experiment_2019_10_09_10_58_54_0001] epoch #59 | computing loss before
2019-10-09 10:59:37 | [experiment_2019_10_09_10_58_54_0001] epoch #59 | performing update
2019-10-09 10:59:37 | [experiment_2019_10_09_10_58_54_0001] epoch #59 | computing gradient
2019-10-09 10:59:37 | [experiment_2019_10_09_10_58_54_0001] epoch #59 | gradient computed
2019-10-09 10:59:37 | [experiment_2019_10_09_10_58_54_0001] epoch #59 | computing descent direction
2019-10-09 10:59:37 | [experiment_2019_10_09_10_58_54_0001] epoch #59 | descent direction computed
2019-10-09 10:59:37 | [experiment_2019_10_09_10_58_54_0001] epoch #59 | backtrack iters: 3
2019-10-09 10:59:37 | [experiment_2019_10_09_10_58_54_0001] epoch #59 | computing loss after
2019-10-09 10:59:37 | [experiment_2019_10_09_10_58_54_0001] epoch #59 | optimization finished
2019-10-09 10:59:37 | [experiment_2019_10_09_10_58_54_0001] epoch #59 | Computing KL after
2019-10-09 10:59:37 | [experiment_2019_10_09_10_58_54_0001] epoch #59 | Computing loss after
2019-10-09 10:59:37 | [experiment_2019_10_09_10_58_54_0001] epoch #59 | Fitting baseline...
2019-10-09 10:59:37 | [experiment_2019_10_09_10_58_54_0001] epoch #59 | Saving snapshot...
2019-10-09 10:59:37 | [experiment_2019_10_09_10_58_54_0001] epoch #59 | Saved
2019-10-09 10:59:37 | [experiment_2019_10_09_10_58_54_0001] epoch #59 | Time 38.15 s
2019-10-09 10:59:37 | [experiment_2019_10_09_10_58_54_0001] epoch #59 | EpochTime 0.59 s
---------------------------------------  -------------
AverageDiscountedReturn                   63.3968
AverageReturn                            100
Entropy                                    0.489971
EnvExecTime                                0.050215
Extras/EpisodeRewardMean                  99.91
Iteration                                 59
LinearFeatureBaseline/ExplainedVariance    1
MaxReturn                                100
MinReturn                                100
NumTrajs                                  40
Perplexity                                 1.63227
PolicyExecTime                             0.352075
ProcessExecTime                            0.017379
StdReturn                                  0
policy/Entropy                             0.500045
policy/KL                                  0.0050462
policy/KLBefore                            0
policy/LossAfter                          -0.00325071
policy/LossBefore                         -1.58548e-08
policy/dLoss                               0.00325069
---------------------------------------  -------------
2019-10-09 10:59:37 | [experiment_2019_10_09_10_58_54_0001] epoch #60 | Obtaining samples...
2019-10-09 10:59:37 | [experiment_2019_10_09_10_58_54_0001] epoch #60 | Obtaining samples for iteration 60...
2019-10-09 10:59:37 | [experiment_2019_10_09_10_58_54_0001] epoch #60 | Logging diagnostics...
2019-10-09 10:59:37 | [experiment_2019_10_09_10_58_54_0001] epoch #60 | Optimizing policy...
2019-10-09 10:59:37 | [experiment_2019_10_09_10_58_54_0001] epoch #60 | Computing loss before
2019-10-09 10:59:37 | [experiment_2019_10_09_10_58_54_0001] epoch #60 | Computing KL before
2019-10-09 10:59:37 | [experiment_2019_10_09_10_58_54_0001] epoch #60 | Optimizing
2019-10-09 10:59:37 | [experiment_2019_10_09_10_58_54_0001] epoch #60 | Start CG optimization: #parameters: 1282, #inputs: 40, #subsample_inputs: 40
2019-10-09 10:59:37 | [experiment_2019_10_09_10_58_54_0001] epoch #60 | computing loss before
2019-10-09 10:59:37 | [experiment_2019_10_09_10_58_54_0001] epoch #60 | performing update
2019-10-09 10:59:37 | [experiment_2019_10_09_10_58_54_0001] epoch #60 | computing gradient
2019-10-09 10:59:37 | [experiment_2019_10_09_10_58_54_0001] epoch #60 | gradient computed
2019-10-09 10:59:37 | [experiment_2019_10_09_10_58_54_0001] epoch #60 | computing descent direction
2019-10-09 10:59:37 | [experiment_2019_10_09_10_58_54_0001] epoch #60 | descent direction computed
2019-10-09 10:59:37 | [experiment_2019_10_09_10_58_54_0001] epoch #60 | backtrack iters: 4
2019-10-09 10:59:37 | [experiment_2019_10_09_10_58_54_0001] epoch #60 | computing loss after
2019-10-09 10:59:37 | [experiment_2019_10_09_10_58_54_0001] epoch #60 | optimization finished
2019-10-09 10:59:37 | [experiment_2019_10_09_10_58_54_0001] epoch #60 | Computing KL after
2019-10-09 10:59:37 | [experiment_2019_10_09_10_58_54_0001] epoch #60 | Computing loss after
2019-10-09 10:59:37 | [experiment_2019_10_09_10_58_54_0001] epoch #60 | Fitting baseline...
2019-10-09 10:59:37 | [experiment_2019_10_09_10_58_54_0001] epoch #60 | Saving snapshot...
2019-10-09 10:59:37 | [experiment_2019_10_09_10_58_54_0001] epoch #60 | Saved
2019-10-09 10:59:37 | [experiment_2019_10_09_10_58_54_0001] epoch #60 | Time 38.75 s
2019-10-09 10:59:37 | [experiment_2019_10_09_10_58_54_0001] epoch #60 | EpochTime 0.60 s
---------------------------------------  -------------
AverageDiscountedReturn                   63.3968
AverageReturn                            100
Entropy                                    0.496668
EnvExecTime                                0.0500371
Extras/EpisodeRewardMean                 100
Iteration                                 60
LinearFeatureBaseline/ExplainedVariance    1
MaxReturn                                100
MinReturn                                100
NumTrajs                                  40
Perplexity                                 1.64324
PolicyExecTime                             0.353195
ProcessExecTime                            0.0174901
StdReturn                                  0
policy/Entropy                             0.480207
policy/KL                                  0.0070544
policy/KLBefore                            0
policy/LossAfter                          -0.00375588
policy/LossBefore                          2.38419e-10
policy/dLoss                               0.00375588
---------------------------------------  -------------
2019-10-09 10:59:37 | [experiment_2019_10_09_10_58_54_0001] epoch #61 | Obtaining samples...
2019-10-09 10:59:37 | [experiment_2019_10_09_10_58_54_0001] epoch #61 | Obtaining samples for iteration 61...
2019-10-09 10:59:38 | [experiment_2019_10_09_10_58_54_0001] epoch #61 | Logging diagnostics...
2019-10-09 10:59:38 | [experiment_2019_10_09_10_58_54_0001] epoch #61 | Optimizing policy...
2019-10-09 10:59:38 | [experiment_2019_10_09_10_58_54_0001] epoch #61 | Computing loss before
2019-10-09 10:59:38 | [experiment_2019_10_09_10_58_54_0001] epoch #61 | Computing KL before
2019-10-09 10:59:38 | [experiment_2019_10_09_10_58_54_0001] epoch #61 | Optimizing
2019-10-09 10:59:38 | [experiment_2019_10_09_10_58_54_0001] epoch #61 | Start CG optimization: #parameters: 1282, #inputs: 40, #subsample_inputs: 40
2019-10-09 10:59:38 | [experiment_2019_10_09_10_58_54_0001] epoch #61 | computing loss before
2019-10-09 10:59:38 | [experiment_2019_10_09_10_58_54_0001] epoch #61 | performing update
2019-10-09 10:59:38 | [experiment_2019_10_09_10_58_54_0001] epoch #61 | computing gradient
2019-10-09 10:59:38 | [experiment_2019_10_09_10_58_54_0001] epoch #61 | gradient computed
2019-10-09 10:59:38 | [experiment_2019_10_09_10_58_54_0001] epoch #61 | computing descent direction
2019-10-09 10:59:38 | [experiment_2019_10_09_10_58_54_0001] epoch #61 | descent direction computed
2019-10-09 10:59:38 | [experiment_2019_10_09_10_58_54_0001] epoch #61 | backtrack iters: 3
2019-10-09 10:59:38 | [experiment_2019_10_09_10_58_54_0001] epoch #61 | computing loss after
2019-10-09 10:59:38 | [experiment_2019_10_09_10_58_54_0001] epoch #61 | optimization finished
2019-10-09 10:59:38 | [experiment_2019_10_09_10_58_54_0001] epoch #61 | Computing KL after
2019-10-09 10:59:38 | [experiment_2019_10_09_10_58_54_0001] epoch #61 | Computing loss after
2019-10-09 10:59:38 | [experiment_2019_10_09_10_58_54_0001] epoch #61 | Fitting baseline...
2019-10-09 10:59:38 | [experiment_2019_10_09_10_58_54_0001] epoch #61 | Saving snapshot...
2019-10-09 10:59:38 | [experiment_2019_10_09_10_58_54_0001] epoch #61 | Saved
2019-10-09 10:59:38 | [experiment_2019_10_09_10_58_54_0001] epoch #61 | Time 39.37 s
2019-10-09 10:59:38 | [experiment_2019_10_09_10_58_54_0001] epoch #61 | EpochTime 0.61 s
---------------------------------------  -------------
AverageDiscountedReturn                   63.3968
AverageReturn                            100
Entropy                                    0.494581
EnvExecTime                                0.0503035
Extras/EpisodeRewardMean                 100
Iteration                                 61
LinearFeatureBaseline/ExplainedVariance    1
MaxReturn                                100
MinReturn                                100
NumTrajs                                  40
Perplexity                                 1.63981
PolicyExecTime                             0.36363
ProcessExecTime                            0.017524
StdReturn                                  0
policy/Entropy                             0.491112
policy/KL                                  0.00863279
policy/KLBefore                            0
policy/LossAfter                          -0.00640456
policy/LossBefore                         -1.01328e-08
policy/dLoss                               0.00640455
---------------------------------------  -------------
2019-10-09 10:59:38 | [experiment_2019_10_09_10_58_54_0001] epoch #62 | Obtaining samples...
2019-10-09 10:59:38 | [experiment_2019_10_09_10_58_54_0001] epoch #62 | Obtaining samples for iteration 62...
2019-10-09 10:59:38 | [experiment_2019_10_09_10_58_54_0001] epoch #62 | Logging diagnostics...
2019-10-09 10:59:38 | [experiment_2019_10_09_10_58_54_0001] epoch #62 | Optimizing policy...
2019-10-09 10:59:38 | [experiment_2019_10_09_10_58_54_0001] epoch #62 | Computing loss before
2019-10-09 10:59:38 | [experiment_2019_10_09_10_58_54_0001] epoch #62 | Computing KL before
2019-10-09 10:59:38 | [experiment_2019_10_09_10_58_54_0001] epoch #62 | Optimizing
2019-10-09 10:59:38 | [experiment_2019_10_09_10_58_54_0001] epoch #62 | Start CG optimization: #parameters: 1282, #inputs: 40, #subsample_inputs: 40
2019-10-09 10:59:38 | [experiment_2019_10_09_10_58_54_0001] epoch #62 | computing loss before
2019-10-09 10:59:38 | [experiment_2019_10_09_10_58_54_0001] epoch #62 | performing update
2019-10-09 10:59:38 | [experiment_2019_10_09_10_58_54_0001] epoch #62 | computing gradient
2019-10-09 10:59:38 | [experiment_2019_10_09_10_58_54_0001] epoch #62 | gradient computed
2019-10-09 10:59:38 | [experiment_2019_10_09_10_58_54_0001] epoch #62 | computing descent direction
2019-10-09 10:59:39 | [experiment_2019_10_09_10_58_54_0001] epoch #62 | descent direction computed
2019-10-09 10:59:39 | [experiment_2019_10_09_10_58_54_0001] epoch #62 | backtrack iters: 3
2019-10-09 10:59:39 | [experiment_2019_10_09_10_58_54_0001] epoch #62 | computing loss after
2019-10-09 10:59:39 | [experiment_2019_10_09_10_58_54_0001] epoch #62 | optimization finished
2019-10-09 10:59:39 | [experiment_2019_10_09_10_58_54_0001] epoch #62 | Computing KL after
2019-10-09 10:59:39 | [experiment_2019_10_09_10_58_54_0001] epoch #62 | Computing loss after
2019-10-09 10:59:39 | [experiment_2019_10_09_10_58_54_0001] epoch #62 | Fitting baseline...
2019-10-09 10:59:39 | [experiment_2019_10_09_10_58_54_0001] epoch #62 | Saving snapshot...
2019-10-09 10:59:39 | [experiment_2019_10_09_10_58_54_0001] epoch #62 | Saved
2019-10-09 10:59:39 | [experiment_2019_10_09_10_58_54_0001] epoch #62 | Time 39.97 s
2019-10-09 10:59:39 | [experiment_2019_10_09_10_58_54_0001] epoch #62 | EpochTime 0.60 s
---------------------------------------  -------------
AverageDiscountedReturn                   63.3968
AverageReturn                            100
Entropy                                    0.477766
EnvExecTime                                0.0494015
Extras/EpisodeRewardMean                 100
Iteration                                 62
LinearFeatureBaseline/ExplainedVariance    1
MaxReturn                                100
MinReturn                                100
NumTrajs                                  40
Perplexity                                 1.61247
PolicyExecTime                             0.348139
ProcessExecTime                            0.0175593
StdReturn                                  0
policy/Entropy                             0.493899
policy/KL                                  0.00540104
policy/KLBefore                            0
policy/LossAfter                          -0.00722706
policy/LossBefore                         -1.57356e-08
policy/dLoss                               0.00722704
---------------------------------------  -------------
2019-10-09 10:59:39 | [experiment_2019_10_09_10_58_54_0001] epoch #63 | Obtaining samples...
2019-10-09 10:59:39 | [experiment_2019_10_09_10_58_54_0001] epoch #63 | Obtaining samples for iteration 63...
2019-10-09 10:59:39 | [experiment_2019_10_09_10_58_54_0001] epoch #63 | Logging diagnostics...
2019-10-09 10:59:39 | [experiment_2019_10_09_10_58_54_0001] epoch #63 | Optimizing policy...
2019-10-09 10:59:39 | [experiment_2019_10_09_10_58_54_0001] epoch #63 | Computing loss before
2019-10-09 10:59:39 | [experiment_2019_10_09_10_58_54_0001] epoch #63 | Computing KL before
2019-10-09 10:59:39 | [experiment_2019_10_09_10_58_54_0001] epoch #63 | Optimizing
2019-10-09 10:59:39 | [experiment_2019_10_09_10_58_54_0001] epoch #63 | Start CG optimization: #parameters: 1282, #inputs: 40, #subsample_inputs: 40
2019-10-09 10:59:39 | [experiment_2019_10_09_10_58_54_0001] epoch #63 | computing loss before
2019-10-09 10:59:39 | [experiment_2019_10_09_10_58_54_0001] epoch #63 | performing update
2019-10-09 10:59:39 | [experiment_2019_10_09_10_58_54_0001] epoch #63 | computing gradient
2019-10-09 10:59:39 | [experiment_2019_10_09_10_58_54_0001] epoch #63 | gradient computed
2019-10-09 10:59:39 | [experiment_2019_10_09_10_58_54_0001] epoch #63 | computing descent direction
2019-10-09 10:59:39 | [experiment_2019_10_09_10_58_54_0001] epoch #63 | descent direction computed
2019-10-09 10:59:39 | [experiment_2019_10_09_10_58_54_0001] epoch #63 | backtrack iters: 2
2019-10-09 10:59:39 | [experiment_2019_10_09_10_58_54_0001] epoch #63 | computing loss after
2019-10-09 10:59:39 | [experiment_2019_10_09_10_58_54_0001] epoch #63 | optimization finished
2019-10-09 10:59:39 | [experiment_2019_10_09_10_58_54_0001] epoch #63 | Computing KL after
2019-10-09 10:59:39 | [experiment_2019_10_09_10_58_54_0001] epoch #63 | Computing loss after
2019-10-09 10:59:39 | [experiment_2019_10_09_10_58_54_0001] epoch #63 | Fitting baseline...
2019-10-09 10:59:39 | [experiment_2019_10_09_10_58_54_0001] epoch #63 | Saving snapshot...
2019-10-09 10:59:39 | [experiment_2019_10_09_10_58_54_0001] epoch #63 | Saved
2019-10-09 10:59:39 | [experiment_2019_10_09_10_58_54_0001] epoch #63 | Time 40.59 s
2019-10-09 10:59:39 | [experiment_2019_10_09_10_58_54_0001] epoch #63 | EpochTime 0.62 s
---------------------------------------  -------------
AverageDiscountedReturn                   63.3968
AverageReturn                            100
Entropy                                    0.486822
EnvExecTime                                0.0514863
Extras/EpisodeRewardMean                 100
Iteration                                 63
LinearFeatureBaseline/ExplainedVariance    1
MaxReturn                                100
MinReturn                                100
NumTrajs                                  40
Perplexity                                 1.62714
PolicyExecTime                             0.370611
ProcessExecTime                            0.0179968
StdReturn                                  0
policy/Entropy                             0.504921
policy/KL                                  0.00789035
policy/KLBefore                            0
policy/LossAfter                          -0.00849228
policy/LossBefore                         -5.96046e-10
policy/dLoss                               0.00849228
---------------------------------------  -------------
2019-10-09 10:59:39 | [experiment_2019_10_09_10_58_54_0001] epoch #64 | Obtaining samples...
2019-10-09 10:59:39 | [experiment_2019_10_09_10_58_54_0001] epoch #64 | Obtaining samples for iteration 64...
2019-10-09 10:59:40 | [experiment_2019_10_09_10_58_54_0001] epoch #64 | Logging diagnostics...
2019-10-09 10:59:40 | [experiment_2019_10_09_10_58_54_0001] epoch #64 | Optimizing policy...
2019-10-09 10:59:40 | [experiment_2019_10_09_10_58_54_0001] epoch #64 | Computing loss before
2019-10-09 10:59:40 | [experiment_2019_10_09_10_58_54_0001] epoch #64 | Computing KL before
2019-10-09 10:59:40 | [experiment_2019_10_09_10_58_54_0001] epoch #64 | Optimizing
2019-10-09 10:59:40 | [experiment_2019_10_09_10_58_54_0001] epoch #64 | Start CG optimization: #parameters: 1282, #inputs: 40, #subsample_inputs: 40
2019-10-09 10:59:40 | [experiment_2019_10_09_10_58_54_0001] epoch #64 | computing loss before
2019-10-09 10:59:40 | [experiment_2019_10_09_10_58_54_0001] epoch #64 | performing update
2019-10-09 10:59:40 | [experiment_2019_10_09_10_58_54_0001] epoch #64 | computing gradient
2019-10-09 10:59:40 | [experiment_2019_10_09_10_58_54_0001] epoch #64 | gradient computed
2019-10-09 10:59:40 | [experiment_2019_10_09_10_58_54_0001] epoch #64 | computing descent direction
2019-10-09 10:59:40 | [experiment_2019_10_09_10_58_54_0001] epoch #64 | descent direction computed
2019-10-09 10:59:40 | [experiment_2019_10_09_10_58_54_0001] epoch #64 | backtrack iters: 2
2019-10-09 10:59:40 | [experiment_2019_10_09_10_58_54_0001] epoch #64 | computing loss after
2019-10-09 10:59:40 | [experiment_2019_10_09_10_58_54_0001] epoch #64 | optimization finished
2019-10-09 10:59:40 | [experiment_2019_10_09_10_58_54_0001] epoch #64 | Computing KL after
2019-10-09 10:59:40 | [experiment_2019_10_09_10_58_54_0001] epoch #64 | Computing loss after
2019-10-09 10:59:40 | [experiment_2019_10_09_10_58_54_0001] epoch #64 | Fitting baseline...
2019-10-09 10:59:40 | [experiment_2019_10_09_10_58_54_0001] epoch #64 | Saving snapshot...
2019-10-09 10:59:40 | [experiment_2019_10_09_10_58_54_0001] epoch #64 | Saved
2019-10-09 10:59:40 | [experiment_2019_10_09_10_58_54_0001] epoch #64 | Time 41.21 s
2019-10-09 10:59:40 | [experiment_2019_10_09_10_58_54_0001] epoch #64 | EpochTime 0.62 s
---------------------------------------  ------------
AverageDiscountedReturn                   63.3968
AverageReturn                            100
Entropy                                    0.510871
EnvExecTime                                0.0498018
Extras/EpisodeRewardMean                 100
Iteration                                 64
LinearFeatureBaseline/ExplainedVariance    1
MaxReturn                                100
MinReturn                                100
NumTrajs                                  40
Perplexity                                 1.66674
PolicyExecTime                             0.372298
ProcessExecTime                            0.0175376
StdReturn                                  0
policy/Entropy                             0.524721
policy/KL                                  0.00793116
policy/KLBefore                            0
policy/LossAfter                          -0.00486516
policy/LossBefore                          3.8147e-09
policy/dLoss                               0.00486517
---------------------------------------  ------------
2019-10-09 10:59:40 | [experiment_2019_10_09_10_58_54_0001] epoch #65 | Obtaining samples...
2019-10-09 10:59:40 | [experiment_2019_10_09_10_58_54_0001] epoch #65 | Obtaining samples for iteration 65...
2019-10-09 10:59:40 | [experiment_2019_10_09_10_58_54_0001] epoch #65 | Logging diagnostics...
2019-10-09 10:59:40 | [experiment_2019_10_09_10_58_54_0001] epoch #65 | Optimizing policy...
2019-10-09 10:59:40 | [experiment_2019_10_09_10_58_54_0001] epoch #65 | Computing loss before
2019-10-09 10:59:40 | [experiment_2019_10_09_10_58_54_0001] epoch #65 | Computing KL before
2019-10-09 10:59:40 | [experiment_2019_10_09_10_58_54_0001] epoch #65 | Optimizing
2019-10-09 10:59:40 | [experiment_2019_10_09_10_58_54_0001] epoch #65 | Start CG optimization: #parameters: 1282, #inputs: 40, #subsample_inputs: 40
2019-10-09 10:59:40 | [experiment_2019_10_09_10_58_54_0001] epoch #65 | computing loss before
2019-10-09 10:59:40 | [experiment_2019_10_09_10_58_54_0001] epoch #65 | performing update
2019-10-09 10:59:40 | [experiment_2019_10_09_10_58_54_0001] epoch #65 | computing gradient
2019-10-09 10:59:40 | [experiment_2019_10_09_10_58_54_0001] epoch #65 | gradient computed
2019-10-09 10:59:40 | [experiment_2019_10_09_10_58_54_0001] epoch #65 | computing descent direction
2019-10-09 10:59:40 | [experiment_2019_10_09_10_58_54_0001] epoch #65 | descent direction computed
2019-10-09 10:59:40 | [experiment_2019_10_09_10_58_54_0001] epoch #65 | backtrack iters: 0
2019-10-09 10:59:40 | [experiment_2019_10_09_10_58_54_0001] epoch #65 | computing loss after
2019-10-09 10:59:40 | [experiment_2019_10_09_10_58_54_0001] epoch #65 | optimization finished
2019-10-09 10:59:40 | [experiment_2019_10_09_10_58_54_0001] epoch #65 | Computing KL after
2019-10-09 10:59:40 | [experiment_2019_10_09_10_58_54_0001] epoch #65 | Computing loss after
2019-10-09 10:59:40 | [experiment_2019_10_09_10_58_54_0001] epoch #65 | Fitting baseline...
2019-10-09 10:59:40 | [experiment_2019_10_09_10_58_54_0001] epoch #65 | Saving snapshot...
2019-10-09 10:59:40 | [experiment_2019_10_09_10_58_54_0001] epoch #65 | Saved
2019-10-09 10:59:40 | [experiment_2019_10_09_10_58_54_0001] epoch #65 | Time 41.86 s
2019-10-09 10:59:40 | [experiment_2019_10_09_10_58_54_0001] epoch #65 | EpochTime 0.65 s
---------------------------------------  ------------
AverageDiscountedReturn                   63.3968
AverageReturn                            100
Entropy                                    0.502427
EnvExecTime                                0.0546982
Extras/EpisodeRewardMean                 100
Iteration                                 65
LinearFeatureBaseline/ExplainedVariance    1
MaxReturn                                100
MinReturn                                100
NumTrajs                                  40
Perplexity                                 1.65273
PolicyExecTime                             0.389754
ProcessExecTime                            0.0193844
StdReturn                                  0
policy/Entropy                             0.528779
policy/KL                                  0.00823889
policy/KLBefore                            0
policy/LossAfter                          -0.00692186
policy/LossBefore                          1.0848e-08
policy/dLoss                               0.00692187
---------------------------------------  ------------
2019-10-09 10:59:40 | [experiment_2019_10_09_10_58_54_0001] epoch #66 | Obtaining samples...
2019-10-09 10:59:40 | [experiment_2019_10_09_10_58_54_0001] epoch #66 | Obtaining samples for iteration 66...
2019-10-09 10:59:41 | [experiment_2019_10_09_10_58_54_0001] epoch #66 | Logging diagnostics...
2019-10-09 10:59:41 | [experiment_2019_10_09_10_58_54_0001] epoch #66 | Optimizing policy...
2019-10-09 10:59:41 | [experiment_2019_10_09_10_58_54_0001] epoch #66 | Computing loss before
2019-10-09 10:59:41 | [experiment_2019_10_09_10_58_54_0001] epoch #66 | Computing KL before
2019-10-09 10:59:41 | [experiment_2019_10_09_10_58_54_0001] epoch #66 | Optimizing
2019-10-09 10:59:41 | [experiment_2019_10_09_10_58_54_0001] epoch #66 | Start CG optimization: #parameters: 1282, #inputs: 40, #subsample_inputs: 40
2019-10-09 10:59:41 | [experiment_2019_10_09_10_58_54_0001] epoch #66 | computing loss before
2019-10-09 10:59:41 | [experiment_2019_10_09_10_58_54_0001] epoch #66 | performing update
2019-10-09 10:59:41 | [experiment_2019_10_09_10_58_54_0001] epoch #66 | computing gradient
2019-10-09 10:59:41 | [experiment_2019_10_09_10_58_54_0001] epoch #66 | gradient computed
2019-10-09 10:59:41 | [experiment_2019_10_09_10_58_54_0001] epoch #66 | computing descent direction
2019-10-09 10:59:41 | [experiment_2019_10_09_10_58_54_0001] epoch #66 | descent direction computed
2019-10-09 10:59:41 | [experiment_2019_10_09_10_58_54_0001] epoch #66 | backtrack iters: 3
2019-10-09 10:59:41 | [experiment_2019_10_09_10_58_54_0001] epoch #66 | computing loss after
2019-10-09 10:59:41 | [experiment_2019_10_09_10_58_54_0001] epoch #66 | optimization finished
2019-10-09 10:59:41 | [experiment_2019_10_09_10_58_54_0001] epoch #66 | Computing KL after
2019-10-09 10:59:41 | [experiment_2019_10_09_10_58_54_0001] epoch #66 | Computing loss after
2019-10-09 10:59:41 | [experiment_2019_10_09_10_58_54_0001] epoch #66 | Fitting baseline...
2019-10-09 10:59:41 | [experiment_2019_10_09_10_58_54_0001] epoch #66 | Saving snapshot...
2019-10-09 10:59:41 | [experiment_2019_10_09_10_58_54_0001] epoch #66 | Saved
2019-10-09 10:59:41 | [experiment_2019_10_09_10_58_54_0001] epoch #66 | Time 42.48 s
2019-10-09 10:59:41 | [experiment_2019_10_09_10_58_54_0001] epoch #66 | EpochTime 0.61 s
---------------------------------------  -------------
AverageDiscountedReturn                   63.3968
AverageReturn                            100
Entropy                                    0.531161
EnvExecTime                                0.050065
Extras/EpisodeRewardMean                 100
Iteration                                 66
LinearFeatureBaseline/ExplainedVariance    1
MaxReturn                                100
MinReturn                                100
NumTrajs                                  40
Perplexity                                 1.70091
PolicyExecTime                             0.359923
ProcessExecTime                            0.0175138
StdReturn                                  0
policy/Entropy                             0.526269
policy/KL                                  0.00679457
policy/KLBefore                            0
policy/LossAfter                          -0.00505859
policy/LossBefore                          5.48363e-09
policy/dLoss                               0.0050586
---------------------------------------  -------------
2019-10-09 10:59:41 | [experiment_2019_10_09_10_58_54_0001] epoch #67 | Obtaining samples...
2019-10-09 10:59:41 | [experiment_2019_10_09_10_58_54_0001] epoch #67 | Obtaining samples for iteration 67...
2019-10-09 10:59:42 | [experiment_2019_10_09_10_58_54_0001] epoch #67 | Logging diagnostics...
2019-10-09 10:59:42 | [experiment_2019_10_09_10_58_54_0001] epoch #67 | Optimizing policy...
2019-10-09 10:59:42 | [experiment_2019_10_09_10_58_54_0001] epoch #67 | Computing loss before
2019-10-09 10:59:42 | [experiment_2019_10_09_10_58_54_0001] epoch #67 | Computing KL before
2019-10-09 10:59:42 | [experiment_2019_10_09_10_58_54_0001] epoch #67 | Optimizing
2019-10-09 10:59:42 | [experiment_2019_10_09_10_58_54_0001] epoch #67 | Start CG optimization: #parameters: 1282, #inputs: 41, #subsample_inputs: 41
2019-10-09 10:59:42 | [experiment_2019_10_09_10_58_54_0001] epoch #67 | computing loss before
2019-10-09 10:59:42 | [experiment_2019_10_09_10_58_54_0001] epoch #67 | performing update
2019-10-09 10:59:42 | [experiment_2019_10_09_10_58_54_0001] epoch #67 | computing gradient
2019-10-09 10:59:42 | [experiment_2019_10_09_10_58_54_0001] epoch #67 | gradient computed
2019-10-09 10:59:42 | [experiment_2019_10_09_10_58_54_0001] epoch #67 | computing descent direction
2019-10-09 10:59:42 | [experiment_2019_10_09_10_58_54_0001] epoch #67 | descent direction computed
2019-10-09 10:59:42 | [experiment_2019_10_09_10_58_54_0001] epoch #67 | backtrack iters: 2
2019-10-09 10:59:42 | [experiment_2019_10_09_10_58_54_0001] epoch #67 | computing loss after
2019-10-09 10:59:42 | [experiment_2019_10_09_10_58_54_0001] epoch #67 | optimization finished
2019-10-09 10:59:42 | [experiment_2019_10_09_10_58_54_0001] epoch #67 | Computing KL after
2019-10-09 10:59:42 | [experiment_2019_10_09_10_58_54_0001] epoch #67 | Computing loss after
2019-10-09 10:59:42 | [experiment_2019_10_09_10_58_54_0001] epoch #67 | Fitting baseline...
2019-10-09 10:59:42 | [experiment_2019_10_09_10_58_54_0001] epoch #67 | Saving snapshot...
2019-10-09 10:59:42 | [experiment_2019_10_09_10_58_54_0001] epoch #67 | Saved
2019-10-09 10:59:42 | [experiment_2019_10_09_10_58_54_0001] epoch #67 | Time 43.14 s
2019-10-09 10:59:42 | [experiment_2019_10_09_10_58_54_0001] epoch #67 | EpochTime 0.66 s
---------------------------------------  -------------
AverageDiscountedReturn                   63.1168
AverageReturn                             99.2927
Entropy                                    0.501695
EnvExecTime                                0.055804
Extras/EpisodeRewardMean                  99.71
Iteration                                 67
LinearFeatureBaseline/ExplainedVariance    0.989817
MaxReturn                                100
MinReturn                                 81
NumTrajs                                  41
Perplexity                                 1.65152
PolicyExecTime                             0.39042
ProcessExecTime                            0.0198793
StdReturn                                  3.09401
policy/Entropy                             0.48771
policy/KL                                  0.00588098
policy/KLBefore                           -2.51426e-10
policy/LossAfter                          -0.00696089
policy/LossBefore                         -6.73499e-09
policy/dLoss                               0.00696088
---------------------------------------  -------------
2019-10-09 10:59:42 | [experiment_2019_10_09_10_58_54_0001] epoch #68 | Obtaining samples...
2019-10-09 10:59:42 | [experiment_2019_10_09_10_58_54_0001] epoch #68 | Obtaining samples for iteration 68...
2019-10-09 10:59:42 | [experiment_2019_10_09_10_58_54_0001] epoch #68 | Logging diagnostics...
2019-10-09 10:59:42 | [experiment_2019_10_09_10_58_54_0001] epoch #68 | Optimizing policy...
2019-10-09 10:59:42 | [experiment_2019_10_09_10_58_54_0001] epoch #68 | Computing loss before
2019-10-09 10:59:42 | [experiment_2019_10_09_10_58_54_0001] epoch #68 | Computing KL before
2019-10-09 10:59:42 | [experiment_2019_10_09_10_58_54_0001] epoch #68 | Optimizing
2019-10-09 10:59:42 | [experiment_2019_10_09_10_58_54_0001] epoch #68 | Start CG optimization: #parameters: 1282, #inputs: 42, #subsample_inputs: 42
2019-10-09 10:59:42 | [experiment_2019_10_09_10_58_54_0001] epoch #68 | computing loss before
2019-10-09 10:59:42 | [experiment_2019_10_09_10_58_54_0001] epoch #68 | performing update
2019-10-09 10:59:42 | [experiment_2019_10_09_10_58_54_0001] epoch #68 | computing gradient
2019-10-09 10:59:42 | [experiment_2019_10_09_10_58_54_0001] epoch #68 | gradient computed
2019-10-09 10:59:42 | [experiment_2019_10_09_10_58_54_0001] epoch #68 | computing descent direction
2019-10-09 10:59:42 | [experiment_2019_10_09_10_58_54_0001] epoch #68 | descent direction computed
2019-10-09 10:59:42 | [experiment_2019_10_09_10_58_54_0001] epoch #68 | backtrack iters: 1
2019-10-09 10:59:42 | [experiment_2019_10_09_10_58_54_0001] epoch #68 | computing loss after
2019-10-09 10:59:42 | [experiment_2019_10_09_10_58_54_0001] epoch #68 | optimization finished
2019-10-09 10:59:42 | [experiment_2019_10_09_10_58_54_0001] epoch #68 | Computing KL after
2019-10-09 10:59:42 | [experiment_2019_10_09_10_58_54_0001] epoch #68 | Computing loss after
2019-10-09 10:59:42 | [experiment_2019_10_09_10_58_54_0001] epoch #68 | Fitting baseline...
2019-10-09 10:59:42 | [experiment_2019_10_09_10_58_54_0001] epoch #68 | Saving snapshot...
2019-10-09 10:59:42 | [experiment_2019_10_09_10_58_54_0001] epoch #68 | Saved
2019-10-09 10:59:42 | [experiment_2019_10_09_10_58_54_0001] epoch #68 | Time 43.83 s
2019-10-09 10:59:42 | [experiment_2019_10_09_10_58_54_0001] epoch #68 | EpochTime 0.69 s
---------------------------------------  -------------
AverageDiscountedReturn                   63.3253
AverageReturn                             99.8095
Entropy                                    0.51585
EnvExecTime                                0.062083
Extras/EpisodeRewardMean                  99.63
Iteration                                 68
LinearFeatureBaseline/ExplainedVariance    0.997789
MaxReturn                                100
MinReturn                                 96
NumTrajs                                  42
Perplexity                                 1.67506
PolicyExecTime                             0.416387
ProcessExecTime                            0.0220959
StdReturn                                  0.851835
policy/Entropy                             0.487553
policy/KL                                  0.00855009
policy/KLBefore                           -1.39566e-10
policy/LossAfter                          -0.0133129
policy/LossBefore                         -5.00497e-08
policy/dLoss                               0.0133129
---------------------------------------  -------------
2019-10-09 10:59:42 | [experiment_2019_10_09_10_58_54_0001] epoch #69 | Obtaining samples...
2019-10-09 10:59:42 | [experiment_2019_10_09_10_58_54_0001] epoch #69 | Obtaining samples for iteration 69...
2019-10-09 10:59:43 | [experiment_2019_10_09_10_58_54_0001] epoch #69 | Logging diagnostics...
2019-10-09 10:59:43 | [experiment_2019_10_09_10_58_54_0001] epoch #69 | Optimizing policy...
2019-10-09 10:59:43 | [experiment_2019_10_09_10_58_54_0001] epoch #69 | Computing loss before
2019-10-09 10:59:43 | [experiment_2019_10_09_10_58_54_0001] epoch #69 | Computing KL before
2019-10-09 10:59:43 | [experiment_2019_10_09_10_58_54_0001] epoch #69 | Optimizing
2019-10-09 10:59:43 | [experiment_2019_10_09_10_58_54_0001] epoch #69 | Start CG optimization: #parameters: 1282, #inputs: 40, #subsample_inputs: 40
2019-10-09 10:59:43 | [experiment_2019_10_09_10_58_54_0001] epoch #69 | computing loss before
2019-10-09 10:59:43 | [experiment_2019_10_09_10_58_54_0001] epoch #69 | performing update
2019-10-09 10:59:43 | [experiment_2019_10_09_10_58_54_0001] epoch #69 | computing gradient
2019-10-09 10:59:43 | [experiment_2019_10_09_10_58_54_0001] epoch #69 | gradient computed
2019-10-09 10:59:43 | [experiment_2019_10_09_10_58_54_0001] epoch #69 | computing descent direction
2019-10-09 10:59:43 | [experiment_2019_10_09_10_58_54_0001] epoch #69 | descent direction computed
2019-10-09 10:59:43 | [experiment_2019_10_09_10_58_54_0001] epoch #69 | backtrack iters: 0
2019-10-09 10:59:43 | [experiment_2019_10_09_10_58_54_0001] epoch #69 | computing loss after
2019-10-09 10:59:43 | [experiment_2019_10_09_10_58_54_0001] epoch #69 | optimization finished
2019-10-09 10:59:43 | [experiment_2019_10_09_10_58_54_0001] epoch #69 | Computing KL after
2019-10-09 10:59:43 | [experiment_2019_10_09_10_58_54_0001] epoch #69 | Computing loss after
2019-10-09 10:59:43 | [experiment_2019_10_09_10_58_54_0001] epoch #69 | Fitting baseline...
2019-10-09 10:59:43 | [experiment_2019_10_09_10_58_54_0001] epoch #69 | Saving snapshot...
2019-10-09 10:59:43 | [experiment_2019_10_09_10_58_54_0001] epoch #69 | Saved
2019-10-09 10:59:43 | [experiment_2019_10_09_10_58_54_0001] epoch #69 | Time 44.45 s
2019-10-09 10:59:43 | [experiment_2019_10_09_10_58_54_0001] epoch #69 | EpochTime 0.61 s
---------------------------------------  -------------
AverageDiscountedReturn                   63.3968
AverageReturn                            100
Entropy                                    0.489563
EnvExecTime                                0.0541112
Extras/EpisodeRewardMean                  99.82
Iteration                                 69
LinearFeatureBaseline/ExplainedVariance    0.999822
MaxReturn                                100
MinReturn                                100
NumTrajs                                  40
Perplexity                                 1.6316
PolicyExecTime                             0.353146
ProcessExecTime                            0.0198221
StdReturn                                  0
policy/Entropy                             0.451146
policy/KL                                  0.00896044
policy/KLBefore                            0
policy/LossAfter                          -0.0106737
policy/LossBefore                         -7.42674e-08
policy/dLoss                               0.0106736
---------------------------------------  -------------
2019-10-09 10:59:43 | [experiment_2019_10_09_10_58_54_0001] epoch #70 | Obtaining samples...
2019-10-09 10:59:43 | [experiment_2019_10_09_10_58_54_0001] epoch #70 | Obtaining samples for iteration 70...
2019-10-09 10:59:44 | [experiment_2019_10_09_10_58_54_0001] epoch #70 | Logging diagnostics...
2019-10-09 10:59:44 | [experiment_2019_10_09_10_58_54_0001] epoch #70 | Optimizing policy...
2019-10-09 10:59:44 | [experiment_2019_10_09_10_58_54_0001] epoch #70 | Computing loss before
2019-10-09 10:59:44 | [experiment_2019_10_09_10_58_54_0001] epoch #70 | Computing KL before
2019-10-09 10:59:44 | [experiment_2019_10_09_10_58_54_0001] epoch #70 | Optimizing
2019-10-09 10:59:44 | [experiment_2019_10_09_10_58_54_0001] epoch #70 | Start CG optimization: #parameters: 1282, #inputs: 40, #subsample_inputs: 40
2019-10-09 10:59:44 | [experiment_2019_10_09_10_58_54_0001] epoch #70 | computing loss before
2019-10-09 10:59:44 | [experiment_2019_10_09_10_58_54_0001] epoch #70 | performing update
2019-10-09 10:59:44 | [experiment_2019_10_09_10_58_54_0001] epoch #70 | computing gradient
2019-10-09 10:59:44 | [experiment_2019_10_09_10_58_54_0001] epoch #70 | gradient computed
2019-10-09 10:59:44 | [experiment_2019_10_09_10_58_54_0001] epoch #70 | computing descent direction
2019-10-09 10:59:44 | [experiment_2019_10_09_10_58_54_0001] epoch #70 | descent direction computed
2019-10-09 10:59:44 | [experiment_2019_10_09_10_58_54_0001] epoch #70 | backtrack iters: 4
2019-10-09 10:59:44 | [experiment_2019_10_09_10_58_54_0001] epoch #70 | computing loss after
2019-10-09 10:59:44 | [experiment_2019_10_09_10_58_54_0001] epoch #70 | optimization finished
2019-10-09 10:59:44 | [experiment_2019_10_09_10_58_54_0001] epoch #70 | Computing KL after
2019-10-09 10:59:44 | [experiment_2019_10_09_10_58_54_0001] epoch #70 | Computing loss after
2019-10-09 10:59:44 | [experiment_2019_10_09_10_58_54_0001] epoch #70 | Fitting baseline...
2019-10-09 10:59:44 | [experiment_2019_10_09_10_58_54_0001] epoch #70 | Saving snapshot...
2019-10-09 10:59:44 | [experiment_2019_10_09_10_58_54_0001] epoch #70 | Saved
2019-10-09 10:59:44 | [experiment_2019_10_09_10_58_54_0001] epoch #70 | Time 45.12 s
2019-10-09 10:59:44 | [experiment_2019_10_09_10_58_54_0001] epoch #70 | EpochTime 0.67 s
---------------------------------------  -------------
AverageDiscountedReturn                   63.3968
AverageReturn                            100
Entropy                                    0.470154
EnvExecTime                                0.0580511
Extras/EpisodeRewardMean                  99.92
Iteration                                 70
LinearFeatureBaseline/ExplainedVariance    1
MaxReturn                                100
MinReturn                                100
NumTrajs                                  40
Perplexity                                 1.60024
PolicyExecTime                             0.396359
ProcessExecTime                            0.0211916
StdReturn                                  0
policy/Entropy                             0.466539
policy/KL                                  0.00628904
policy/KLBefore                            0
policy/LossAfter                          -0.0047753
policy/LossBefore                         -1.74642e-08
policy/dLoss                               0.00477529
---------------------------------------  -------------
2019-10-09 10:59:44 | [experiment_2019_10_09_10_58_54_0001] epoch #71 | Obtaining samples...
2019-10-09 10:59:44 | [experiment_2019_10_09_10_58_54_0001] epoch #71 | Obtaining samples for iteration 71...
2019-10-09 10:59:44 | [experiment_2019_10_09_10_58_54_0001] epoch #71 | Logging diagnostics...
2019-10-09 10:59:44 | [experiment_2019_10_09_10_58_54_0001] epoch #71 | Optimizing policy...
2019-10-09 10:59:44 | [experiment_2019_10_09_10_58_54_0001] epoch #71 | Computing loss before
2019-10-09 10:59:44 | [experiment_2019_10_09_10_58_54_0001] epoch #71 | Computing KL before
2019-10-09 10:59:44 | [experiment_2019_10_09_10_58_54_0001] epoch #71 | Optimizing
2019-10-09 10:59:44 | [experiment_2019_10_09_10_58_54_0001] epoch #71 | Start CG optimization: #parameters: 1282, #inputs: 40, #subsample_inputs: 40
2019-10-09 10:59:44 | [experiment_2019_10_09_10_58_54_0001] epoch #71 | computing loss before
2019-10-09 10:59:44 | [experiment_2019_10_09_10_58_54_0001] epoch #71 | performing update
2019-10-09 10:59:44 | [experiment_2019_10_09_10_58_54_0001] epoch #71 | computing gradient
2019-10-09 10:59:44 | [experiment_2019_10_09_10_58_54_0001] epoch #71 | gradient computed
2019-10-09 10:59:44 | [experiment_2019_10_09_10_58_54_0001] epoch #71 | computing descent direction
2019-10-09 10:59:44 | [experiment_2019_10_09_10_58_54_0001] epoch #71 | descent direction computed
2019-10-09 10:59:44 | [experiment_2019_10_09_10_58_54_0001] epoch #71 | backtrack iters: 2
2019-10-09 10:59:44 | [experiment_2019_10_09_10_58_54_0001] epoch #71 | computing loss after
2019-10-09 10:59:44 | [experiment_2019_10_09_10_58_54_0001] epoch #71 | optimization finished
2019-10-09 10:59:44 | [experiment_2019_10_09_10_58_54_0001] epoch #71 | Computing KL after
2019-10-09 10:59:44 | [experiment_2019_10_09_10_58_54_0001] epoch #71 | Computing loss after
2019-10-09 10:59:44 | [experiment_2019_10_09_10_58_54_0001] epoch #71 | Fitting baseline...
2019-10-09 10:59:44 | [experiment_2019_10_09_10_58_54_0001] epoch #71 | Saving snapshot...
2019-10-09 10:59:44 | [experiment_2019_10_09_10_58_54_0001] epoch #71 | Saved
2019-10-09 10:59:44 | [experiment_2019_10_09_10_58_54_0001] epoch #71 | Time 45.78 s
2019-10-09 10:59:44 | [experiment_2019_10_09_10_58_54_0001] epoch #71 | EpochTime 0.66 s
---------------------------------------  -------------
AverageDiscountedReturn                   63.3968
AverageReturn                            100
Entropy                                    0.483144
EnvExecTime                                0.0568578
Extras/EpisodeRewardMean                 100
Iteration                                 71
LinearFeatureBaseline/ExplainedVariance    1
MaxReturn                                100
MinReturn                                100
NumTrajs                                  40
Perplexity                                 1.62116
PolicyExecTime                             0.386231
ProcessExecTime                            0.0205736
StdReturn                                  0
policy/Entropy                             0.444157
policy/KL                                  0.0099892
policy/KLBefore                            0
policy/LossAfter                          -0.00709828
policy/LossBefore                          8.58307e-09
policy/dLoss                               0.00709829
---------------------------------------  -------------
2019-10-09 10:59:44 | [experiment_2019_10_09_10_58_54_0001] epoch #72 | Obtaining samples...
2019-10-09 10:59:44 | [experiment_2019_10_09_10_58_54_0001] epoch #72 | Obtaining samples for iteration 72...
2019-10-09 10:59:45 | [experiment_2019_10_09_10_58_54_0001] epoch #72 | Logging diagnostics...
2019-10-09 10:59:45 | [experiment_2019_10_09_10_58_54_0001] epoch #72 | Optimizing policy...
2019-10-09 10:59:45 | [experiment_2019_10_09_10_58_54_0001] epoch #72 | Computing loss before
2019-10-09 10:59:45 | [experiment_2019_10_09_10_58_54_0001] epoch #72 | Computing KL before
2019-10-09 10:59:45 | [experiment_2019_10_09_10_58_54_0001] epoch #72 | Optimizing
2019-10-09 10:59:45 | [experiment_2019_10_09_10_58_54_0001] epoch #72 | Start CG optimization: #parameters: 1282, #inputs: 40, #subsample_inputs: 40
2019-10-09 10:59:45 | [experiment_2019_10_09_10_58_54_0001] epoch #72 | computing loss before
2019-10-09 10:59:45 | [experiment_2019_10_09_10_58_54_0001] epoch #72 | performing update
2019-10-09 10:59:45 | [experiment_2019_10_09_10_58_54_0001] epoch #72 | computing gradient
2019-10-09 10:59:45 | [experiment_2019_10_09_10_58_54_0001] epoch #72 | gradient computed
2019-10-09 10:59:45 | [experiment_2019_10_09_10_58_54_0001] epoch #72 | computing descent direction
2019-10-09 10:59:45 | [experiment_2019_10_09_10_58_54_0001] epoch #72 | descent direction computed
2019-10-09 10:59:45 | [experiment_2019_10_09_10_58_54_0001] epoch #72 | backtrack iters: 3
2019-10-09 10:59:45 | [experiment_2019_10_09_10_58_54_0001] epoch #72 | computing loss after
2019-10-09 10:59:45 | [experiment_2019_10_09_10_58_54_0001] epoch #72 | optimization finished
2019-10-09 10:59:45 | [experiment_2019_10_09_10_58_54_0001] epoch #72 | Computing KL after
2019-10-09 10:59:45 | [experiment_2019_10_09_10_58_54_0001] epoch #72 | Computing loss after
2019-10-09 10:59:45 | [experiment_2019_10_09_10_58_54_0001] epoch #72 | Fitting baseline...
2019-10-09 10:59:45 | [experiment_2019_10_09_10_58_54_0001] epoch #72 | Saving snapshot...
2019-10-09 10:59:45 | [experiment_2019_10_09_10_58_54_0001] epoch #72 | Saved
2019-10-09 10:59:45 | [experiment_2019_10_09_10_58_54_0001] epoch #72 | Time 46.43 s
2019-10-09 10:59:45 | [experiment_2019_10_09_10_58_54_0001] epoch #72 | EpochTime 0.64 s
---------------------------------------  -------------
AverageDiscountedReturn                   63.3968
AverageReturn                            100
Entropy                                    0.462444
EnvExecTime                                0.0567234
Extras/EpisodeRewardMean                 100
Iteration                                 72
LinearFeatureBaseline/ExplainedVariance    1
MaxReturn                                100
MinReturn                                100
NumTrajs                                  40
Perplexity                                 1.58795
PolicyExecTime                             0.37353
ProcessExecTime                            0.0205362
StdReturn                                  0
policy/Entropy                             0.480758
policy/KL                                  0.00893395
policy/KLBefore                            0
policy/LossAfter                          -0.00548268
policy/LossBefore                         -1.97887e-08
policy/dLoss                               0.00548266
---------------------------------------  -------------
2019-10-09 10:59:45 | [experiment_2019_10_09_10_58_54_0001] epoch #73 | Obtaining samples...
2019-10-09 10:59:45 | [experiment_2019_10_09_10_58_54_0001] epoch #73 | Obtaining samples for iteration 73...
2019-10-09 10:59:46 | [experiment_2019_10_09_10_58_54_0001] epoch #73 | Logging diagnostics...
2019-10-09 10:59:46 | [experiment_2019_10_09_10_58_54_0001] epoch #73 | Optimizing policy...
2019-10-09 10:59:46 | [experiment_2019_10_09_10_58_54_0001] epoch #73 | Computing loss before
2019-10-09 10:59:46 | [experiment_2019_10_09_10_58_54_0001] epoch #73 | Computing KL before
2019-10-09 10:59:46 | [experiment_2019_10_09_10_58_54_0001] epoch #73 | Optimizing
2019-10-09 10:59:46 | [experiment_2019_10_09_10_58_54_0001] epoch #73 | Start CG optimization: #parameters: 1282, #inputs: 40, #subsample_inputs: 40
2019-10-09 10:59:46 | [experiment_2019_10_09_10_58_54_0001] epoch #73 | computing loss before
2019-10-09 10:59:46 | [experiment_2019_10_09_10_58_54_0001] epoch #73 | performing update
2019-10-09 10:59:46 | [experiment_2019_10_09_10_58_54_0001] epoch #73 | computing gradient
2019-10-09 10:59:46 | [experiment_2019_10_09_10_58_54_0001] epoch #73 | gradient computed
2019-10-09 10:59:46 | [experiment_2019_10_09_10_58_54_0001] epoch #73 | computing descent direction
2019-10-09 10:59:46 | [experiment_2019_10_09_10_58_54_0001] epoch #73 | descent direction computed
2019-10-09 10:59:46 | [experiment_2019_10_09_10_58_54_0001] epoch #73 | backtrack iters: 3
2019-10-09 10:59:46 | [experiment_2019_10_09_10_58_54_0001] epoch #73 | computing loss after
2019-10-09 10:59:46 | [experiment_2019_10_09_10_58_54_0001] epoch #73 | optimization finished
2019-10-09 10:59:46 | [experiment_2019_10_09_10_58_54_0001] epoch #73 | Computing KL after
2019-10-09 10:59:46 | [experiment_2019_10_09_10_58_54_0001] epoch #73 | Computing loss after
2019-10-09 10:59:46 | [experiment_2019_10_09_10_58_54_0001] epoch #73 | Fitting baseline...
2019-10-09 10:59:46 | [experiment_2019_10_09_10_58_54_0001] epoch #73 | Saving snapshot...
2019-10-09 10:59:46 | [experiment_2019_10_09_10_58_54_0001] epoch #73 | Saved
2019-10-09 10:59:46 | [experiment_2019_10_09_10_58_54_0001] epoch #73 | Time 47.14 s
2019-10-09 10:59:46 | [experiment_2019_10_09_10_58_54_0001] epoch #73 | EpochTime 0.71 s
---------------------------------------  -------------
AverageDiscountedReturn                   63.3968
AverageReturn                            100
Entropy                                    0.509327
EnvExecTime                                0.0594454
Extras/EpisodeRewardMean                 100
Iteration                                 73
LinearFeatureBaseline/ExplainedVariance    1
MaxReturn                                100
MinReturn                                100
NumTrajs                                  40
Perplexity                                 1.66417
PolicyExecTime                             0.395181
ProcessExecTime                            0.0232606
StdReturn                                  0
policy/Entropy                             0.514813
policy/KL                                  0.00556899
policy/KLBefore                            0
policy/LossAfter                          -0.00670892
policy/LossBefore                          6.55651e-09
policy/dLoss                               0.00670893
---------------------------------------  -------------
2019-10-09 10:59:46 | [experiment_2019_10_09_10_58_54_0001] epoch #74 | Obtaining samples...
2019-10-09 10:59:46 | [experiment_2019_10_09_10_58_54_0001] epoch #74 | Obtaining samples for iteration 74...
2019-10-09 10:59:46 | [experiment_2019_10_09_10_58_54_0001] epoch #74 | Logging diagnostics...
2019-10-09 10:59:46 | [experiment_2019_10_09_10_58_54_0001] epoch #74 | Optimizing policy...
2019-10-09 10:59:46 | [experiment_2019_10_09_10_58_54_0001] epoch #74 | Computing loss before
2019-10-09 10:59:46 | [experiment_2019_10_09_10_58_54_0001] epoch #74 | Computing KL before
2019-10-09 10:59:46 | [experiment_2019_10_09_10_58_54_0001] epoch #74 | Optimizing
2019-10-09 10:59:46 | [experiment_2019_10_09_10_58_54_0001] epoch #74 | Start CG optimization: #parameters: 1282, #inputs: 40, #subsample_inputs: 40
2019-10-09 10:59:46 | [experiment_2019_10_09_10_58_54_0001] epoch #74 | computing loss before
2019-10-09 10:59:46 | [experiment_2019_10_09_10_58_54_0001] epoch #74 | performing update
2019-10-09 10:59:46 | [experiment_2019_10_09_10_58_54_0001] epoch #74 | computing gradient
2019-10-09 10:59:46 | [experiment_2019_10_09_10_58_54_0001] epoch #74 | gradient computed
2019-10-09 10:59:46 | [experiment_2019_10_09_10_58_54_0001] epoch #74 | computing descent direction
2019-10-09 10:59:46 | [experiment_2019_10_09_10_58_54_0001] epoch #74 | descent direction computed
2019-10-09 10:59:46 | [experiment_2019_10_09_10_58_54_0001] epoch #74 | backtrack iters: 2
2019-10-09 10:59:46 | [experiment_2019_10_09_10_58_54_0001] epoch #74 | computing loss after
2019-10-09 10:59:46 | [experiment_2019_10_09_10_58_54_0001] epoch #74 | optimization finished
2019-10-09 10:59:46 | [experiment_2019_10_09_10_58_54_0001] epoch #74 | Computing KL after
2019-10-09 10:59:46 | [experiment_2019_10_09_10_58_54_0001] epoch #74 | Computing loss after
2019-10-09 10:59:46 | [experiment_2019_10_09_10_58_54_0001] epoch #74 | Fitting baseline...
2019-10-09 10:59:46 | [experiment_2019_10_09_10_58_54_0001] epoch #74 | Saving snapshot...
2019-10-09 10:59:46 | [experiment_2019_10_09_10_58_54_0001] epoch #74 | Saved
2019-10-09 10:59:46 | [experiment_2019_10_09_10_58_54_0001] epoch #74 | Time 47.83 s
2019-10-09 10:59:46 | [experiment_2019_10_09_10_58_54_0001] epoch #74 | EpochTime 0.68 s
---------------------------------------  -------------
AverageDiscountedReturn                   63.3968
AverageReturn                            100
Entropy                                    0.509463
EnvExecTime                                0.0606878
Extras/EpisodeRewardMean                 100
Iteration                                 74
LinearFeatureBaseline/ExplainedVariance    1
MaxReturn                                100
MinReturn                                100
NumTrajs                                  40
Perplexity                                 1.6644
PolicyExecTime                             0.400229
ProcessExecTime                            0.0224831
StdReturn                                  0
policy/Entropy                             0.495292
policy/KL                                  0.00918399
policy/KLBefore                            0
policy/LossAfter                          -0.00558142
policy/LossBefore                          1.07288e-09
policy/dLoss                               0.00558142
---------------------------------------  -------------
2019-10-09 10:59:46 | [experiment_2019_10_09_10_58_54_0001] epoch #75 | Obtaining samples...
2019-10-09 10:59:46 | [experiment_2019_10_09_10_58_54_0001] epoch #75 | Obtaining samples for iteration 75...
2019-10-09 10:59:47 | [experiment_2019_10_09_10_58_54_0001] epoch #75 | Logging diagnostics...
2019-10-09 10:59:47 | [experiment_2019_10_09_10_58_54_0001] epoch #75 | Optimizing policy...
2019-10-09 10:59:47 | [experiment_2019_10_09_10_58_54_0001] epoch #75 | Computing loss before
2019-10-09 10:59:47 | [experiment_2019_10_09_10_58_54_0001] epoch #75 | Computing KL before
2019-10-09 10:59:47 | [experiment_2019_10_09_10_58_54_0001] epoch #75 | Optimizing
2019-10-09 10:59:47 | [experiment_2019_10_09_10_58_54_0001] epoch #75 | Start CG optimization: #parameters: 1282, #inputs: 40, #subsample_inputs: 40
2019-10-09 10:59:47 | [experiment_2019_10_09_10_58_54_0001] epoch #75 | computing loss before
2019-10-09 10:59:47 | [experiment_2019_10_09_10_58_54_0001] epoch #75 | performing update
2019-10-09 10:59:47 | [experiment_2019_10_09_10_58_54_0001] epoch #75 | computing gradient
2019-10-09 10:59:47 | [experiment_2019_10_09_10_58_54_0001] epoch #75 | gradient computed
2019-10-09 10:59:47 | [experiment_2019_10_09_10_58_54_0001] epoch #75 | computing descent direction
2019-10-09 10:59:47 | [experiment_2019_10_09_10_58_54_0001] epoch #75 | descent direction computed
2019-10-09 10:59:47 | [experiment_2019_10_09_10_58_54_0001] epoch #75 | backtrack iters: 4
2019-10-09 10:59:47 | [experiment_2019_10_09_10_58_54_0001] epoch #75 | computing loss after
2019-10-09 10:59:47 | [experiment_2019_10_09_10_58_54_0001] epoch #75 | optimization finished
2019-10-09 10:59:47 | [experiment_2019_10_09_10_58_54_0001] epoch #75 | Computing KL after
2019-10-09 10:59:47 | [experiment_2019_10_09_10_58_54_0001] epoch #75 | Computing loss after
2019-10-09 10:59:47 | [experiment_2019_10_09_10_58_54_0001] epoch #75 | Fitting baseline...
2019-10-09 10:59:47 | [experiment_2019_10_09_10_58_54_0001] epoch #75 | Saving snapshot...
2019-10-09 10:59:47 | [experiment_2019_10_09_10_58_54_0001] epoch #75 | Saved
2019-10-09 10:59:47 | [experiment_2019_10_09_10_58_54_0001] epoch #75 | Time 48.47 s
2019-10-09 10:59:47 | [experiment_2019_10_09_10_58_54_0001] epoch #75 | EpochTime 0.63 s
---------------------------------------  -------------
AverageDiscountedReturn                   63.3968
AverageReturn                            100
Entropy                                    0.502912
EnvExecTime                                0.0537002
Extras/EpisodeRewardMean                 100
Iteration                                 75
LinearFeatureBaseline/ExplainedVariance    1
MaxReturn                                100
MinReturn                                100
NumTrajs                                  40
Perplexity                                 1.65353
PolicyExecTime                             0.368267
ProcessExecTime                            0.0204327
StdReturn                                  0
policy/Entropy                             0.525771
policy/KL                                  0.00736049
policy/KLBefore                            0
policy/LossAfter                          -0.003213
policy/LossBefore                         -4.41074e-09
policy/dLoss                               0.00321299
---------------------------------------  -------------
2019-10-09 10:59:47 | [experiment_2019_10_09_10_58_54_0001] epoch #76 | Obtaining samples...
2019-10-09 10:59:47 | [experiment_2019_10_09_10_58_54_0001] epoch #76 | Obtaining samples for iteration 76...
2019-10-09 10:59:48 | [experiment_2019_10_09_10_58_54_0001] epoch #76 | Logging diagnostics...
2019-10-09 10:59:48 | [experiment_2019_10_09_10_58_54_0001] epoch #76 | Optimizing policy...
2019-10-09 10:59:48 | [experiment_2019_10_09_10_58_54_0001] epoch #76 | Computing loss before
2019-10-09 10:59:48 | [experiment_2019_10_09_10_58_54_0001] epoch #76 | Computing KL before
2019-10-09 10:59:48 | [experiment_2019_10_09_10_58_54_0001] epoch #76 | Optimizing
2019-10-09 10:59:48 | [experiment_2019_10_09_10_58_54_0001] epoch #76 | Start CG optimization: #parameters: 1282, #inputs: 41, #subsample_inputs: 41
2019-10-09 10:59:48 | [experiment_2019_10_09_10_58_54_0001] epoch #76 | computing loss before
2019-10-09 10:59:48 | [experiment_2019_10_09_10_58_54_0001] epoch #76 | performing update
2019-10-09 10:59:48 | [experiment_2019_10_09_10_58_54_0001] epoch #76 | computing gradient
2019-10-09 10:59:48 | [experiment_2019_10_09_10_58_54_0001] epoch #76 | gradient computed
2019-10-09 10:59:48 | [experiment_2019_10_09_10_58_54_0001] epoch #76 | computing descent direction
2019-10-09 10:59:48 | [experiment_2019_10_09_10_58_54_0001] epoch #76 | descent direction computed
2019-10-09 10:59:48 | [experiment_2019_10_09_10_58_54_0001] epoch #76 | backtrack iters: 3
2019-10-09 10:59:48 | [experiment_2019_10_09_10_58_54_0001] epoch #76 | computing loss after
2019-10-09 10:59:48 | [experiment_2019_10_09_10_58_54_0001] epoch #76 | optimization finished
2019-10-09 10:59:48 | [experiment_2019_10_09_10_58_54_0001] epoch #76 | Computing KL after
2019-10-09 10:59:48 | [experiment_2019_10_09_10_58_54_0001] epoch #76 | Computing loss after
2019-10-09 10:59:48 | [experiment_2019_10_09_10_58_54_0001] epoch #76 | Fitting baseline...
2019-10-09 10:59:48 | [experiment_2019_10_09_10_58_54_0001] epoch #76 | Saving snapshot...
2019-10-09 10:59:48 | [experiment_2019_10_09_10_58_54_0001] epoch #76 | Saved
2019-10-09 10:59:48 | [experiment_2019_10_09_10_58_54_0001] epoch #76 | Time 49.13 s
2019-10-09 10:59:48 | [experiment_2019_10_09_10_58_54_0001] epoch #76 | EpochTime 0.66 s
---------------------------------------  -------------
AverageDiscountedReturn                   62.6338
AverageReturn                             98.1707
Entropy                                    0.539699
EnvExecTime                                0.0560102
Extras/EpisodeRewardMean                  99.25
Iteration                                 76
LinearFeatureBaseline/ExplainedVariance    0.962567
MaxReturn                                100
MinReturn                                 65
NumTrajs                                  41
Perplexity                                 1.71549
PolicyExecTime                             0.382136
ProcessExecTime                            0.0202293
StdReturn                                  6.38177
policy/Entropy                             0.522193
policy/KL                                  0.0063174
policy/KLBefore                           -2.06883e-10
policy/LossAfter                          -0.0106239
policy/LossBefore                         -7.79229e-08
policy/dLoss                               0.0106238
---------------------------------------  -------------
2019-10-09 10:59:48 | [experiment_2019_10_09_10_58_54_0001] epoch #77 | Obtaining samples...
2019-10-09 10:59:48 | [experiment_2019_10_09_10_58_54_0001] epoch #77 | Obtaining samples for iteration 77...
2019-10-09 10:59:48 | [experiment_2019_10_09_10_58_54_0001] epoch #77 | Logging diagnostics...
2019-10-09 10:59:48 | [experiment_2019_10_09_10_58_54_0001] epoch #77 | Optimizing policy...
2019-10-09 10:59:48 | [experiment_2019_10_09_10_58_54_0001] epoch #77 | Computing loss before
2019-10-09 10:59:48 | [experiment_2019_10_09_10_58_54_0001] epoch #77 | Computing KL before
2019-10-09 10:59:48 | [experiment_2019_10_09_10_58_54_0001] epoch #77 | Optimizing
2019-10-09 10:59:48 | [experiment_2019_10_09_10_58_54_0001] epoch #77 | Start CG optimization: #parameters: 1282, #inputs: 41, #subsample_inputs: 41
2019-10-09 10:59:48 | [experiment_2019_10_09_10_58_54_0001] epoch #77 | computing loss before
2019-10-09 10:59:48 | [experiment_2019_10_09_10_58_54_0001] epoch #77 | performing update
2019-10-09 10:59:48 | [experiment_2019_10_09_10_58_54_0001] epoch #77 | computing gradient
2019-10-09 10:59:48 | [experiment_2019_10_09_10_58_54_0001] epoch #77 | gradient computed
2019-10-09 10:59:48 | [experiment_2019_10_09_10_58_54_0001] epoch #77 | computing descent direction
2019-10-09 10:59:48 | [experiment_2019_10_09_10_58_54_0001] epoch #77 | descent direction computed
2019-10-09 10:59:48 | [experiment_2019_10_09_10_58_54_0001] epoch #77 | backtrack iters: 2
2019-10-09 10:59:48 | [experiment_2019_10_09_10_58_54_0001] epoch #77 | computing loss after
2019-10-09 10:59:48 | [experiment_2019_10_09_10_58_54_0001] epoch #77 | optimization finished
2019-10-09 10:59:48 | [experiment_2019_10_09_10_58_54_0001] epoch #77 | Computing KL after
2019-10-09 10:59:48 | [experiment_2019_10_09_10_58_54_0001] epoch #77 | Computing loss after
2019-10-09 10:59:48 | [experiment_2019_10_09_10_58_54_0001] epoch #77 | Fitting baseline...
2019-10-09 10:59:48 | [experiment_2019_10_09_10_58_54_0001] epoch #77 | Saving snapshot...
2019-10-09 10:59:48 | [experiment_2019_10_09_10_58_54_0001] epoch #77 | Saved
2019-10-09 10:59:48 | [experiment_2019_10_09_10_58_54_0001] epoch #77 | Time 49.77 s
2019-10-09 10:59:48 | [experiment_2019_10_09_10_58_54_0001] epoch #77 | EpochTime 0.64 s
---------------------------------------  -------------
AverageDiscountedReturn                   62.9591
AverageReturn                             98.9024
Entropy                                    0.522496
EnvExecTime                                0.0545392
Extras/EpisodeRewardMean                  98.8
Iteration                                 77
LinearFeatureBaseline/ExplainedVariance    0.98716
MaxReturn                                100
MinReturn                                 80
NumTrajs                                  41
Perplexity                                 1.68623
PolicyExecTime                             0.374294
ProcessExecTime                            0.019557
StdReturn                                  4.01099
policy/Entropy                             0.507411
policy/KL                                  0.00673806
policy/KLBefore                            1.65408e-10
policy/LossAfter                          -0.0115712
policy/LossBefore                          1.64629e-09
policy/dLoss                               0.0115712
---------------------------------------  -------------
2019-10-09 10:59:48 | [experiment_2019_10_09_10_58_54_0001] epoch #78 | Obtaining samples...
2019-10-09 10:59:48 | [experiment_2019_10_09_10_58_54_0001] epoch #78 | Obtaining samples for iteration 78...
2019-10-09 10:59:49 | [experiment_2019_10_09_10_58_54_0001] epoch #78 | Logging diagnostics...
2019-10-09 10:59:49 | [experiment_2019_10_09_10_58_54_0001] epoch #78 | Optimizing policy...
2019-10-09 10:59:49 | [experiment_2019_10_09_10_58_54_0001] epoch #78 | Computing loss before
2019-10-09 10:59:49 | [experiment_2019_10_09_10_58_54_0001] epoch #78 | Computing KL before
2019-10-09 10:59:49 | [experiment_2019_10_09_10_58_54_0001] epoch #78 | Optimizing
2019-10-09 10:59:49 | [experiment_2019_10_09_10_58_54_0001] epoch #78 | Start CG optimization: #parameters: 1282, #inputs: 41, #subsample_inputs: 41
2019-10-09 10:59:49 | [experiment_2019_10_09_10_58_54_0001] epoch #78 | computing loss before
2019-10-09 10:59:49 | [experiment_2019_10_09_10_58_54_0001] epoch #78 | performing update
2019-10-09 10:59:49 | [experiment_2019_10_09_10_58_54_0001] epoch #78 | computing gradient
2019-10-09 10:59:49 | [experiment_2019_10_09_10_58_54_0001] epoch #78 | gradient computed
2019-10-09 10:59:49 | [experiment_2019_10_09_10_58_54_0001] epoch #78 | computing descent direction
2019-10-09 10:59:49 | [experiment_2019_10_09_10_58_54_0001] epoch #78 | descent direction computed
2019-10-09 10:59:49 | [experiment_2019_10_09_10_58_54_0001] epoch #78 | backtrack iters: 4
2019-10-09 10:59:49 | [experiment_2019_10_09_10_58_54_0001] epoch #78 | computing loss after
2019-10-09 10:59:49 | [experiment_2019_10_09_10_58_54_0001] epoch #78 | optimization finished
2019-10-09 10:59:49 | [experiment_2019_10_09_10_58_54_0001] epoch #78 | Computing KL after
2019-10-09 10:59:49 | [experiment_2019_10_09_10_58_54_0001] epoch #78 | Computing loss after
2019-10-09 10:59:49 | [experiment_2019_10_09_10_58_54_0001] epoch #78 | Fitting baseline...
2019-10-09 10:59:49 | [experiment_2019_10_09_10_58_54_0001] epoch #78 | Saving snapshot...
2019-10-09 10:59:49 | [experiment_2019_10_09_10_58_54_0001] epoch #78 | Saved
2019-10-09 10:59:49 | [experiment_2019_10_09_10_58_54_0001] epoch #78 | Time 50.40 s
2019-10-09 10:59:49 | [experiment_2019_10_09_10_58_54_0001] epoch #78 | EpochTime 0.62 s
---------------------------------------  -------------
AverageDiscountedReturn                   62.5263
AverageReturn                             98.0732
Entropy                                    0.514914
EnvExecTime                                0.0526035
Extras/EpisodeRewardMean                  98.41
Iteration                                 78
LinearFeatureBaseline/ExplainedVariance    0.941202
MaxReturn                                100
MinReturn                                 59
NumTrajs                                  41
Perplexity                                 1.6735
PolicyExecTime                             0.345697
ProcessExecTime                            0.0192525
StdReturn                                  8.51509
policy/Entropy                             0.495995
policy/KL                                  0.00513961
policy/KLBefore                           -6.84693e-11
policy/LossAfter                          -0.0129438
policy/LossBefore                         -1.61871e-08
policy/dLoss                               0.0129438
---------------------------------------  -------------
2019-10-09 10:59:49 | [experiment_2019_10_09_10_58_54_0001] epoch #79 | Obtaining samples...
2019-10-09 10:59:49 | [experiment_2019_10_09_10_58_54_0001] epoch #79 | Obtaining samples for iteration 79...
2019-10-09 10:59:49 | [experiment_2019_10_09_10_58_54_0001] epoch #79 | Logging diagnostics...
2019-10-09 10:59:49 | [experiment_2019_10_09_10_58_54_0001] epoch #79 | Optimizing policy...
2019-10-09 10:59:49 | [experiment_2019_10_09_10_58_54_0001] epoch #79 | Computing loss before
2019-10-09 10:59:50 | [experiment_2019_10_09_10_58_54_0001] epoch #79 | Computing KL before
2019-10-09 10:59:50 | [experiment_2019_10_09_10_58_54_0001] epoch #79 | Optimizing
2019-10-09 10:59:50 | [experiment_2019_10_09_10_58_54_0001] epoch #79 | Start CG optimization: #parameters: 1282, #inputs: 40, #subsample_inputs: 40
2019-10-09 10:59:50 | [experiment_2019_10_09_10_58_54_0001] epoch #79 | computing loss before
2019-10-09 10:59:50 | [experiment_2019_10_09_10_58_54_0001] epoch #79 | performing update
2019-10-09 10:59:50 | [experiment_2019_10_09_10_58_54_0001] epoch #79 | computing gradient
2019-10-09 10:59:50 | [experiment_2019_10_09_10_58_54_0001] epoch #79 | gradient computed
2019-10-09 10:59:50 | [experiment_2019_10_09_10_58_54_0001] epoch #79 | computing descent direction
2019-10-09 10:59:50 | [experiment_2019_10_09_10_58_54_0001] epoch #79 | descent direction computed
2019-10-09 10:59:50 | [experiment_2019_10_09_10_58_54_0001] epoch #79 | backtrack iters: 1
2019-10-09 10:59:50 | [experiment_2019_10_09_10_58_54_0001] epoch #79 | computing loss after
2019-10-09 10:59:50 | [experiment_2019_10_09_10_58_54_0001] epoch #79 | optimization finished
2019-10-09 10:59:50 | [experiment_2019_10_09_10_58_54_0001] epoch #79 | Computing KL after
2019-10-09 10:59:50 | [experiment_2019_10_09_10_58_54_0001] epoch #79 | Computing loss after
2019-10-09 10:59:50 | [experiment_2019_10_09_10_58_54_0001] epoch #79 | Fitting baseline...
2019-10-09 10:59:50 | [experiment_2019_10_09_10_58_54_0001] epoch #79 | Saving snapshot...
2019-10-09 10:59:50 | [experiment_2019_10_09_10_58_54_0001] epoch #79 | Saved
2019-10-09 10:59:50 | [experiment_2019_10_09_10_58_54_0001] epoch #79 | Time 51.02 s
2019-10-09 10:59:50 | [experiment_2019_10_09_10_58_54_0001] epoch #79 | EpochTime 0.62 s
---------------------------------------  -------------
AverageDiscountedReturn                   63.3968
AverageReturn                            100
Entropy                                    0.506646
EnvExecTime                                0.0540402
Extras/EpisodeRewardMean                  99.21
Iteration                                 79
LinearFeatureBaseline/ExplainedVariance    0.997464
MaxReturn                                100
MinReturn                                100
NumTrajs                                  40
Perplexity                                 1.65971
PolicyExecTime                             0.358468
ProcessExecTime                            0.0195925
StdReturn                                  0
policy/Entropy                             0.50645
policy/KL                                  0.00704285
policy/KLBefore                            0
policy/LossAfter                          -0.00729892
policy/LossBefore                          2.70605e-08
policy/dLoss                               0.00729894
---------------------------------------  -------------
2019-10-09 10:59:50 | [experiment_2019_10_09_10_58_54_0001] epoch #80 | Obtaining samples...
2019-10-09 10:59:50 | [experiment_2019_10_09_10_58_54_0001] epoch #80 | Obtaining samples for iteration 80...
2019-10-09 10:59:50 | [experiment_2019_10_09_10_58_54_0001] epoch #80 | Logging diagnostics...
2019-10-09 10:59:50 | [experiment_2019_10_09_10_58_54_0001] epoch #80 | Optimizing policy...
2019-10-09 10:59:50 | [experiment_2019_10_09_10_58_54_0001] epoch #80 | Computing loss before
2019-10-09 10:59:50 | [experiment_2019_10_09_10_58_54_0001] epoch #80 | Computing KL before
2019-10-09 10:59:50 | [experiment_2019_10_09_10_58_54_0001] epoch #80 | Optimizing
2019-10-09 10:59:50 | [experiment_2019_10_09_10_58_54_0001] epoch #80 | Start CG optimization: #parameters: 1282, #inputs: 40, #subsample_inputs: 40
2019-10-09 10:59:50 | [experiment_2019_10_09_10_58_54_0001] epoch #80 | computing loss before
2019-10-09 10:59:50 | [experiment_2019_10_09_10_58_54_0001] epoch #80 | performing update
2019-10-09 10:59:50 | [experiment_2019_10_09_10_58_54_0001] epoch #80 | computing gradient
2019-10-09 10:59:50 | [experiment_2019_10_09_10_58_54_0001] epoch #80 | gradient computed
2019-10-09 10:59:50 | [experiment_2019_10_09_10_58_54_0001] epoch #80 | computing descent direction
2019-10-09 10:59:50 | [experiment_2019_10_09_10_58_54_0001] epoch #80 | descent direction computed
2019-10-09 10:59:50 | [experiment_2019_10_09_10_58_54_0001] epoch #80 | backtrack iters: 0
2019-10-09 10:59:50 | [experiment_2019_10_09_10_58_54_0001] epoch #80 | computing loss after
2019-10-09 10:59:50 | [experiment_2019_10_09_10_58_54_0001] epoch #80 | optimization finished
2019-10-09 10:59:50 | [experiment_2019_10_09_10_58_54_0001] epoch #80 | Computing KL after
2019-10-09 10:59:50 | [experiment_2019_10_09_10_58_54_0001] epoch #80 | Computing loss after
2019-10-09 10:59:50 | [experiment_2019_10_09_10_58_54_0001] epoch #80 | Fitting baseline...
2019-10-09 10:59:50 | [experiment_2019_10_09_10_58_54_0001] epoch #80 | Saving snapshot...
2019-10-09 10:59:50 | [experiment_2019_10_09_10_58_54_0001] epoch #80 | Saved
2019-10-09 10:59:50 | [experiment_2019_10_09_10_58_54_0001] epoch #80 | Time 51.64 s
2019-10-09 10:59:50 | [experiment_2019_10_09_10_58_54_0001] epoch #80 | EpochTime 0.61 s
---------------------------------------  -------------
AverageDiscountedReturn                   63.3968
AverageReturn                            100
Entropy                                    0.507022
EnvExecTime                                0.0517106
Extras/EpisodeRewardMean                 100
Iteration                                 80
LinearFeatureBaseline/ExplainedVariance    1
MaxReturn                                100
MinReturn                                100
NumTrajs                                  40
Perplexity                                 1.66034
PolicyExecTime                             0.352344
ProcessExecTime                            0.0184596
StdReturn                                  0
policy/Entropy                             0.517888
policy/KL                                  0.00785461
policy/KLBefore                            0
policy/LossAfter                          -0.00638857
policy/LossBefore                         -6.31809e-09
policy/dLoss                               0.00638857
---------------------------------------  -------------
2019-10-09 10:59:50 | [experiment_2019_10_09_10_58_54_0001] epoch #81 | Obtaining samples...
2019-10-09 10:59:50 | [experiment_2019_10_09_10_58_54_0001] epoch #81 | Obtaining samples for iteration 81...
2019-10-09 10:59:51 | [experiment_2019_10_09_10_58_54_0001] epoch #81 | Logging diagnostics...
2019-10-09 10:59:51 | [experiment_2019_10_09_10_58_54_0001] epoch #81 | Optimizing policy...
2019-10-09 10:59:51 | [experiment_2019_10_09_10_58_54_0001] epoch #81 | Computing loss before
2019-10-09 10:59:51 | [experiment_2019_10_09_10_58_54_0001] epoch #81 | Computing KL before
2019-10-09 10:59:51 | [experiment_2019_10_09_10_58_54_0001] epoch #81 | Optimizing
2019-10-09 10:59:51 | [experiment_2019_10_09_10_58_54_0001] epoch #81 | Start CG optimization: #parameters: 1282, #inputs: 41, #subsample_inputs: 41
2019-10-09 10:59:51 | [experiment_2019_10_09_10_58_54_0001] epoch #81 | computing loss before
2019-10-09 10:59:51 | [experiment_2019_10_09_10_58_54_0001] epoch #81 | performing update
2019-10-09 10:59:51 | [experiment_2019_10_09_10_58_54_0001] epoch #81 | computing gradient
2019-10-09 10:59:51 | [experiment_2019_10_09_10_58_54_0001] epoch #81 | gradient computed
2019-10-09 10:59:51 | [experiment_2019_10_09_10_58_54_0001] epoch #81 | computing descent direction
2019-10-09 10:59:51 | [experiment_2019_10_09_10_58_54_0001] epoch #81 | descent direction computed
2019-10-09 10:59:51 | [experiment_2019_10_09_10_58_54_0001] epoch #81 | backtrack iters: 1
2019-10-09 10:59:51 | [experiment_2019_10_09_10_58_54_0001] epoch #81 | computing loss after
2019-10-09 10:59:51 | [experiment_2019_10_09_10_58_54_0001] epoch #81 | optimization finished
2019-10-09 10:59:51 | [experiment_2019_10_09_10_58_54_0001] epoch #81 | Computing KL after
2019-10-09 10:59:51 | [experiment_2019_10_09_10_58_54_0001] epoch #81 | Computing loss after
2019-10-09 10:59:51 | [experiment_2019_10_09_10_58_54_0001] epoch #81 | Fitting baseline...
2019-10-09 10:59:51 | [experiment_2019_10_09_10_58_54_0001] epoch #81 | Saving snapshot...
2019-10-09 10:59:51 | [experiment_2019_10_09_10_58_54_0001] epoch #81 | Saved
2019-10-09 10:59:51 | [experiment_2019_10_09_10_58_54_0001] epoch #81 | Time 52.34 s
2019-10-09 10:59:51 | [experiment_2019_10_09_10_58_54_0001] epoch #81 | EpochTime 0.70 s
---------------------------------------  -------------
AverageDiscountedReturn                   63.3122
AverageReturn                             99.7805
Entropy                                    0.513983
EnvExecTime                                0.0619922
Extras/EpisodeRewardMean                  99.91
Iteration                                 81
LinearFeatureBaseline/ExplainedVariance    0.997729
MaxReturn                                100
MinReturn                                 91
NumTrajs                                  41
Perplexity                                 1.67194
PolicyExecTime                             0.416554
ProcessExecTime                            0.0220566
StdReturn                                  1.38832
policy/Entropy                             0.512834
policy/KL                                  0.00677099
policy/KLBefore                           -2.68613e-10
policy/LossAfter                          -0.00346821
policy/LossBefore                         -4.62989e-08
policy/dLoss                               0.00346816
---------------------------------------  -------------
2019-10-09 10:59:51 | [experiment_2019_10_09_10_58_54_0001] epoch #82 | Obtaining samples...
2019-10-09 10:59:51 | [experiment_2019_10_09_10_58_54_0001] epoch #82 | Obtaining samples for iteration 82...
2019-10-09 10:59:51 | [experiment_2019_10_09_10_58_54_0001] epoch #82 | Logging diagnostics...
2019-10-09 10:59:51 | [experiment_2019_10_09_10_58_54_0001] epoch #82 | Optimizing policy...
2019-10-09 10:59:51 | [experiment_2019_10_09_10_58_54_0001] epoch #82 | Computing loss before
2019-10-09 10:59:52 | [experiment_2019_10_09_10_58_54_0001] epoch #82 | Computing KL before
2019-10-09 10:59:52 | [experiment_2019_10_09_10_58_54_0001] epoch #82 | Optimizing
2019-10-09 10:59:52 | [experiment_2019_10_09_10_58_54_0001] epoch #82 | Start CG optimization: #parameters: 1282, #inputs: 40, #subsample_inputs: 40
2019-10-09 10:59:52 | [experiment_2019_10_09_10_58_54_0001] epoch #82 | computing loss before
2019-10-09 10:59:52 | [experiment_2019_10_09_10_58_54_0001] epoch #82 | performing update
2019-10-09 10:59:52 | [experiment_2019_10_09_10_58_54_0001] epoch #82 | computing gradient
2019-10-09 10:59:52 | [experiment_2019_10_09_10_58_54_0001] epoch #82 | gradient computed
2019-10-09 10:59:52 | [experiment_2019_10_09_10_58_54_0001] epoch #82 | computing descent direction
2019-10-09 10:59:52 | [experiment_2019_10_09_10_58_54_0001] epoch #82 | descent direction computed
2019-10-09 10:59:52 | [experiment_2019_10_09_10_58_54_0001] epoch #82 | backtrack iters: 1
2019-10-09 10:59:52 | [experiment_2019_10_09_10_58_54_0001] epoch #82 | computing loss after
2019-10-09 10:59:52 | [experiment_2019_10_09_10_58_54_0001] epoch #82 | optimization finished
2019-10-09 10:59:52 | [experiment_2019_10_09_10_58_54_0001] epoch #82 | Computing KL after
2019-10-09 10:59:52 | [experiment_2019_10_09_10_58_54_0001] epoch #82 | Computing loss after
2019-10-09 10:59:52 | [experiment_2019_10_09_10_58_54_0001] epoch #82 | Fitting baseline...
2019-10-09 10:59:52 | [experiment_2019_10_09_10_58_54_0001] epoch #82 | Saving snapshot...
2019-10-09 10:59:52 | [experiment_2019_10_09_10_58_54_0001] epoch #82 | Saved
2019-10-09 10:59:52 | [experiment_2019_10_09_10_58_54_0001] epoch #82 | Time 53.03 s
2019-10-09 10:59:52 | [experiment_2019_10_09_10_58_54_0001] epoch #82 | EpochTime 0.68 s
---------------------------------------  -------------
AverageDiscountedReturn                   63.3968
AverageReturn                            100
Entropy                                    0.520753
EnvExecTime                                0.0590568
Extras/EpisodeRewardMean                  99.91
Iteration                                 82
LinearFeatureBaseline/ExplainedVariance    0.999832
MaxReturn                                100
MinReturn                                100
NumTrajs                                  40
Perplexity                                 1.68329
PolicyExecTime                             0.400932
ProcessExecTime                            0.0214505
StdReturn                                  0
policy/Entropy                             0.501323
policy/KL                                  0.0077485
policy/KLBefore                            0
policy/LossAfter                          -0.00569208
policy/LossBefore                          1.04904e-08
policy/dLoss                               0.00569209
---------------------------------------  -------------
2019-10-09 10:59:52 | [experiment_2019_10_09_10_58_54_0001] epoch #83 | Obtaining samples...
2019-10-09 10:59:52 | [experiment_2019_10_09_10_58_54_0001] epoch #83 | Obtaining samples for iteration 83...
2019-10-09 10:59:52 | [experiment_2019_10_09_10_58_54_0001] epoch #83 | Logging diagnostics...
2019-10-09 10:59:52 | [experiment_2019_10_09_10_58_54_0001] epoch #83 | Optimizing policy...
2019-10-09 10:59:52 | [experiment_2019_10_09_10_58_54_0001] epoch #83 | Computing loss before
2019-10-09 10:59:52 | [experiment_2019_10_09_10_58_54_0001] epoch #83 | Computing KL before
2019-10-09 10:59:52 | [experiment_2019_10_09_10_58_54_0001] epoch #83 | Optimizing
2019-10-09 10:59:52 | [experiment_2019_10_09_10_58_54_0001] epoch #83 | Start CG optimization: #parameters: 1282, #inputs: 40, #subsample_inputs: 40
2019-10-09 10:59:52 | [experiment_2019_10_09_10_58_54_0001] epoch #83 | computing loss before
2019-10-09 10:59:52 | [experiment_2019_10_09_10_58_54_0001] epoch #83 | performing update
2019-10-09 10:59:52 | [experiment_2019_10_09_10_58_54_0001] epoch #83 | computing gradient
2019-10-09 10:59:52 | [experiment_2019_10_09_10_58_54_0001] epoch #83 | gradient computed
2019-10-09 10:59:52 | [experiment_2019_10_09_10_58_54_0001] epoch #83 | computing descent direction
2019-10-09 10:59:52 | [experiment_2019_10_09_10_58_54_0001] epoch #83 | descent direction computed
2019-10-09 10:59:52 | [experiment_2019_10_09_10_58_54_0001] epoch #83 | backtrack iters: 3
2019-10-09 10:59:52 | [experiment_2019_10_09_10_58_54_0001] epoch #83 | computing loss after
2019-10-09 10:59:52 | [experiment_2019_10_09_10_58_54_0001] epoch #83 | optimization finished
2019-10-09 10:59:52 | [experiment_2019_10_09_10_58_54_0001] epoch #83 | Computing KL after
2019-10-09 10:59:52 | [experiment_2019_10_09_10_58_54_0001] epoch #83 | Computing loss after
2019-10-09 10:59:52 | [experiment_2019_10_09_10_58_54_0001] epoch #83 | Fitting baseline...
2019-10-09 10:59:52 | [experiment_2019_10_09_10_58_54_0001] epoch #83 | Saving snapshot...
2019-10-09 10:59:52 | [experiment_2019_10_09_10_58_54_0001] epoch #83 | Saved
2019-10-09 10:59:52 | [experiment_2019_10_09_10_58_54_0001] epoch #83 | Time 53.72 s
2019-10-09 10:59:52 | [experiment_2019_10_09_10_58_54_0001] epoch #83 | EpochTime 0.69 s
---------------------------------------  -------------
AverageDiscountedReturn                   63.3968
AverageReturn                            100
Entropy                                    0.514434
EnvExecTime                                0.0597401
Extras/EpisodeRewardMean                 100
Iteration                                 83
LinearFeatureBaseline/ExplainedVariance    1
MaxReturn                                100
MinReturn                                100
NumTrajs                                  40
Perplexity                                 1.67269
PolicyExecTime                             0.405517
ProcessExecTime                            0.0217376
StdReturn                                  0
policy/Entropy                             0.520549
policy/KL                                  0.00435916
policy/KLBefore                            0
policy/LossAfter                          -0.00159505
policy/LossBefore                         -5.84126e-09
policy/dLoss                               0.00159504
---------------------------------------  -------------
2019-10-09 10:59:52 | [experiment_2019_10_09_10_58_54_0001] epoch #84 | Obtaining samples...
2019-10-09 10:59:52 | [experiment_2019_10_09_10_58_54_0001] epoch #84 | Obtaining samples for iteration 84...
2019-10-09 10:59:53 | [experiment_2019_10_09_10_58_54_0001] epoch #84 | Logging diagnostics...
2019-10-09 10:59:53 | [experiment_2019_10_09_10_58_54_0001] epoch #84 | Optimizing policy...
2019-10-09 10:59:53 | [experiment_2019_10_09_10_58_54_0001] epoch #84 | Computing loss before
2019-10-09 10:59:53 | [experiment_2019_10_09_10_58_54_0001] epoch #84 | Computing KL before
2019-10-09 10:59:53 | [experiment_2019_10_09_10_58_54_0001] epoch #84 | Optimizing
2019-10-09 10:59:53 | [experiment_2019_10_09_10_58_54_0001] epoch #84 | Start CG optimization: #parameters: 1282, #inputs: 41, #subsample_inputs: 41
2019-10-09 10:59:53 | [experiment_2019_10_09_10_58_54_0001] epoch #84 | computing loss before
2019-10-09 10:59:53 | [experiment_2019_10_09_10_58_54_0001] epoch #84 | performing update
2019-10-09 10:59:53 | [experiment_2019_10_09_10_58_54_0001] epoch #84 | computing gradient
2019-10-09 10:59:53 | [experiment_2019_10_09_10_58_54_0001] epoch #84 | gradient computed
2019-10-09 10:59:53 | [experiment_2019_10_09_10_58_54_0001] epoch #84 | computing descent direction
2019-10-09 10:59:53 | [experiment_2019_10_09_10_58_54_0001] epoch #84 | descent direction computed
2019-10-09 10:59:53 | [experiment_2019_10_09_10_58_54_0001] epoch #84 | backtrack iters: 1
2019-10-09 10:59:53 | [experiment_2019_10_09_10_58_54_0001] epoch #84 | computing loss after
2019-10-09 10:59:53 | [experiment_2019_10_09_10_58_54_0001] epoch #84 | optimization finished
2019-10-09 10:59:53 | [experiment_2019_10_09_10_58_54_0001] epoch #84 | Computing KL after
2019-10-09 10:59:53 | [experiment_2019_10_09_10_58_54_0001] epoch #84 | Computing loss after
2019-10-09 10:59:53 | [experiment_2019_10_09_10_58_54_0001] epoch #84 | Fitting baseline...
2019-10-09 10:59:53 | [experiment_2019_10_09_10_58_54_0001] epoch #84 | Saving snapshot...
2019-10-09 10:59:53 | [experiment_2019_10_09_10_58_54_0001] epoch #84 | Saved
2019-10-09 10:59:53 | [experiment_2019_10_09_10_58_54_0001] epoch #84 | Time 54.39 s
2019-10-09 10:59:53 | [experiment_2019_10_09_10_58_54_0001] epoch #84 | EpochTime 0.66 s
---------------------------------------  -------------
AverageDiscountedReturn                   63.3877
AverageReturn                             99.9756
Entropy                                    0.500772
EnvExecTime                                0.0561702
Extras/EpisodeRewardMean                  99.99
Iteration                                 84
LinearFeatureBaseline/ExplainedVariance    0.999968
MaxReturn                                100
MinReturn                                 99
NumTrajs                                  41
Perplexity                                 1.65
PolicyExecTime                             0.384609
ProcessExecTime                            0.019187
StdReturn                                  0.154257
policy/Entropy                             0.50016
policy/KL                                  0.00837557
policy/KLBefore                           -1.47158e-10
policy/LossAfter                          -0.00916803
policy/LossBefore                          7.56146e-09
policy/dLoss                               0.00916803
---------------------------------------  -------------
2019-10-09 10:59:53 | [experiment_2019_10_09_10_58_54_0001] epoch #85 | Obtaining samples...
2019-10-09 10:59:53 | [experiment_2019_10_09_10_58_54_0001] epoch #85 | Obtaining samples for iteration 85...
2019-10-09 10:59:53 | [experiment_2019_10_09_10_58_54_0001] epoch #85 | Logging diagnostics...
2019-10-09 10:59:53 | [experiment_2019_10_09_10_58_54_0001] epoch #85 | Optimizing policy...
2019-10-09 10:59:53 | [experiment_2019_10_09_10_58_54_0001] epoch #85 | Computing loss before
2019-10-09 10:59:54 | [experiment_2019_10_09_10_58_54_0001] epoch #85 | Computing KL before
2019-10-09 10:59:54 | [experiment_2019_10_09_10_58_54_0001] epoch #85 | Optimizing
2019-10-09 10:59:54 | [experiment_2019_10_09_10_58_54_0001] epoch #85 | Start CG optimization: #parameters: 1282, #inputs: 40, #subsample_inputs: 40
2019-10-09 10:59:54 | [experiment_2019_10_09_10_58_54_0001] epoch #85 | computing loss before
2019-10-09 10:59:54 | [experiment_2019_10_09_10_58_54_0001] epoch #85 | performing update
2019-10-09 10:59:54 | [experiment_2019_10_09_10_58_54_0001] epoch #85 | computing gradient
2019-10-09 10:59:54 | [experiment_2019_10_09_10_58_54_0001] epoch #85 | gradient computed
2019-10-09 10:59:54 | [experiment_2019_10_09_10_58_54_0001] epoch #85 | computing descent direction
2019-10-09 10:59:54 | [experiment_2019_10_09_10_58_54_0001] epoch #85 | descent direction computed
2019-10-09 10:59:54 | [experiment_2019_10_09_10_58_54_0001] epoch #85 | backtrack iters: 1
2019-10-09 10:59:54 | [experiment_2019_10_09_10_58_54_0001] epoch #85 | computing loss after
2019-10-09 10:59:54 | [experiment_2019_10_09_10_58_54_0001] epoch #85 | optimization finished
2019-10-09 10:59:54 | [experiment_2019_10_09_10_58_54_0001] epoch #85 | Computing KL after
2019-10-09 10:59:54 | [experiment_2019_10_09_10_58_54_0001] epoch #85 | Computing loss after
2019-10-09 10:59:54 | [experiment_2019_10_09_10_58_54_0001] epoch #85 | Fitting baseline...
2019-10-09 10:59:54 | [experiment_2019_10_09_10_58_54_0001] epoch #85 | Saving snapshot...
2019-10-09 10:59:54 | [experiment_2019_10_09_10_58_54_0001] epoch #85 | Saved
2019-10-09 10:59:54 | [experiment_2019_10_09_10_58_54_0001] epoch #85 | Time 55.02 s
2019-10-09 10:59:54 | [experiment_2019_10_09_10_58_54_0001] epoch #85 | EpochTime 0.63 s
---------------------------------------  -------------
AverageDiscountedReturn                   63.3968
AverageReturn                            100
Entropy                                    0.508777
EnvExecTime                                0.052304
Extras/EpisodeRewardMean                  99.99
Iteration                                 85
LinearFeatureBaseline/ExplainedVariance    0.999998
MaxReturn                                100
MinReturn                                100
NumTrajs                                  40
Perplexity                                 1.66326
PolicyExecTime                             0.366354
ProcessExecTime                            0.0183966
StdReturn                                  0
policy/Entropy                             0.500033
policy/KL                                  0.00797192
policy/KLBefore                            0
policy/LossAfter                          -0.0171343
policy/LossBefore                          1.19209e-09
policy/dLoss                               0.0171343
---------------------------------------  -------------
2019-10-09 10:59:54 | [experiment_2019_10_09_10_58_54_0001] epoch #86 | Obtaining samples...
2019-10-09 10:59:54 | [experiment_2019_10_09_10_58_54_0001] epoch #86 | Obtaining samples for iteration 86...
2019-10-09 10:59:54 | [experiment_2019_10_09_10_58_54_0001] epoch #86 | Logging diagnostics...
2019-10-09 10:59:54 | [experiment_2019_10_09_10_58_54_0001] epoch #86 | Optimizing policy...
2019-10-09 10:59:54 | [experiment_2019_10_09_10_58_54_0001] epoch #86 | Computing loss before
2019-10-09 10:59:54 | [experiment_2019_10_09_10_58_54_0001] epoch #86 | Computing KL before
2019-10-09 10:59:54 | [experiment_2019_10_09_10_58_54_0001] epoch #86 | Optimizing
2019-10-09 10:59:54 | [experiment_2019_10_09_10_58_54_0001] epoch #86 | Start CG optimization: #parameters: 1282, #inputs: 40, #subsample_inputs: 40
2019-10-09 10:59:54 | [experiment_2019_10_09_10_58_54_0001] epoch #86 | computing loss before
2019-10-09 10:59:54 | [experiment_2019_10_09_10_58_54_0001] epoch #86 | performing update
2019-10-09 10:59:54 | [experiment_2019_10_09_10_58_54_0001] epoch #86 | computing gradient
2019-10-09 10:59:54 | [experiment_2019_10_09_10_58_54_0001] epoch #86 | gradient computed
2019-10-09 10:59:54 | [experiment_2019_10_09_10_58_54_0001] epoch #86 | computing descent direction
2019-10-09 10:59:54 | [experiment_2019_10_09_10_58_54_0001] epoch #86 | descent direction computed
2019-10-09 10:59:54 | [experiment_2019_10_09_10_58_54_0001] epoch #86 | backtrack iters: 1
2019-10-09 10:59:54 | [experiment_2019_10_09_10_58_54_0001] epoch #86 | computing loss after
2019-10-09 10:59:54 | [experiment_2019_10_09_10_58_54_0001] epoch #86 | optimization finished
2019-10-09 10:59:54 | [experiment_2019_10_09_10_58_54_0001] epoch #86 | Computing KL after
2019-10-09 10:59:54 | [experiment_2019_10_09_10_58_54_0001] epoch #86 | Computing loss after
2019-10-09 10:59:54 | [experiment_2019_10_09_10_58_54_0001] epoch #86 | Fitting baseline...
2019-10-09 10:59:54 | [experiment_2019_10_09_10_58_54_0001] epoch #86 | Saving snapshot...
2019-10-09 10:59:54 | [experiment_2019_10_09_10_58_54_0001] epoch #86 | Saved
2019-10-09 10:59:54 | [experiment_2019_10_09_10_58_54_0001] epoch #86 | Time 55.65 s
2019-10-09 10:59:54 | [experiment_2019_10_09_10_58_54_0001] epoch #86 | EpochTime 0.63 s
---------------------------------------  -------------
AverageDiscountedReturn                   63.3968
AverageReturn                            100
Entropy                                    0.507508
EnvExecTime                                0.0499175
Extras/EpisodeRewardMean                 100
Iteration                                 86
LinearFeatureBaseline/ExplainedVariance    1
MaxReturn                                100
MinReturn                                100
NumTrajs                                  40
Perplexity                                 1.66115
PolicyExecTime                             0.37357
ProcessExecTime                            0.0176623
StdReturn                                  0
policy/Entropy                             0.508099
policy/KL                                  0.00990829
policy/KLBefore                            0
policy/LossAfter                          -0.00813918
policy/LossBefore                          1.23978e-08
policy/dLoss                               0.00813919
---------------------------------------  -------------
2019-10-09 10:59:54 | [experiment_2019_10_09_10_58_54_0001] epoch #87 | Obtaining samples...
2019-10-09 10:59:54 | [experiment_2019_10_09_10_58_54_0001] epoch #87 | Obtaining samples for iteration 87...
2019-10-09 10:59:55 | [experiment_2019_10_09_10_58_54_0001] epoch #87 | Logging diagnostics...
2019-10-09 10:59:55 | [experiment_2019_10_09_10_58_54_0001] epoch #87 | Optimizing policy...
2019-10-09 10:59:55 | [experiment_2019_10_09_10_58_54_0001] epoch #87 | Computing loss before
2019-10-09 10:59:55 | [experiment_2019_10_09_10_58_54_0001] epoch #87 | Computing KL before
2019-10-09 10:59:55 | [experiment_2019_10_09_10_58_54_0001] epoch #87 | Optimizing
2019-10-09 10:59:55 | [experiment_2019_10_09_10_58_54_0001] epoch #87 | Start CG optimization: #parameters: 1282, #inputs: 40, #subsample_inputs: 40
2019-10-09 10:59:55 | [experiment_2019_10_09_10_58_54_0001] epoch #87 | computing loss before
2019-10-09 10:59:55 | [experiment_2019_10_09_10_58_54_0001] epoch #87 | performing update
2019-10-09 10:59:55 | [experiment_2019_10_09_10_58_54_0001] epoch #87 | computing gradient
2019-10-09 10:59:55 | [experiment_2019_10_09_10_58_54_0001] epoch #87 | gradient computed
2019-10-09 10:59:55 | [experiment_2019_10_09_10_58_54_0001] epoch #87 | computing descent direction
2019-10-09 10:59:55 | [experiment_2019_10_09_10_58_54_0001] epoch #87 | descent direction computed
2019-10-09 10:59:55 | [experiment_2019_10_09_10_58_54_0001] epoch #87 | backtrack iters: 0
2019-10-09 10:59:55 | [experiment_2019_10_09_10_58_54_0001] epoch #87 | computing loss after
2019-10-09 10:59:55 | [experiment_2019_10_09_10_58_54_0001] epoch #87 | optimization finished
2019-10-09 10:59:55 | [experiment_2019_10_09_10_58_54_0001] epoch #87 | Computing KL after
2019-10-09 10:59:55 | [experiment_2019_10_09_10_58_54_0001] epoch #87 | Computing loss after
2019-10-09 10:59:55 | [experiment_2019_10_09_10_58_54_0001] epoch #87 | Fitting baseline...
2019-10-09 10:59:55 | [experiment_2019_10_09_10_58_54_0001] epoch #87 | Saving snapshot...
2019-10-09 10:59:55 | [experiment_2019_10_09_10_58_54_0001] epoch #87 | Saved
2019-10-09 10:59:55 | [experiment_2019_10_09_10_58_54_0001] epoch #87 | Time 56.28 s
2019-10-09 10:59:55 | [experiment_2019_10_09_10_58_54_0001] epoch #87 | EpochTime 0.62 s
---------------------------------------  -------------
AverageDiscountedReturn                   63.3968
AverageReturn                            100
Entropy                                    0.513396
EnvExecTime                                0.051168
Extras/EpisodeRewardMean                 100
Iteration                                 87
LinearFeatureBaseline/ExplainedVariance    1
MaxReturn                                100
MinReturn                                100
NumTrajs                                  40
Perplexity                                 1.67096
PolicyExecTime                             0.358128
ProcessExecTime                            0.0178931
StdReturn                                  0
policy/Entropy                             0.513972
policy/KL                                  0.00786554
policy/KLBefore                            0
policy/LossAfter                          -0.00732721
policy/LossBefore                         -3.93391e-09
policy/dLoss                               0.00732721
---------------------------------------  -------------
2019-10-09 10:59:55 | [experiment_2019_10_09_10_58_54_0001] epoch #88 | Obtaining samples...
2019-10-09 10:59:55 | [experiment_2019_10_09_10_58_54_0001] epoch #88 | Obtaining samples for iteration 88...
2019-10-09 10:59:55 | [experiment_2019_10_09_10_58_54_0001] epoch #88 | Logging diagnostics...
2019-10-09 10:59:55 | [experiment_2019_10_09_10_58_54_0001] epoch #88 | Optimizing policy...
2019-10-09 10:59:55 | [experiment_2019_10_09_10_58_54_0001] epoch #88 | Computing loss before
2019-10-09 10:59:55 | [experiment_2019_10_09_10_58_54_0001] epoch #88 | Computing KL before
2019-10-09 10:59:55 | [experiment_2019_10_09_10_58_54_0001] epoch #88 | Optimizing
2019-10-09 10:59:55 | [experiment_2019_10_09_10_58_54_0001] epoch #88 | Start CG optimization: #parameters: 1282, #inputs: 41, #subsample_inputs: 41
2019-10-09 10:59:55 | [experiment_2019_10_09_10_58_54_0001] epoch #88 | computing loss before
2019-10-09 10:59:55 | [experiment_2019_10_09_10_58_54_0001] epoch #88 | performing update
2019-10-09 10:59:55 | [experiment_2019_10_09_10_58_54_0001] epoch #88 | computing gradient
2019-10-09 10:59:55 | [experiment_2019_10_09_10_58_54_0001] epoch #88 | gradient computed
2019-10-09 10:59:55 | [experiment_2019_10_09_10_58_54_0001] epoch #88 | computing descent direction
2019-10-09 10:59:55 | [experiment_2019_10_09_10_58_54_0001] epoch #88 | descent direction computed
2019-10-09 10:59:55 | [experiment_2019_10_09_10_58_54_0001] epoch #88 | backtrack iters: 1
2019-10-09 10:59:55 | [experiment_2019_10_09_10_58_54_0001] epoch #88 | computing loss after
2019-10-09 10:59:55 | [experiment_2019_10_09_10_58_54_0001] epoch #88 | optimization finished
2019-10-09 10:59:55 | [experiment_2019_10_09_10_58_54_0001] epoch #88 | Computing KL after
2019-10-09 10:59:55 | [experiment_2019_10_09_10_58_54_0001] epoch #88 | Computing loss after
2019-10-09 10:59:56 | [experiment_2019_10_09_10_58_54_0001] epoch #88 | Fitting baseline...
2019-10-09 10:59:56 | [experiment_2019_10_09_10_58_54_0001] epoch #88 | Saving snapshot...
2019-10-09 10:59:56 | [experiment_2019_10_09_10_58_54_0001] epoch #88 | Saved
2019-10-09 10:59:56 | [experiment_2019_10_09_10_58_54_0001] epoch #88 | Time 56.93 s
2019-10-09 10:59:56 | [experiment_2019_10_09_10_58_54_0001] epoch #88 | EpochTime 0.65 s
---------------------------------------  -------------
AverageDiscountedReturn                   63.0572
AverageReturn                             99.1707
Entropy                                    0.508405
EnvExecTime                                0.0530441
Extras/EpisodeRewardMean                  99.66
Iteration                                 88
LinearFeatureBaseline/ExplainedVariance    0.983838
MaxReturn                                100
MinReturn                                 75
NumTrajs                                  41
Perplexity                                 1.66264
PolicyExecTime                             0.374694
ProcessExecTime                            0.0185304
StdReturn                                  4.06593
policy/Entropy                             0.509371
policy/KL                                  0.00909577
policy/KLBefore                            2.44647e-10
policy/LossAfter                          -0.0121603
policy/LossBefore                         -1.66383e-09
policy/dLoss                               0.0121603
---------------------------------------  -------------
2019-10-09 10:59:56 | [experiment_2019_10_09_10_58_54_0001] epoch #89 | Obtaining samples...
2019-10-09 10:59:56 | [experiment_2019_10_09_10_58_54_0001] epoch #89 | Obtaining samples for iteration 89...
2019-10-09 10:59:56 | [experiment_2019_10_09_10_58_54_0001] epoch #89 | Logging diagnostics...
2019-10-09 10:59:56 | [experiment_2019_10_09_10_58_54_0001] epoch #89 | Optimizing policy...
2019-10-09 10:59:56 | [experiment_2019_10_09_10_58_54_0001] epoch #89 | Computing loss before
2019-10-09 10:59:56 | [experiment_2019_10_09_10_58_54_0001] epoch #89 | Computing KL before
2019-10-09 10:59:56 | [experiment_2019_10_09_10_58_54_0001] epoch #89 | Optimizing
2019-10-09 10:59:56 | [experiment_2019_10_09_10_58_54_0001] epoch #89 | Start CG optimization: #parameters: 1282, #inputs: 40, #subsample_inputs: 40
2019-10-09 10:59:56 | [experiment_2019_10_09_10_58_54_0001] epoch #89 | computing loss before
2019-10-09 10:59:56 | [experiment_2019_10_09_10_58_54_0001] epoch #89 | performing update
2019-10-09 10:59:56 | [experiment_2019_10_09_10_58_54_0001] epoch #89 | computing gradient
2019-10-09 10:59:56 | [experiment_2019_10_09_10_58_54_0001] epoch #89 | gradient computed
2019-10-09 10:59:56 | [experiment_2019_10_09_10_58_54_0001] epoch #89 | computing descent direction
2019-10-09 10:59:56 | [experiment_2019_10_09_10_58_54_0001] epoch #89 | descent direction computed
2019-10-09 10:59:56 | [experiment_2019_10_09_10_58_54_0001] epoch #89 | backtrack iters: 0
2019-10-09 10:59:56 | [experiment_2019_10_09_10_58_54_0001] epoch #89 | computing loss after
2019-10-09 10:59:56 | [experiment_2019_10_09_10_58_54_0001] epoch #89 | optimization finished
2019-10-09 10:59:56 | [experiment_2019_10_09_10_58_54_0001] epoch #89 | Computing KL after
2019-10-09 10:59:56 | [experiment_2019_10_09_10_58_54_0001] epoch #89 | Computing loss after
2019-10-09 10:59:56 | [experiment_2019_10_09_10_58_54_0001] epoch #89 | Fitting baseline...
2019-10-09 10:59:56 | [experiment_2019_10_09_10_58_54_0001] epoch #89 | Saving snapshot...
2019-10-09 10:59:56 | [experiment_2019_10_09_10_58_54_0001] epoch #89 | Saved
2019-10-09 10:59:56 | [experiment_2019_10_09_10_58_54_0001] epoch #89 | Time 57.56 s
2019-10-09 10:59:56 | [experiment_2019_10_09_10_58_54_0001] epoch #89 | EpochTime 0.62 s
---------------------------------------  -------------
AverageDiscountedReturn                   63.3968
AverageReturn                            100
Entropy                                    0.50857
EnvExecTime                                0.0516849
Extras/EpisodeRewardMean                  99.66
Iteration                                 89
LinearFeatureBaseline/ExplainedVariance    0.998487
MaxReturn                                100
MinReturn                                100
NumTrajs                                  40
Perplexity                                 1.66291
PolicyExecTime                             0.362121
ProcessExecTime                            0.017909
StdReturn                                  0
policy/Entropy                             0.488991
policy/KL                                  0.00614628
policy/KLBefore                            0
policy/LossAfter                          -0.0139782
policy/LossBefore                         -4.76837e-10
policy/dLoss                               0.0139782
---------------------------------------  -------------
2019-10-09 10:59:56 | [experiment_2019_10_09_10_58_54_0001] epoch #90 | Obtaining samples...
2019-10-09 10:59:56 | [experiment_2019_10_09_10_58_54_0001] epoch #90 | Obtaining samples for iteration 90...
2019-10-09 10:59:57 | [experiment_2019_10_09_10_58_54_0001] epoch #90 | Logging diagnostics...
2019-10-09 10:59:57 | [experiment_2019_10_09_10_58_54_0001] epoch #90 | Optimizing policy...
2019-10-09 10:59:57 | [experiment_2019_10_09_10_58_54_0001] epoch #90 | Computing loss before
2019-10-09 10:59:57 | [experiment_2019_10_09_10_58_54_0001] epoch #90 | Computing KL before
2019-10-09 10:59:57 | [experiment_2019_10_09_10_58_54_0001] epoch #90 | Optimizing
2019-10-09 10:59:57 | [experiment_2019_10_09_10_58_54_0001] epoch #90 | Start CG optimization: #parameters: 1282, #inputs: 40, #subsample_inputs: 40
2019-10-09 10:59:57 | [experiment_2019_10_09_10_58_54_0001] epoch #90 | computing loss before
2019-10-09 10:59:57 | [experiment_2019_10_09_10_58_54_0001] epoch #90 | performing update
2019-10-09 10:59:57 | [experiment_2019_10_09_10_58_54_0001] epoch #90 | computing gradient
2019-10-09 10:59:57 | [experiment_2019_10_09_10_58_54_0001] epoch #90 | gradient computed
2019-10-09 10:59:57 | [experiment_2019_10_09_10_58_54_0001] epoch #90 | computing descent direction
2019-10-09 10:59:57 | [experiment_2019_10_09_10_58_54_0001] epoch #90 | descent direction computed
2019-10-09 10:59:57 | [experiment_2019_10_09_10_58_54_0001] epoch #90 | backtrack iters: 2
2019-10-09 10:59:57 | [experiment_2019_10_09_10_58_54_0001] epoch #90 | computing loss after
2019-10-09 10:59:57 | [experiment_2019_10_09_10_58_54_0001] epoch #90 | optimization finished
2019-10-09 10:59:57 | [experiment_2019_10_09_10_58_54_0001] epoch #90 | Computing KL after
2019-10-09 10:59:57 | [experiment_2019_10_09_10_58_54_0001] epoch #90 | Computing loss after
2019-10-09 10:59:57 | [experiment_2019_10_09_10_58_54_0001] epoch #90 | Fitting baseline...
2019-10-09 10:59:57 | [experiment_2019_10_09_10_58_54_0001] epoch #90 | Saving snapshot...
2019-10-09 10:59:57 | [experiment_2019_10_09_10_58_54_0001] epoch #90 | Saved
2019-10-09 10:59:57 | [experiment_2019_10_09_10_58_54_0001] epoch #90 | Time 58.20 s
2019-10-09 10:59:57 | [experiment_2019_10_09_10_58_54_0001] epoch #90 | EpochTime 0.64 s
---------------------------------------  -------------
AverageDiscountedReturn                   63.3968
AverageReturn                            100
Entropy                                    0.500006
EnvExecTime                                0.0520058
Extras/EpisodeRewardMean                  99.91
Iteration                                 90
LinearFeatureBaseline/ExplainedVariance    1
MaxReturn                                100
MinReturn                                100
NumTrajs                                  40
Perplexity                                 1.64873
PolicyExecTime                             0.36868
ProcessExecTime                            0.0185301
StdReturn                                  0
policy/Entropy                             0.511151
policy/KL                                  0.00965739
policy/KLBefore                            0
policy/LossAfter                          -0.0057217
policy/LossBefore                          1.26958e-08
policy/dLoss                               0.00572171
---------------------------------------  -------------
2019-10-09 10:59:57 | [experiment_2019_10_09_10_58_54_0001] epoch #91 | Obtaining samples...
2019-10-09 10:59:57 | [experiment_2019_10_09_10_58_54_0001] epoch #91 | Obtaining samples for iteration 91...
2019-10-09 10:59:57 | [experiment_2019_10_09_10_58_54_0001] epoch #91 | Logging diagnostics...
2019-10-09 10:59:57 | [experiment_2019_10_09_10_58_54_0001] epoch #91 | Optimizing policy...
2019-10-09 10:59:57 | [experiment_2019_10_09_10_58_54_0001] epoch #91 | Computing loss before
2019-10-09 10:59:57 | [experiment_2019_10_09_10_58_54_0001] epoch #91 | Computing KL before
2019-10-09 10:59:57 | [experiment_2019_10_09_10_58_54_0001] epoch #91 | Optimizing
2019-10-09 10:59:57 | [experiment_2019_10_09_10_58_54_0001] epoch #91 | Start CG optimization: #parameters: 1282, #inputs: 40, #subsample_inputs: 40
2019-10-09 10:59:57 | [experiment_2019_10_09_10_58_54_0001] epoch #91 | computing loss before
2019-10-09 10:59:57 | [experiment_2019_10_09_10_58_54_0001] epoch #91 | performing update
2019-10-09 10:59:57 | [experiment_2019_10_09_10_58_54_0001] epoch #91 | computing gradient
2019-10-09 10:59:57 | [experiment_2019_10_09_10_58_54_0001] epoch #91 | gradient computed
2019-10-09 10:59:57 | [experiment_2019_10_09_10_58_54_0001] epoch #91 | computing descent direction
2019-10-09 10:59:57 | [experiment_2019_10_09_10_58_54_0001] epoch #91 | descent direction computed
2019-10-09 10:59:57 | [experiment_2019_10_09_10_58_54_0001] epoch #91 | backtrack iters: 2
2019-10-09 10:59:57 | [experiment_2019_10_09_10_58_54_0001] epoch #91 | computing loss after
2019-10-09 10:59:57 | [experiment_2019_10_09_10_58_54_0001] epoch #91 | optimization finished
2019-10-09 10:59:57 | [experiment_2019_10_09_10_58_54_0001] epoch #91 | Computing KL after
2019-10-09 10:59:57 | [experiment_2019_10_09_10_58_54_0001] epoch #91 | Computing loss after
2019-10-09 10:59:57 | [experiment_2019_10_09_10_58_54_0001] epoch #91 | Fitting baseline...
2019-10-09 10:59:57 | [experiment_2019_10_09_10_58_54_0001] epoch #91 | Saving snapshot...
2019-10-09 10:59:57 | [experiment_2019_10_09_10_58_54_0001] epoch #91 | Saved
2019-10-09 10:59:57 | [experiment_2019_10_09_10_58_54_0001] epoch #91 | Time 58.82 s
2019-10-09 10:59:57 | [experiment_2019_10_09_10_58_54_0001] epoch #91 | EpochTime 0.61 s
---------------------------------------  ------------
AverageDiscountedReturn                   63.3968
AverageReturn                            100
Entropy                                    0.501093
EnvExecTime                                0.050204
Extras/EpisodeRewardMean                 100
Iteration                                 91
LinearFeatureBaseline/ExplainedVariance    1
MaxReturn                                100
MinReturn                                100
NumTrajs                                  40
Perplexity                                 1.65052
PolicyExecTime                             0.357744
ProcessExecTime                            0.0173948
StdReturn                                  0
policy/Entropy                             0.506626
policy/KL                                  0.00630062
policy/KLBefore                            0
policy/LossAfter                          -0.00436918
policy/LossBefore                         -1.2219e-08
policy/dLoss                               0.00436917
---------------------------------------  ------------
2019-10-09 10:59:57 | [experiment_2019_10_09_10_58_54_0001] epoch #92 | Obtaining samples...
2019-10-09 10:59:57 | [experiment_2019_10_09_10_58_54_0001] epoch #92 | Obtaining samples for iteration 92...
2019-10-09 10:59:58 | [experiment_2019_10_09_10_58_54_0001] epoch #92 | Logging diagnostics...
2019-10-09 10:59:58 | [experiment_2019_10_09_10_58_54_0001] epoch #92 | Optimizing policy...
2019-10-09 10:59:58 | [experiment_2019_10_09_10_58_54_0001] epoch #92 | Computing loss before
2019-10-09 10:59:58 | [experiment_2019_10_09_10_58_54_0001] epoch #92 | Computing KL before
2019-10-09 10:59:58 | [experiment_2019_10_09_10_58_54_0001] epoch #92 | Optimizing
2019-10-09 10:59:58 | [experiment_2019_10_09_10_58_54_0001] epoch #92 | Start CG optimization: #parameters: 1282, #inputs: 40, #subsample_inputs: 40
2019-10-09 10:59:58 | [experiment_2019_10_09_10_58_54_0001] epoch #92 | computing loss before
2019-10-09 10:59:58 | [experiment_2019_10_09_10_58_54_0001] epoch #92 | performing update
2019-10-09 10:59:58 | [experiment_2019_10_09_10_58_54_0001] epoch #92 | computing gradient
2019-10-09 10:59:58 | [experiment_2019_10_09_10_58_54_0001] epoch #92 | gradient computed
2019-10-09 10:59:58 | [experiment_2019_10_09_10_58_54_0001] epoch #92 | computing descent direction
2019-10-09 10:59:58 | [experiment_2019_10_09_10_58_54_0001] epoch #92 | descent direction computed
2019-10-09 10:59:58 | [experiment_2019_10_09_10_58_54_0001] epoch #92 | backtrack iters: 1
2019-10-09 10:59:58 | [experiment_2019_10_09_10_58_54_0001] epoch #92 | computing loss after
2019-10-09 10:59:58 | [experiment_2019_10_09_10_58_54_0001] epoch #92 | optimization finished
2019-10-09 10:59:58 | [experiment_2019_10_09_10_58_54_0001] epoch #92 | Computing KL after
2019-10-09 10:59:58 | [experiment_2019_10_09_10_58_54_0001] epoch #92 | Computing loss after
2019-10-09 10:59:58 | [experiment_2019_10_09_10_58_54_0001] epoch #92 | Fitting baseline...
2019-10-09 10:59:58 | [experiment_2019_10_09_10_58_54_0001] epoch #92 | Saving snapshot...
2019-10-09 10:59:58 | [experiment_2019_10_09_10_58_54_0001] epoch #92 | Saved
2019-10-09 10:59:58 | [experiment_2019_10_09_10_58_54_0001] epoch #92 | Time 59.45 s
2019-10-09 10:59:58 | [experiment_2019_10_09_10_58_54_0001] epoch #92 | EpochTime 0.62 s
---------------------------------------  -------------
AverageDiscountedReturn                   63.3968
AverageReturn                            100
Entropy                                    0.504437
EnvExecTime                                0.0523274
Extras/EpisodeRewardMean                 100
Iteration                                 92
LinearFeatureBaseline/ExplainedVariance    1
MaxReturn                                100
MinReturn                                100
NumTrajs                                  40
Perplexity                                 1.65605
PolicyExecTime                             0.362137
ProcessExecTime                            0.0186625
StdReturn                                  0
policy/Entropy                             0.515662
policy/KL                                  0.0070942
policy/KLBefore                            0
policy/LossAfter                          -0.00595082
policy/LossBefore                          1.90735e-09
policy/dLoss                               0.00595082
---------------------------------------  -------------
2019-10-09 10:59:58 | [experiment_2019_10_09_10_58_54_0001] epoch #93 | Obtaining samples...
2019-10-09 10:59:58 | [experiment_2019_10_09_10_58_54_0001] epoch #93 | Obtaining samples for iteration 93...
2019-10-09 10:59:59 | [experiment_2019_10_09_10_58_54_0001] epoch #93 | Logging diagnostics...
2019-10-09 10:59:59 | [experiment_2019_10_09_10_58_54_0001] epoch #93 | Optimizing policy...
2019-10-09 10:59:59 | [experiment_2019_10_09_10_58_54_0001] epoch #93 | Computing loss before
2019-10-09 10:59:59 | [experiment_2019_10_09_10_58_54_0001] epoch #93 | Computing KL before
2019-10-09 10:59:59 | [experiment_2019_10_09_10_58_54_0001] epoch #93 | Optimizing
2019-10-09 10:59:59 | [experiment_2019_10_09_10_58_54_0001] epoch #93 | Start CG optimization: #parameters: 1282, #inputs: 40, #subsample_inputs: 40
2019-10-09 10:59:59 | [experiment_2019_10_09_10_58_54_0001] epoch #93 | computing loss before
2019-10-09 10:59:59 | [experiment_2019_10_09_10_58_54_0001] epoch #93 | performing update
2019-10-09 10:59:59 | [experiment_2019_10_09_10_58_54_0001] epoch #93 | computing gradient
2019-10-09 10:59:59 | [experiment_2019_10_09_10_58_54_0001] epoch #93 | gradient computed
2019-10-09 10:59:59 | [experiment_2019_10_09_10_58_54_0001] epoch #93 | computing descent direction
2019-10-09 10:59:59 | [experiment_2019_10_09_10_58_54_0001] epoch #93 | descent direction computed
2019-10-09 10:59:59 | [experiment_2019_10_09_10_58_54_0001] epoch #93 | backtrack iters: 1
2019-10-09 10:59:59 | [experiment_2019_10_09_10_58_54_0001] epoch #93 | computing loss after
2019-10-09 10:59:59 | [experiment_2019_10_09_10_58_54_0001] epoch #93 | optimization finished
2019-10-09 10:59:59 | [experiment_2019_10_09_10_58_54_0001] epoch #93 | Computing KL after
2019-10-09 10:59:59 | [experiment_2019_10_09_10_58_54_0001] epoch #93 | Computing loss after
2019-10-09 10:59:59 | [experiment_2019_10_09_10_58_54_0001] epoch #93 | Fitting baseline...
2019-10-09 10:59:59 | [experiment_2019_10_09_10_58_54_0001] epoch #93 | Saving snapshot...
2019-10-09 10:59:59 | [experiment_2019_10_09_10_58_54_0001] epoch #93 | Saved
2019-10-09 10:59:59 | [experiment_2019_10_09_10_58_54_0001] epoch #93 | Time 60.09 s
2019-10-09 10:59:59 | [experiment_2019_10_09_10_58_54_0001] epoch #93 | EpochTime 0.64 s
---------------------------------------  -------------
AverageDiscountedReturn                   63.3968
AverageReturn                            100
Entropy                                    0.516161
EnvExecTime                                0.0531712
Extras/EpisodeRewardMean                 100
Iteration                                 93
LinearFeatureBaseline/ExplainedVariance    1
MaxReturn                                100
MinReturn                                100
NumTrajs                                  40
Perplexity                                 1.67558
PolicyExecTime                             0.360574
ProcessExecTime                            0.0186152
StdReturn                                  0
policy/Entropy                             0.504668
policy/KL                                  0.00645223
policy/KLBefore                            0
policy/LossAfter                          -0.00732024
policy/LossBefore                         -5.48363e-09
policy/dLoss                               0.00732023
---------------------------------------  -------------
2019-10-09 10:59:59 | [experiment_2019_10_09_10_58_54_0001] epoch #94 | Obtaining samples...
2019-10-09 10:59:59 | [experiment_2019_10_09_10_58_54_0001] epoch #94 | Obtaining samples for iteration 94...
2019-10-09 10:59:59 | [experiment_2019_10_09_10_58_54_0001] epoch #94 | Logging diagnostics...
2019-10-09 10:59:59 | [experiment_2019_10_09_10_58_54_0001] epoch #94 | Optimizing policy...
2019-10-09 10:59:59 | [experiment_2019_10_09_10_58_54_0001] epoch #94 | Computing loss before
2019-10-09 10:59:59 | [experiment_2019_10_09_10_58_54_0001] epoch #94 | Computing KL before
2019-10-09 10:59:59 | [experiment_2019_10_09_10_58_54_0001] epoch #94 | Optimizing
2019-10-09 10:59:59 | [experiment_2019_10_09_10_58_54_0001] epoch #94 | Start CG optimization: #parameters: 1282, #inputs: 40, #subsample_inputs: 40
2019-10-09 10:59:59 | [experiment_2019_10_09_10_58_54_0001] epoch #94 | computing loss before
2019-10-09 10:59:59 | [experiment_2019_10_09_10_58_54_0001] epoch #94 | performing update
2019-10-09 10:59:59 | [experiment_2019_10_09_10_58_54_0001] epoch #94 | computing gradient
2019-10-09 10:59:59 | [experiment_2019_10_09_10_58_54_0001] epoch #94 | gradient computed
2019-10-09 10:59:59 | [experiment_2019_10_09_10_58_54_0001] epoch #94 | computing descent direction
2019-10-09 10:59:59 | [experiment_2019_10_09_10_58_54_0001] epoch #94 | descent direction computed
2019-10-09 10:59:59 | [experiment_2019_10_09_10_58_54_0001] epoch #94 | backtrack iters: 2
2019-10-09 10:59:59 | [experiment_2019_10_09_10_58_54_0001] epoch #94 | computing loss after
2019-10-09 10:59:59 | [experiment_2019_10_09_10_58_54_0001] epoch #94 | optimization finished
2019-10-09 10:59:59 | [experiment_2019_10_09_10_58_54_0001] epoch #94 | Computing KL after
2019-10-09 10:59:59 | [experiment_2019_10_09_10_58_54_0001] epoch #94 | Computing loss after
2019-10-09 10:59:59 | [experiment_2019_10_09_10_58_54_0001] epoch #94 | Fitting baseline...
2019-10-09 10:59:59 | [experiment_2019_10_09_10_58_54_0001] epoch #94 | Saving snapshot...
2019-10-09 10:59:59 | [experiment_2019_10_09_10_58_54_0001] epoch #94 | Saved
2019-10-09 10:59:59 | [experiment_2019_10_09_10_58_54_0001] epoch #94 | Time 60.77 s
2019-10-09 10:59:59 | [experiment_2019_10_09_10_58_54_0001] epoch #94 | EpochTime 0.68 s
---------------------------------------  -------------
AverageDiscountedReturn                   63.3968
AverageReturn                            100
Entropy                                    0.504777
EnvExecTime                                0.0573473
Extras/EpisodeRewardMean                 100
Iteration                                 94
LinearFeatureBaseline/ExplainedVariance    1
MaxReturn                                100
MinReturn                                100
NumTrajs                                  40
Perplexity                                 1.65662
PolicyExecTime                             0.387916
ProcessExecTime                            0.020678
StdReturn                                  0
policy/Entropy                             0.503496
policy/KL                                  0.00860346
policy/KLBefore                            0
policy/LossAfter                          -0.00739904
policy/LossBefore                          1.01328e-09
policy/dLoss                               0.00739904
---------------------------------------  -------------
2019-10-09 10:59:59 | [experiment_2019_10_09_10_58_54_0001] epoch #95 | Obtaining samples...
2019-10-09 10:59:59 | [experiment_2019_10_09_10_58_54_0001] epoch #95 | Obtaining samples for iteration 95...
2019-10-09 11:00:00 | [experiment_2019_10_09_10_58_54_0001] epoch #95 | Logging diagnostics...
2019-10-09 11:00:00 | [experiment_2019_10_09_10_58_54_0001] epoch #95 | Optimizing policy...
2019-10-09 11:00:00 | [experiment_2019_10_09_10_58_54_0001] epoch #95 | Computing loss before
2019-10-09 11:00:00 | [experiment_2019_10_09_10_58_54_0001] epoch #95 | Computing KL before
2019-10-09 11:00:00 | [experiment_2019_10_09_10_58_54_0001] epoch #95 | Optimizing
2019-10-09 11:00:00 | [experiment_2019_10_09_10_58_54_0001] epoch #95 | Start CG optimization: #parameters: 1282, #inputs: 40, #subsample_inputs: 40
2019-10-09 11:00:00 | [experiment_2019_10_09_10_58_54_0001] epoch #95 | computing loss before
2019-10-09 11:00:00 | [experiment_2019_10_09_10_58_54_0001] epoch #95 | performing update
2019-10-09 11:00:00 | [experiment_2019_10_09_10_58_54_0001] epoch #95 | computing gradient
2019-10-09 11:00:00 | [experiment_2019_10_09_10_58_54_0001] epoch #95 | gradient computed
2019-10-09 11:00:00 | [experiment_2019_10_09_10_58_54_0001] epoch #95 | computing descent direction
2019-10-09 11:00:00 | [experiment_2019_10_09_10_58_54_0001] epoch #95 | descent direction computed
2019-10-09 11:00:00 | [experiment_2019_10_09_10_58_54_0001] epoch #95 | backtrack iters: 0
2019-10-09 11:00:00 | [experiment_2019_10_09_10_58_54_0001] epoch #95 | computing loss after
2019-10-09 11:00:00 | [experiment_2019_10_09_10_58_54_0001] epoch #95 | optimization finished
2019-10-09 11:00:00 | [experiment_2019_10_09_10_58_54_0001] epoch #95 | Computing KL after
2019-10-09 11:00:00 | [experiment_2019_10_09_10_58_54_0001] epoch #95 | Computing loss after
2019-10-09 11:00:00 | [experiment_2019_10_09_10_58_54_0001] epoch #95 | Fitting baseline...
2019-10-09 11:00:00 | [experiment_2019_10_09_10_58_54_0001] epoch #95 | Saving snapshot...
2019-10-09 11:00:00 | [experiment_2019_10_09_10_58_54_0001] epoch #95 | Saved
2019-10-09 11:00:00 | [experiment_2019_10_09_10_58_54_0001] epoch #95 | Time 61.40 s
2019-10-09 11:00:00 | [experiment_2019_10_09_10_58_54_0001] epoch #95 | EpochTime 0.62 s
---------------------------------------  -------------
AverageDiscountedReturn                   63.3968
AverageReturn                            100
Entropy                                    0.517312
EnvExecTime                                0.052093
Extras/EpisodeRewardMean                 100
Iteration                                 95
LinearFeatureBaseline/ExplainedVariance    0.999999
MaxReturn                                100
MinReturn                                100
NumTrajs                                  40
Perplexity                                 1.67751
PolicyExecTime                             0.350677
ProcessExecTime                            0.0186481
StdReturn                                  0
policy/Entropy                             0.50896
policy/KL                                  0.00945668
policy/KLBefore                            0
policy/LossAfter                          -0.0123184
policy/LossBefore                         -8.10623e-09
policy/dLoss                               0.0123184
---------------------------------------  -------------
2019-10-09 11:00:00 | [experiment_2019_10_09_10_58_54_0001] epoch #96 | Obtaining samples...
2019-10-09 11:00:00 | [experiment_2019_10_09_10_58_54_0001] epoch #96 | Obtaining samples for iteration 96...
2019-10-09 11:00:01 | [experiment_2019_10_09_10_58_54_0001] epoch #96 | Logging diagnostics...
2019-10-09 11:00:01 | [experiment_2019_10_09_10_58_54_0001] epoch #96 | Optimizing policy...
2019-10-09 11:00:01 | [experiment_2019_10_09_10_58_54_0001] epoch #96 | Computing loss before
2019-10-09 11:00:01 | [experiment_2019_10_09_10_58_54_0001] epoch #96 | Computing KL before
2019-10-09 11:00:01 | [experiment_2019_10_09_10_58_54_0001] epoch #96 | Optimizing
2019-10-09 11:00:01 | [experiment_2019_10_09_10_58_54_0001] epoch #96 | Start CG optimization: #parameters: 1282, #inputs: 40, #subsample_inputs: 40
2019-10-09 11:00:01 | [experiment_2019_10_09_10_58_54_0001] epoch #96 | computing loss before
2019-10-09 11:00:01 | [experiment_2019_10_09_10_58_54_0001] epoch #96 | performing update
2019-10-09 11:00:01 | [experiment_2019_10_09_10_58_54_0001] epoch #96 | computing gradient
2019-10-09 11:00:01 | [experiment_2019_10_09_10_58_54_0001] epoch #96 | gradient computed
2019-10-09 11:00:01 | [experiment_2019_10_09_10_58_54_0001] epoch #96 | computing descent direction
2019-10-09 11:00:01 | [experiment_2019_10_09_10_58_54_0001] epoch #96 | descent direction computed
2019-10-09 11:00:01 | [experiment_2019_10_09_10_58_54_0001] epoch #96 | backtrack iters: 2
2019-10-09 11:00:01 | [experiment_2019_10_09_10_58_54_0001] epoch #96 | computing loss after
2019-10-09 11:00:01 | [experiment_2019_10_09_10_58_54_0001] epoch #96 | optimization finished
2019-10-09 11:00:01 | [experiment_2019_10_09_10_58_54_0001] epoch #96 | Computing KL after
2019-10-09 11:00:01 | [experiment_2019_10_09_10_58_54_0001] epoch #96 | Computing loss after
2019-10-09 11:00:01 | [experiment_2019_10_09_10_58_54_0001] epoch #96 | Fitting baseline...
2019-10-09 11:00:01 | [experiment_2019_10_09_10_58_54_0001] epoch #96 | Saving snapshot...
2019-10-09 11:00:01 | [experiment_2019_10_09_10_58_54_0001] epoch #96 | Saved
2019-10-09 11:00:01 | [experiment_2019_10_09_10_58_54_0001] epoch #96 | Time 62.10 s
2019-10-09 11:00:01 | [experiment_2019_10_09_10_58_54_0001] epoch #96 | EpochTime 0.69 s
---------------------------------------  -------------
AverageDiscountedReturn                   63.3968
AverageReturn                            100
Entropy                                    0.524347
EnvExecTime                                0.0516195
Extras/EpisodeRewardMean                 100
Iteration                                 96
LinearFeatureBaseline/ExplainedVariance    1
MaxReturn                                100
MinReturn                                100
NumTrajs                                  40
Perplexity                                 1.68936
PolicyExecTime                             0.415185
ProcessExecTime                            0.018842
StdReturn                                  0
policy/Entropy                             0.52371
policy/KL                                  0.00610002
policy/KLBefore                            0
policy/LossAfter                          -0.00987183
policy/LossBefore                         -1.97887e-08
policy/dLoss                               0.00987181
---------------------------------------  -------------
2019-10-09 11:00:01 | [experiment_2019_10_09_10_58_54_0001] epoch #97 | Obtaining samples...
2019-10-09 11:00:01 | [experiment_2019_10_09_10_58_54_0001] epoch #97 | Obtaining samples for iteration 97...
2019-10-09 11:00:01 | [experiment_2019_10_09_10_58_54_0001] epoch #97 | Logging diagnostics...
2019-10-09 11:00:01 | [experiment_2019_10_09_10_58_54_0001] epoch #97 | Optimizing policy...
2019-10-09 11:00:01 | [experiment_2019_10_09_10_58_54_0001] epoch #97 | Computing loss before
2019-10-09 11:00:01 | [experiment_2019_10_09_10_58_54_0001] epoch #97 | Computing KL before
2019-10-09 11:00:01 | [experiment_2019_10_09_10_58_54_0001] epoch #97 | Optimizing
2019-10-09 11:00:01 | [experiment_2019_10_09_10_58_54_0001] epoch #97 | Start CG optimization: #parameters: 1282, #inputs: 40, #subsample_inputs: 40
2019-10-09 11:00:01 | [experiment_2019_10_09_10_58_54_0001] epoch #97 | computing loss before
2019-10-09 11:00:01 | [experiment_2019_10_09_10_58_54_0001] epoch #97 | performing update
2019-10-09 11:00:01 | [experiment_2019_10_09_10_58_54_0001] epoch #97 | computing gradient
2019-10-09 11:00:01 | [experiment_2019_10_09_10_58_54_0001] epoch #97 | gradient computed
2019-10-09 11:00:01 | [experiment_2019_10_09_10_58_54_0001] epoch #97 | computing descent direction
2019-10-09 11:00:01 | [experiment_2019_10_09_10_58_54_0001] epoch #97 | descent direction computed
2019-10-09 11:00:01 | [experiment_2019_10_09_10_58_54_0001] epoch #97 | backtrack iters: 2
2019-10-09 11:00:01 | [experiment_2019_10_09_10_58_54_0001] epoch #97 | computing loss after
2019-10-09 11:00:01 | [experiment_2019_10_09_10_58_54_0001] epoch #97 | optimization finished
2019-10-09 11:00:01 | [experiment_2019_10_09_10_58_54_0001] epoch #97 | Computing KL after
2019-10-09 11:00:01 | [experiment_2019_10_09_10_58_54_0001] epoch #97 | Computing loss after
2019-10-09 11:00:01 | [experiment_2019_10_09_10_58_54_0001] epoch #97 | Fitting baseline...
2019-10-09 11:00:01 | [experiment_2019_10_09_10_58_54_0001] epoch #97 | Saving snapshot...
2019-10-09 11:00:01 | [experiment_2019_10_09_10_58_54_0001] epoch #97 | Saved
2019-10-09 11:00:01 | [experiment_2019_10_09_10_58_54_0001] epoch #97 | Time 62.75 s
2019-10-09 11:00:01 | [experiment_2019_10_09_10_58_54_0001] epoch #97 | EpochTime 0.64 s
---------------------------------------  -------------
AverageDiscountedReturn                   63.3968
AverageReturn                            100
Entropy                                    0.522225
EnvExecTime                                0.054153
Extras/EpisodeRewardMean                 100
Iteration                                 97
LinearFeatureBaseline/ExplainedVariance    1
MaxReturn                                100
MinReturn                                100
NumTrajs                                  40
Perplexity                                 1.68578
PolicyExecTime                             0.364102
ProcessExecTime                            0.0196965
StdReturn                                  0
policy/Entropy                             0.530567
policy/KL                                  0.00706008
policy/KLBefore                            0
policy/LossAfter                          -0.00630498
policy/LossBefore                         -1.26362e-08
policy/dLoss                               0.00630497
---------------------------------------  -------------
2019-10-09 11:00:01 | [experiment_2019_10_09_10_58_54_0001] epoch #98 | Obtaining samples...
2019-10-09 11:00:01 | [experiment_2019_10_09_10_58_54_0001] epoch #98 | Obtaining samples for iteration 98...
2019-10-09 11:00:02 | [experiment_2019_10_09_10_58_54_0001] epoch #98 | Logging diagnostics...
2019-10-09 11:00:02 | [experiment_2019_10_09_10_58_54_0001] epoch #98 | Optimizing policy...
2019-10-09 11:00:02 | [experiment_2019_10_09_10_58_54_0001] epoch #98 | Computing loss before
2019-10-09 11:00:02 | [experiment_2019_10_09_10_58_54_0001] epoch #98 | Computing KL before
2019-10-09 11:00:02 | [experiment_2019_10_09_10_58_54_0001] epoch #98 | Optimizing
2019-10-09 11:00:02 | [experiment_2019_10_09_10_58_54_0001] epoch #98 | Start CG optimization: #parameters: 1282, #inputs: 41, #subsample_inputs: 41
2019-10-09 11:00:02 | [experiment_2019_10_09_10_58_54_0001] epoch #98 | computing loss before
2019-10-09 11:00:02 | [experiment_2019_10_09_10_58_54_0001] epoch #98 | performing update
2019-10-09 11:00:02 | [experiment_2019_10_09_10_58_54_0001] epoch #98 | computing gradient
2019-10-09 11:00:02 | [experiment_2019_10_09_10_58_54_0001] epoch #98 | gradient computed
2019-10-09 11:00:02 | [experiment_2019_10_09_10_58_54_0001] epoch #98 | computing descent direction
2019-10-09 11:00:02 | [experiment_2019_10_09_10_58_54_0001] epoch #98 | descent direction computed
2019-10-09 11:00:02 | [experiment_2019_10_09_10_58_54_0001] epoch #98 | backtrack iters: 5
2019-10-09 11:00:02 | [experiment_2019_10_09_10_58_54_0001] epoch #98 | computing loss after
2019-10-09 11:00:02 | [experiment_2019_10_09_10_58_54_0001] epoch #98 | optimization finished
2019-10-09 11:00:02 | [experiment_2019_10_09_10_58_54_0001] epoch #98 | Computing KL after
2019-10-09 11:00:02 | [experiment_2019_10_09_10_58_54_0001] epoch #98 | Computing loss after
2019-10-09 11:00:02 | [experiment_2019_10_09_10_58_54_0001] epoch #98 | Fitting baseline...
2019-10-09 11:00:02 | [experiment_2019_10_09_10_58_54_0001] epoch #98 | Saving snapshot...
2019-10-09 11:00:02 | [experiment_2019_10_09_10_58_54_0001] epoch #98 | Saved
2019-10-09 11:00:02 | [experiment_2019_10_09_10_58_54_0001] epoch #98 | Time 63.44 s
2019-10-09 11:00:02 | [experiment_2019_10_09_10_58_54_0001] epoch #98 | EpochTime 0.69 s
---------------------------------------  -------------
AverageDiscountedReturn                   62.9683
AverageReturn                             99.0488
Entropy                                    0.522832
EnvExecTime                                0.0580738
Extras/EpisodeRewardMean                  99.61
Iteration                                 98
LinearFeatureBaseline/ExplainedVariance    0.97274
MaxReturn                                100
MinReturn                                 61
NumTrajs                                  41
Perplexity                                 1.6868
PolicyExecTime                             0.390432
ProcessExecTime                            0.0210056
StdReturn                                  6.01604
policy/Entropy                             0.487039
policy/KL                                  0.00920742
policy/KLBefore                            4.35079e-10
policy/LossAfter                          -0.0128495
policy/LossBefore                          1.15437e-08
policy/dLoss                               0.0128496
---------------------------------------  -------------
2019-10-09 11:00:02 | [experiment_2019_10_09_10_58_54_0001] epoch #99 | Obtaining samples...
2019-10-09 11:00:02 | [experiment_2019_10_09_10_58_54_0001] epoch #99 | Obtaining samples for iteration 99...
2019-10-09 11:00:03 | [experiment_2019_10_09_10_58_54_0001] epoch #99 | Logging diagnostics...
2019-10-09 11:00:03 | [experiment_2019_10_09_10_58_54_0001] epoch #99 | Optimizing policy...
2019-10-09 11:00:03 | [experiment_2019_10_09_10_58_54_0001] epoch #99 | Computing loss before
2019-10-09 11:00:03 | [experiment_2019_10_09_10_58_54_0001] epoch #99 | Computing KL before
2019-10-09 11:00:03 | [experiment_2019_10_09_10_58_54_0001] epoch #99 | Optimizing
2019-10-09 11:00:03 | [experiment_2019_10_09_10_58_54_0001] epoch #99 | Start CG optimization: #parameters: 1282, #inputs: 40, #subsample_inputs: 40
2019-10-09 11:00:03 | [experiment_2019_10_09_10_58_54_0001] epoch #99 | computing loss before
2019-10-09 11:00:03 | [experiment_2019_10_09_10_58_54_0001] epoch #99 | performing update
2019-10-09 11:00:03 | [experiment_2019_10_09_10_58_54_0001] epoch #99 | computing gradient
2019-10-09 11:00:03 | [experiment_2019_10_09_10_58_54_0001] epoch #99 | gradient computed
2019-10-09 11:00:03 | [experiment_2019_10_09_10_58_54_0001] epoch #99 | computing descent direction
2019-10-09 11:00:03 | [experiment_2019_10_09_10_58_54_0001] epoch #99 | descent direction computed
2019-10-09 11:00:03 | [experiment_2019_10_09_10_58_54_0001] epoch #99 | backtrack iters: 2
2019-10-09 11:00:03 | [experiment_2019_10_09_10_58_54_0001] epoch #99 | computing loss after
2019-10-09 11:00:03 | [experiment_2019_10_09_10_58_54_0001] epoch #99 | optimization finished
2019-10-09 11:00:03 | [experiment_2019_10_09_10_58_54_0001] epoch #99 | Computing KL after
2019-10-09 11:00:03 | [experiment_2019_10_09_10_58_54_0001] epoch #99 | Computing loss after
2019-10-09 11:00:03 | [experiment_2019_10_09_10_58_54_0001] epoch #99 | Fitting baseline...
2019-10-09 11:00:03 | [experiment_2019_10_09_10_58_54_0001] epoch #99 | Saving snapshot...
2019-10-09 11:00:03 | [experiment_2019_10_09_10_58_54_0001] epoch #99 | Saved
2019-10-09 11:00:03 | [experiment_2019_10_09_10_58_54_0001] epoch #99 | Time 64.10 s
2019-10-09 11:00:03 | [experiment_2019_10_09_10_58_54_0001] epoch #99 | EpochTime 0.65 s
---------------------------------------  -------------
AverageDiscountedReturn                   63.3968
AverageReturn                            100
Entropy                                    0.521418
EnvExecTime                                0.0531185
Extras/EpisodeRewardMean                  99.61
Iteration                                 99
LinearFeatureBaseline/ExplainedVariance    0.998494
MaxReturn                                100
MinReturn                                100
NumTrajs                                  40
Perplexity                                 1.68441
PolicyExecTime                             0.365603
ProcessExecTime                            0.0197423
StdReturn                                  0
policy/Entropy                             0.501746
policy/KL                                  0.00818689
policy/KLBefore                            0
policy/LossAfter                          -0.0117231
policy/LossBefore                         -3.91006e-08
policy/dLoss                               0.0117231
---------------------------------------  -------------
